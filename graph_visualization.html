<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 750px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 750px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "##28282B", "id": "(\u0027Fine-tune the Entire RAG Architecture (including DPR retriever) for\\n  Question-Answering\u0027, \u0027Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Suranga\\n  Nanayakkara\u0027):   In this paper, we illustrate how to fine-tune the entire Retrieval Augment\nGeneration (RAG) architecture in an end-to-end manner. We highlighted the main\nengineering challenges that needed to be addressed to achieve this objective.\nWe also compare how end-to-end RAG architecture outperforms the original RAG\narchitecture for the task of question answering. We have open-sourced our\nimplementation in the HuggingFace Transformers library.", "label": "(\u0027Fine-tune the Entire RAG Architecture (including DPR retriever) for\\n  Question-Answering\u0027, \u0027Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Suranga\\n  Nanayakkara\u0027):   In this paper, we illustrate how to fine-tune the entire Retrieval Augment\nGeneration (RAG) architecture in an end-to-end manner. We highlighted the main\nengineering challenges that needed to be addressed to achieve this objective.\nWe also compare how end-to-end RAG architecture outperforms the original RAG\narchitecture for the task of question answering. We have open-sourced our\nimplementation in the HuggingFace Transformers library.", "shape": "dot", "title": "Node: (\u0027Fine-tune the Entire RAG Architecture (including DPR retriever) for\\n  Question-Answering\u0027, \u0027Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Suranga\\n  Nanayakkara\u0027):   In this paper, we illustrate how to fine-tune the entire Retrieval Augment\nGeneration (RAG) architecture in an end-to-end manner. We highlighted the main\nengineering challenges that needed to be addressed to achieve this objective.\nWe also compare how end-to-end RAG architecture outperforms the original RAG\narchitecture for the task of question answering. We have open-sourced our\nimplementation in the HuggingFace Transformers library.\nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieval Augmented Generation and Representative Vector Summarization\\n  for large unstructured textual data in Medical Education\u0027, \u0027S. S. Manathunga and Y. A. Illangasekara\u0027):   Large Language Models are increasingly being used for various tasks including\ncontent generation and as chatbots. Despite their impressive performances in\ngeneral tasks, LLMs need to be aligned when applying for domain specific tasks\nto mitigate the problems of hallucination and producing harmful answers.\nRetrieval Augmented Generation (RAG) allows to easily attach and manipulate a\nnon-parametric knowledgebases to LLMs. Applications of RAG in the field of\nmedical education are discussed in this paper. A combined extractive and\nabstractive summarization method for large unstructured textual data using\nrepresentative vectors is proposed.", "label": "(\u0027Retrieval Augmented Generation and Representative Vector Summarization\\n  for large unstructured textual data in Medical Education\u0027, \u0027S. S. Manathunga and Y. A. Illangasekara\u0027):   Large Language Models are increasingly being used for various tasks including\ncontent generation and as chatbots. Despite their impressive performances in\ngeneral tasks, LLMs need to be aligned when applying for domain specific tasks\nto mitigate the problems of hallucination and producing harmful answers.\nRetrieval Augmented Generation (RAG) allows to easily attach and manipulate a\nnon-parametric knowledgebases to LLMs. Applications of RAG in the field of\nmedical education are discussed in this paper. A combined extractive and\nabstractive summarization method for large unstructured textual data using\nrepresentative vectors is proposed.", "shape": "dot", "title": "Node: (\u0027Retrieval Augmented Generation and Representative Vector Summarization\\n  for large unstructured textual data in Medical Education\u0027, \u0027S. S. Manathunga and Y. A. Illangasekara\u0027):   Large Language Models are increasingly being used for various tasks including\ncontent generation and as chatbots. Despite their impressive performances in\ngeneral tasks, LLMs need to be aligned when applying for domain specific tasks\nto mitigate the problems of hallucination and producing harmful answers.\nRetrieval Augmented Generation (RAG) allows to easily attach and manipulate a\nnon-parametric knowledgebases to LLMs. Applications of RAG in the field of\nmedical education are discussed in this paper. A combined extractive and\nabstractive summarization method for large unstructured textual data using\nrepresentative vectors is proposed.\nPaper ID: 2308.00479\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Study on the Implementation of Generative AI Services Using an\\n  Enterprise Data-Based LLM Application Architecture\u0027, \u0027Cheonsu Jeong\u0027):   This study presents a method for implementing generative AI services by\nutilizing the Large Language Models (LLM) application architecture. With recent\nadvancements in generative AI technology, LLMs have gained prominence across\nvarious domains. In this context, the research addresses the challenge of\ninformation scarcity and proposes specific remedies by harnessing LLM\ncapabilities. The investigation delves into strategies for mitigating the issue\nof inadequate data, offering tailored solutions. The study delves into the\nefficacy of employing fine-tuning techniques and direct document integration to\nalleviate data insufficiency. A significant contribution of this work is the\ndevelopment of a Retrieval-Augmented Generation (RAG) model, which tackles the\naforementioned challenges. The RAG model is carefully designed to enhance\ninformation storage and retrieval processes, ensuring improved content\ngeneration. The research elucidates the key phases of the information storage\nand retrieval methodology underpinned by the RAG model. A comprehensive\nanalysis of these steps is undertaken, emphasizing their significance in\naddressing the scarcity of data. The study highlights the efficacy of the\nproposed method, showcasing its applicability through illustrative instances.\nBy implementing the RAG model for information storage and retrieval, the\nresearch not only contributes to a deeper comprehension of generative AI\ntechnology but also facilitates its practical usability within enterprises\nutilizing LLMs. This work holds substantial value in advancing the field of\ngenerative AI, offering insights into enhancing data-driven content generation\nand fostering active utilization of LLM-based services within corporate\nsettings.", "label": "(\u0027A Study on the Implementation of Generative AI Services Using an\\n  Enterprise Data-Based LLM Application Architecture\u0027, \u0027Cheonsu Jeong\u0027):   This study presents a method for implementing generative AI services by\nutilizing the Large Language Models (LLM) application architecture. With recent\nadvancements in generative AI technology, LLMs have gained prominence across\nvarious domains. In this context, the research addresses the challenge of\ninformation scarcity and proposes specific remedies by harnessing LLM\ncapabilities. The investigation delves into strategies for mitigating the issue\nof inadequate data, offering tailored solutions. The study delves into the\nefficacy of employing fine-tuning techniques and direct document integration to\nalleviate data insufficiency. A significant contribution of this work is the\ndevelopment of a Retrieval-Augmented Generation (RAG) model, which tackles the\naforementioned challenges. The RAG model is carefully designed to enhance\ninformation storage and retrieval processes, ensuring improved content\ngeneration. The research elucidates the key phases of the information storage\nand retrieval methodology underpinned by the RAG model. A comprehensive\nanalysis of these steps is undertaken, emphasizing their significance in\naddressing the scarcity of data. The study highlights the efficacy of the\nproposed method, showcasing its applicability through illustrative instances.\nBy implementing the RAG model for information storage and retrieval, the\nresearch not only contributes to a deeper comprehension of generative AI\ntechnology but also facilitates its practical usability within enterprises\nutilizing LLMs. This work holds substantial value in advancing the field of\ngenerative AI, offering insights into enhancing data-driven content generation\nand fostering active utilization of LLM-based services within corporate\nsettings.", "shape": "dot", "title": "Node: (\u0027A Study on the Implementation of Generative AI Services Using an\\n  Enterprise Data-Based LLM Application Architecture\u0027, \u0027Cheonsu Jeong\u0027):   This study presents a method for implementing generative AI services by\nutilizing the Large Language Models (LLM) application architecture. With recent\nadvancements in generative AI technology, LLMs have gained prominence across\nvarious domains. In this context, the research addresses the challenge of\ninformation scarcity and proposes specific remedies by harnessing LLM\ncapabilities. The investigation delves into strategies for mitigating the issue\nof inadequate data, offering tailored solutions. The study delves into the\nefficacy of employing fine-tuning techniques and direct document integration to\nalleviate data insufficiency. A significant contribution of this work is the\ndevelopment of a Retrieval-Augmented Generation (RAG) model, which tackles the\naforementioned challenges. The RAG model is carefully designed to enhance\ninformation storage and retrieval processes, ensuring improved content\ngeneration. The research elucidates the key phases of the information storage\nand retrieval methodology underpinned by the RAG model. A comprehensive\nanalysis of these steps is undertaken, emphasizing their significance in\naddressing the scarcity of data. The study highlights the efficacy of the\nproposed method, showcasing its applicability through illustrative instances.\nBy implementing the RAG model for information storage and retrieval, the\nresearch not only contributes to a deeper comprehension of generative AI\ntechnology but also facilitates its practical usability within enterprises\nutilizing LLMs. This work holds substantial value in advancing the field of\ngenerative AI, offering insights into enhancing data-driven content generation\nand fostering active utilization of LLM-based services within corporate\nsettings.\nPaper ID: 2309.01105\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Benchmarking Large Language Models in Retrieval-Augmented Generation\u0027, \u0027Jiawei Chen, Hongyu Lin, Xianpei Han, Le Sun\u0027):   Retrieval-Augmented Generation (RAG) is a promising approach for mitigating\nthe hallucination of large language models (LLMs). However, existing research\nlacks rigorous evaluation of the impact of retrieval-augmented generation on\ndifferent large language models, which make it challenging to identify the\npotential bottlenecks in the capabilities of RAG for different LLMs. In this\npaper, we systematically investigate the impact of Retrieval-Augmented\nGeneration on large language models. We analyze the performance of different\nlarge language models in 4 fundamental abilities required for RAG, including\nnoise robustness, negative rejection, information integration, and\ncounterfactual robustness. To this end, we establish Retrieval-Augmented\nGeneration Benchmark (RGB), a new corpus for RAG evaluation in both English and\nChinese. RGB divides the instances within the benchmark into 4 separate\ntestbeds based on the aforementioned fundamental abilities required to resolve\nthe case. Then we evaluate 6 representative LLMs on RGB to diagnose the\nchallenges of current LLMs when applying RAG. Evaluation reveals that while\nLLMs exhibit a certain degree of noise robustness, they still struggle\nsignificantly in terms of negative rejection, information integration, and\ndealing with false information. The aforementioned assessment outcomes indicate\nthat there is still a considerable journey ahead to effectively apply RAG to\nLLMs.", "label": "(\u0027Benchmarking Large Language Models in Retrieval-Augmented Generation\u0027, \u0027Jiawei Chen, Hongyu Lin, Xianpei Han, Le Sun\u0027):   Retrieval-Augmented Generation (RAG) is a promising approach for mitigating\nthe hallucination of large language models (LLMs). However, existing research\nlacks rigorous evaluation of the impact of retrieval-augmented generation on\ndifferent large language models, which make it challenging to identify the\npotential bottlenecks in the capabilities of RAG for different LLMs. In this\npaper, we systematically investigate the impact of Retrieval-Augmented\nGeneration on large language models. We analyze the performance of different\nlarge language models in 4 fundamental abilities required for RAG, including\nnoise robustness, negative rejection, information integration, and\ncounterfactual robustness. To this end, we establish Retrieval-Augmented\nGeneration Benchmark (RGB), a new corpus for RAG evaluation in both English and\nChinese. RGB divides the instances within the benchmark into 4 separate\ntestbeds based on the aforementioned fundamental abilities required to resolve\nthe case. Then we evaluate 6 representative LLMs on RGB to diagnose the\nchallenges of current LLMs when applying RAG. Evaluation reveals that while\nLLMs exhibit a certain degree of noise robustness, they still struggle\nsignificantly in terms of negative rejection, information integration, and\ndealing with false information. The aforementioned assessment outcomes indicate\nthat there is still a considerable journey ahead to effectively apply RAG to\nLLMs.", "shape": "dot", "title": "Node: (\u0027Benchmarking Large Language Models in Retrieval-Augmented Generation\u0027, \u0027Jiawei Chen, Hongyu Lin, Xianpei Han, Le Sun\u0027):   Retrieval-Augmented Generation (RAG) is a promising approach for mitigating\nthe hallucination of large language models (LLMs). However, existing research\nlacks rigorous evaluation of the impact of retrieval-augmented generation on\ndifferent large language models, which make it challenging to identify the\npotential bottlenecks in the capabilities of RAG for different LLMs. In this\npaper, we systematically investigate the impact of Retrieval-Augmented\nGeneration on large language models. We analyze the performance of different\nlarge language models in 4 fundamental abilities required for RAG, including\nnoise robustness, negative rejection, information integration, and\ncounterfactual robustness. To this end, we establish Retrieval-Augmented\nGeneration Benchmark (RGB), a new corpus for RAG evaluation in both English and\nChinese. RGB divides the instances within the benchmark into 4 separate\ntestbeds based on the aforementioned fundamental abilities required to resolve\nthe case. Then we evaluate 6 representative LLMs on RGB to diagnose the\nchallenges of current LLMs when applying RAG. Evaluation reveals that while\nLLMs exhibit a certain degree of noise robustness, they still struggle\nsignificantly in terms of negative rejection, information integration, and\ndealing with false information. The aforementioned assessment outcomes indicate\nthat there is still a considerable journey ahead to effectively apply RAG to\nLLMs.\nPaper ID: 2309.01431\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027, \u0027Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert\u0027):   We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework\nfor reference-free evaluation of Retrieval Augmented Generation (RAG)\npipelines. RAG systems are composed of a retrieval and an LLM based generation\nmodule, and provide LLMs with knowledge from a reference textual database,\nwhich enables them to act as a natural language layer between a user and\ntextual databases, reducing the risk of hallucinations. Evaluating RAG\narchitectures is, however, challenging because there are several dimensions to\nconsider: the ability of the retrieval system to identify relevant and focused\ncontext passages, the ability of the LLM to exploit such passages in a faithful\nway, or the quality of the generation itself. With RAGAs, we put forward a\nsuite of metrics which can be used to evaluate these different dimensions\n\\textit{without having to rely on ground truth human annotations}. We posit\nthat such a framework can crucially contribute to faster evaluation cycles of\nRAG architectures, which is especially important given the fast adoption of\nLLMs.", "label": "(\u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027, \u0027Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert\u0027):   We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework\nfor reference-free evaluation of Retrieval Augmented Generation (RAG)\npipelines. RAG systems are composed of a retrieval and an LLM based generation\nmodule, and provide LLMs with knowledge from a reference textual database,\nwhich enables them to act as a natural language layer between a user and\ntextual databases, reducing the risk of hallucinations. Evaluating RAG\narchitectures is, however, challenging because there are several dimensions to\nconsider: the ability of the retrieval system to identify relevant and focused\ncontext passages, the ability of the LLM to exploit such passages in a faithful\nway, or the quality of the generation itself. With RAGAs, we put forward a\nsuite of metrics which can be used to evaluate these different dimensions\n\\textit{without having to rely on ground truth human annotations}. We posit\nthat such a framework can crucially contribute to faster evaluation cycles of\nRAG architectures, which is especially important given the fast adoption of\nLLMs.", "shape": "dot", "title": "Node: (\u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027, \u0027Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert\u0027):   We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework\nfor reference-free evaluation of Retrieval Augmented Generation (RAG)\npipelines. RAG systems are composed of a retrieval and an LLM based generation\nmodule, and provide LLMs with knowledge from a reference textual database,\nwhich enables them to act as a natural language layer between a user and\ntextual databases, reducing the risk of hallucinations. Evaluating RAG\narchitectures is, however, challenging because there are several dimensions to\nconsider: the ability of the retrieval system to identify relevant and focused\ncontext passages, the ability of the LLM to exploit such passages in a faithful\nway, or the quality of the generation itself. With RAGAs, we put forward a\nsuite of metrics which can be used to evaluate these different dimensions\n\\textit{without having to rely on ground truth human annotations}. We posit\nthat such a framework can crucially contribute to faster evaluation cycles of\nRAG architectures, which is especially important given the fast adoption of\nLLMs.\nPaper ID: 2309.15217\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027, \u0027Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi,\\n  Yi Dai, Jiawei Sun, Meng Wang and Haofen Wang\u0027):   Large Language Models (LLMs) showcase impressive capabilities but encounter\nchallenges like hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the generation,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs\u0027 intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval, the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces up-to-date evaluation framework and\nbenchmark. At the end, this article delineates the challenges currently faced\nand points out prospective avenues for research and development.", "label": "(\u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027, \u0027Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi,\\n  Yi Dai, Jiawei Sun, Meng Wang and Haofen Wang\u0027):   Large Language Models (LLMs) showcase impressive capabilities but encounter\nchallenges like hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the generation,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs\u0027 intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval, the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces up-to-date evaluation framework and\nbenchmark. At the end, this article delineates the challenges currently faced\nand points out prospective avenues for research and development.", "shape": "dot", "title": "Node: (\u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027, \u0027Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi,\\n  Yi Dai, Jiawei Sun, Meng Wang and Haofen Wang\u0027):   Large Language Models (LLMs) showcase impressive capabilities but encounter\nchallenges like hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the generation,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs\u0027 intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval, the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces up-to-date evaluation framework and\nbenchmark. At the end, this article delineates the challenges currently faced\nand points out prospective avenues for research and development.\nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Bridging the Preference Gap between Retrievers and LLMs\u0027, \u0027Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei and\\n  Michael Bendersky\u0027):   Large Language Models (LLMs) have demonstrated superior results across a wide\nrange of tasks, and Retrieval-augmented Generation (RAG) is an effective way to\nenhance the performance by locating relevant information and placing it into\nthe context window of the LLM. However, the relationship between retrievers and\nLLMs in a RAG is still under-investigated. Most existing work treats the\nretriever and the LLM as independent components and leaves a gap between\nretrieving human-\"friendly\" information and assembling a LLM-\"friendly\"\ncontext. In this work, we examine a novel bridge mechanism. We validate the\nranking and selection assumptions of retrievers in the context of RAG and\npropose a framework that chains together supervised and reinforcement learning\nto train a bridge model that optimizes the connection between the retriever and\nthe LLM. Empirical results demonstrate the effectiveness of our method in both\nquestion-answering and personalized generation tasks.", "label": "(\u0027Bridging the Preference Gap between Retrievers and LLMs\u0027, \u0027Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei and\\n  Michael Bendersky\u0027):   Large Language Models (LLMs) have demonstrated superior results across a wide\nrange of tasks, and Retrieval-augmented Generation (RAG) is an effective way to\nenhance the performance by locating relevant information and placing it into\nthe context window of the LLM. However, the relationship between retrievers and\nLLMs in a RAG is still under-investigated. Most existing work treats the\nretriever and the LLM as independent components and leaves a gap between\nretrieving human-\"friendly\" information and assembling a LLM-\"friendly\"\ncontext. In this work, we examine a novel bridge mechanism. We validate the\nranking and selection assumptions of retrievers in the context of RAG and\npropose a framework that chains together supervised and reinforcement learning\nto train a bridge model that optimizes the connection between the retriever and\nthe LLM. Empirical results demonstrate the effectiveness of our method in both\nquestion-answering and personalized generation tasks.", "shape": "dot", "title": "Node: (\u0027Bridging the Preference Gap between Retrievers and LLMs\u0027, \u0027Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei and\\n  Michael Bendersky\u0027):   Large Language Models (LLMs) have demonstrated superior results across a wide\nrange of tasks, and Retrieval-augmented Generation (RAG) is an effective way to\nenhance the performance by locating relevant information and placing it into\nthe context window of the LLM. However, the relationship between retrievers and\nLLMs in a RAG is still under-investigated. Most existing work treats the\nretriever and the LLM as independent components and leaves a gap between\nretrieving human-\"friendly\" information and assembling a LLM-\"friendly\"\ncontext. In this work, we examine a novel bridge mechanism. We validate the\nranking and selection assumptions of retrievers in the context of RAG and\npropose a framework that chains together supervised and reinforcement learning\nto train a bridge model that optimizes the connection between the retriever and\nthe LLM. Empirical results demonstrate the effectiveness of our method in both\nquestion-answering and personalized generation tasks.\nPaper ID: 2401.06954\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027The Chronicles of RAG: The Retriever, the Chunk and the Generator\u0027, \"Paulo Finardi, Leonardo Avila, Rodrigo Castaldoni, Pedro Gengo, Celio\\n  Larcher, Marcos Piau, Pablo Costa, Vinicius Carid\\\\\u0027a\"):   Retrieval Augmented Generation (RAG) has become one of the most popular\nparadigms for enabling LLMs to access external data, and also as a mechanism\nfor grounding to mitigate against hallucinations. When implementing RAG you can\nface several challenges like effective integration of retrieval models,\nefficient representation learning, data diversity, computational efficiency\noptimization, evaluation, and quality of text generation. Given all these\nchallenges, every day a new technique to improve RAG appears, making it\nunfeasible to experiment with all combinations for your problem. In this\ncontext, this paper presents good practices to implement, optimize, and\nevaluate RAG for the Brazilian Portuguese language, focusing on the\nestablishment of a simple pipeline for inference and experiments. We explored a\ndiverse set of methods to answer questions about the first Harry Potter book.\nTo generate the answers we used the OpenAI\u0027s gpt-4, gpt-4-1106-preview,\ngpt-3.5-turbo-1106, and Google\u0027s Gemini Pro. Focusing on the quality of the\nretriever, our approach achieved an improvement of MRR@10 by 35.4% compared to\nthe baseline. When optimizing the input size in the application, we observed\nthat it is possible to further enhance it by 2.4%. Finally, we present the\ncomplete architecture of the RAG with our recommendations. As result, we moved\nfrom a baseline of 57.88% to a maximum relative score of 98.61%.", "label": "(\u0027The Chronicles of RAG: The Retriever, the Chunk and the Generator\u0027, \"Paulo Finardi, Leonardo Avila, Rodrigo Castaldoni, Pedro Gengo, Celio\\n  Larcher, Marcos Piau, Pablo Costa, Vinicius Carid\\\\\u0027a\"):   Retrieval Augmented Generation (RAG) has become one of the most popular\nparadigms for enabling LLMs to access external data, and also as a mechanism\nfor grounding to mitigate against hallucinations. When implementing RAG you can\nface several challenges like effective integration of retrieval models,\nefficient representation learning, data diversity, computational efficiency\noptimization, evaluation, and quality of text generation. Given all these\nchallenges, every day a new technique to improve RAG appears, making it\nunfeasible to experiment with all combinations for your problem. In this\ncontext, this paper presents good practices to implement, optimize, and\nevaluate RAG for the Brazilian Portuguese language, focusing on the\nestablishment of a simple pipeline for inference and experiments. We explored a\ndiverse set of methods to answer questions about the first Harry Potter book.\nTo generate the answers we used the OpenAI\u0027s gpt-4, gpt-4-1106-preview,\ngpt-3.5-turbo-1106, and Google\u0027s Gemini Pro. Focusing on the quality of the\nretriever, our approach achieved an improvement of MRR@10 by 35.4% compared to\nthe baseline. When optimizing the input size in the application, we observed\nthat it is possible to further enhance it by 2.4%. Finally, we present the\ncomplete architecture of the RAG with our recommendations. As result, we moved\nfrom a baseline of 57.88% to a maximum relative score of 98.61%.", "shape": "dot", "title": "Node: (\u0027The Chronicles of RAG: The Retriever, the Chunk and the Generator\u0027, \"Paulo Finardi, Leonardo Avila, Rodrigo Castaldoni, Pedro Gengo, Celio\\n  Larcher, Marcos Piau, Pablo Costa, Vinicius Carid\\\\\u0027a\"):   Retrieval Augmented Generation (RAG) has become one of the most popular\nparadigms for enabling LLMs to access external data, and also as a mechanism\nfor grounding to mitigate against hallucinations. When implementing RAG you can\nface several challenges like effective integration of retrieval models,\nefficient representation learning, data diversity, computational efficiency\noptimization, evaluation, and quality of text generation. Given all these\nchallenges, every day a new technique to improve RAG appears, making it\nunfeasible to experiment with all combinations for your problem. In this\ncontext, this paper presents good practices to implement, optimize, and\nevaluate RAG for the Brazilian Portuguese language, focusing on the\nestablishment of a simple pipeline for inference and experiments. We explored a\ndiverse set of methods to answer questions about the first Harry Potter book.\nTo generate the answers we used the OpenAI\u0027s gpt-4, gpt-4-1106-preview,\ngpt-3.5-turbo-1106, and Google\u0027s Gemini Pro. Focusing on the quality of the\nretriever, our approach achieved an improvement of MRR@10 by 35.4% compared to\nthe baseline. When optimizing the input size in the application, we observed\nthat it is possible to further enhance it by 2.4%. Finally, we present the\ncomplete architecture of the RAG with our recommendations. As result, we moved\nfrom a baseline of 57.88% to a maximum relative score of 98.61%.\nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027, \u0027Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone\\n  Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, Fabrizio\\n  Silvestri\u0027):   Retrieval-Augmented Generation (RAG) has recently emerged as a method to\nextend beyond the pre-trained knowledge of Large Language Models by augmenting\nthe original prompt with relevant passages or documents retrieved by an\nInformation Retrieval (IR) system. RAG has become increasingly important for\nGenerative AI solutions, especially in enterprise settings or in any domain in\nwhich knowledge is constantly refreshed and cannot be memorized in the LLM. We\nargue here that the retrieval component of RAG systems, be it dense or sparse,\ndeserves increased attention from the research community, and accordingly, we\nconduct the first comprehensive and systematic examination of the retrieval\nstrategy of RAG systems. We focus, in particular, on the type of passages IR\nsystems within a RAG solution should retrieve. Our analysis considers multiple\nfactors, such as the relevance of the passages included in the prompt context,\ntheir position, and their number. One counter-intuitive finding of this work is\nthat the retriever\u0027s highest-scoring documents that are not directly relevant\nto the query (e.g., do not contain the answer) negatively impact the\neffectiveness of the LLM. Even more surprising, we discovered that adding\nrandom documents in the prompt improves the LLM accuracy by up to 35%. These\nresults highlight the need to investigate the appropriate strategies when\nintegrating retrieval with LLMs, thereby laying the groundwork for future\nresearch in this area.", "label": "(\u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027, \u0027Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone\\n  Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, Fabrizio\\n  Silvestri\u0027):   Retrieval-Augmented Generation (RAG) has recently emerged as a method to\nextend beyond the pre-trained knowledge of Large Language Models by augmenting\nthe original prompt with relevant passages or documents retrieved by an\nInformation Retrieval (IR) system. RAG has become increasingly important for\nGenerative AI solutions, especially in enterprise settings or in any domain in\nwhich knowledge is constantly refreshed and cannot be memorized in the LLM. We\nargue here that the retrieval component of RAG systems, be it dense or sparse,\ndeserves increased attention from the research community, and accordingly, we\nconduct the first comprehensive and systematic examination of the retrieval\nstrategy of RAG systems. We focus, in particular, on the type of passages IR\nsystems within a RAG solution should retrieve. Our analysis considers multiple\nfactors, such as the relevance of the passages included in the prompt context,\ntheir position, and their number. One counter-intuitive finding of this work is\nthat the retriever\u0027s highest-scoring documents that are not directly relevant\nto the query (e.g., do not contain the answer) negatively impact the\neffectiveness of the LLM. Even more surprising, we discovered that adding\nrandom documents in the prompt improves the LLM accuracy by up to 35%. These\nresults highlight the need to investigate the appropriate strategies when\nintegrating retrieval with LLMs, thereby laying the groundwork for future\nresearch in this area.", "shape": "dot", "title": "Node: (\u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027, \u0027Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone\\n  Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, Fabrizio\\n  Silvestri\u0027):   Retrieval-Augmented Generation (RAG) has recently emerged as a method to\nextend beyond the pre-trained knowledge of Large Language Models by augmenting\nthe original prompt with relevant passages or documents retrieved by an\nInformation Retrieval (IR) system. RAG has become increasingly important for\nGenerative AI solutions, especially in enterprise settings or in any domain in\nwhich knowledge is constantly refreshed and cannot be memorized in the LLM. We\nargue here that the retrieval component of RAG systems, be it dense or sparse,\ndeserves increased attention from the research community, and accordingly, we\nconduct the first comprehensive and systematic examination of the retrieval\nstrategy of RAG systems. We focus, in particular, on the type of passages IR\nsystems within a RAG solution should retrieve. Our analysis considers multiple\nfactors, such as the relevance of the passages included in the prompt context,\ntheir position, and their number. One counter-intuitive finding of this work is\nthat the retriever\u0027s highest-scoring documents that are not directly relevant\nto the query (e.g., do not contain the answer) negatively impact the\neffectiveness of the LLM. Even more surprising, we discovered that adding\nrandom documents in the prompt improves the LLM accuracy by up to 35%. These\nresults highlight the need to investigate the appropriate strategies when\nintegrating retrieval with LLMs, thereby laying the groundwork for future\nresearch in this area.\nPaper ID: 2401.14887\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Corrective Retrieval Augmented Generation\u0027, \u0027Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling\u0027):   Large language models (LLMs) inevitably exhibit hallucinations since the\naccuracy of generated texts cannot be secured solely by the parametric\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\ndocuments, raising concerns about how the model behaves if retrieval goes\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\nretrieval evaluator is designed to assess the overall quality of retrieved\ndocuments for a query, returning a confidence degree based on which different\nknowledge retrieval actions can be triggered. Since retrieval from static and\nlimited corpora can only return sub-optimal documents, large-scale web searches\nare utilized as an extension for augmenting the retrieval results. Besides, a\ndecompose-then-recompose algorithm is designed for retrieved documents to\nselectively focus on key information and filter out irrelevant information in\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\nRAG-based approaches. Experiments on four datasets covering short- and\nlong-form generation tasks show that CRAG can significantly improve the\nperformance of RAG-based approaches.", "label": "(\u0027Corrective Retrieval Augmented Generation\u0027, \u0027Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling\u0027):   Large language models (LLMs) inevitably exhibit hallucinations since the\naccuracy of generated texts cannot be secured solely by the parametric\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\ndocuments, raising concerns about how the model behaves if retrieval goes\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\nretrieval evaluator is designed to assess the overall quality of retrieved\ndocuments for a query, returning a confidence degree based on which different\nknowledge retrieval actions can be triggered. Since retrieval from static and\nlimited corpora can only return sub-optimal documents, large-scale web searches\nare utilized as an extension for augmenting the retrieval results. Besides, a\ndecompose-then-recompose algorithm is designed for retrieved documents to\nselectively focus on key information and filter out irrelevant information in\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\nRAG-based approaches. Experiments on four datasets covering short- and\nlong-form generation tasks show that CRAG can significantly improve the\nperformance of RAG-based approaches.", "shape": "dot", "title": "Node: (\u0027Corrective Retrieval Augmented Generation\u0027, \u0027Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling\u0027):   Large language models (LLMs) inevitably exhibit hallucinations since the\naccuracy of generated texts cannot be secured solely by the parametric\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\ndocuments, raising concerns about how the model behaves if retrieval goes\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\nretrieval evaluator is designed to assess the overall quality of retrieved\ndocuments for a query, returning a confidence degree based on which different\nknowledge retrieval actions can be triggered. Since retrieval from static and\nlimited corpora can only return sub-optimal documents, large-scale web searches\nare utilized as an extension for augmenting the retrieval results. Besides, a\ndecompose-then-recompose algorithm is designed for retrieved documents to\nselectively focus on key information and filter out irrelevant information in\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\nRAG-based approaches. Experiments on four datasets covering short- and\nlong-form generation tasks show that CRAG can significantly improve the\nperformance of RAG-based approaches.\nPaper ID: 2401.15884\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented\\n  Generation of Large Language Models\u0027, \u0027Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang,\\n  Hao Wu, Huanyong Liu, Tong Xu, Enhong Chen\u0027):   Retrieval-Augmented Generation (RAG) is a technique that enhances the\ncapabilities of large language models (LLMs) by incorporating external\nknowledge sources. This method addresses common LLM limitations, including\noutdated information and the tendency to produce inaccurate \"hallucinated\"\ncontent. However, the evaluation of RAG systems is challenging, as existing\nbenchmarks are limited in scope and diversity. Most of the current benchmarks\npredominantly assess question-answering applications, overlooking the broader\nspectrum of situations where RAG could prove advantageous. Moreover, they only\nevaluate the performance of the LLM component of the RAG pipeline in the\nexperiments, and neglect the influence of the retrieval component and the\nexternal knowledge database. To address these issues, this paper constructs a\nlarge-scale and more comprehensive benchmark, and evaluates all the components\nof RAG systems in various RAG application scenarios. Specifically, we have\ncategorized the range of RAG applications into four distinct types-Create,\nRead, Update, and Delete (CRUD), each representing a unique use case. \"Create\"\nrefers to scenarios requiring the generation of original, varied content.\n\"Read\" involves responding to intricate questions in knowledge-intensive\nsituations. \"Update\" focuses on revising and rectifying inaccuracies or\ninconsistencies in pre-existing texts. \"Delete\" pertains to the task of\nsummarizing extensive texts into more concise forms. For each of these CRUD\ncategories, we have developed comprehensive datasets to evaluate the\nperformance of RAG systems. We also analyze the effects of various components\nof the RAG system, such as the retriever, the context length, the knowledge\nbase construction, and the LLM. Finally, we provide useful insights for\noptimizing the RAG technology for different scenarios.", "label": "(\u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented\\n  Generation of Large Language Models\u0027, \u0027Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang,\\n  Hao Wu, Huanyong Liu, Tong Xu, Enhong Chen\u0027):   Retrieval-Augmented Generation (RAG) is a technique that enhances the\ncapabilities of large language models (LLMs) by incorporating external\nknowledge sources. This method addresses common LLM limitations, including\noutdated information and the tendency to produce inaccurate \"hallucinated\"\ncontent. However, the evaluation of RAG systems is challenging, as existing\nbenchmarks are limited in scope and diversity. Most of the current benchmarks\npredominantly assess question-answering applications, overlooking the broader\nspectrum of situations where RAG could prove advantageous. Moreover, they only\nevaluate the performance of the LLM component of the RAG pipeline in the\nexperiments, and neglect the influence of the retrieval component and the\nexternal knowledge database. To address these issues, this paper constructs a\nlarge-scale and more comprehensive benchmark, and evaluates all the components\nof RAG systems in various RAG application scenarios. Specifically, we have\ncategorized the range of RAG applications into four distinct types-Create,\nRead, Update, and Delete (CRUD), each representing a unique use case. \"Create\"\nrefers to scenarios requiring the generation of original, varied content.\n\"Read\" involves responding to intricate questions in knowledge-intensive\nsituations. \"Update\" focuses on revising and rectifying inaccuracies or\ninconsistencies in pre-existing texts. \"Delete\" pertains to the task of\nsummarizing extensive texts into more concise forms. For each of these CRUD\ncategories, we have developed comprehensive datasets to evaluate the\nperformance of RAG systems. We also analyze the effects of various components\nof the RAG system, such as the retriever, the context length, the knowledge\nbase construction, and the LLM. Finally, we provide useful insights for\noptimizing the RAG technology for different scenarios.", "shape": "dot", "title": "Node: (\u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented\\n  Generation of Large Language Models\u0027, \u0027Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang,\\n  Hao Wu, Huanyong Liu, Tong Xu, Enhong Chen\u0027):   Retrieval-Augmented Generation (RAG) is a technique that enhances the\ncapabilities of large language models (LLMs) by incorporating external\nknowledge sources. This method addresses common LLM limitations, including\noutdated information and the tendency to produce inaccurate \"hallucinated\"\ncontent. However, the evaluation of RAG systems is challenging, as existing\nbenchmarks are limited in scope and diversity. Most of the current benchmarks\npredominantly assess question-answering applications, overlooking the broader\nspectrum of situations where RAG could prove advantageous. Moreover, they only\nevaluate the performance of the LLM component of the RAG pipeline in the\nexperiments, and neglect the influence of the retrieval component and the\nexternal knowledge database. To address these issues, this paper constructs a\nlarge-scale and more comprehensive benchmark, and evaluates all the components\nof RAG systems in various RAG application scenarios. Specifically, we have\ncategorized the range of RAG applications into four distinct types-Create,\nRead, Update, and Delete (CRUD), each representing a unique use case. \"Create\"\nrefers to scenarios requiring the generation of original, varied content.\n\"Read\" involves responding to intricate questions in knowledge-intensive\nsituations. \"Update\" focuses on revising and rectifying inaccuracies or\ninconsistencies in pre-existing texts. \"Delete\" pertains to the task of\nsummarizing extensive texts into more concise forms. For each of these CRUD\ncategories, we have developed comprehensive datasets to evaluate the\nperformance of RAG systems. We also analyze the effects of various components\nof the RAG system, such as the retriever, the context length, the knowledge\nbase construction, and the LLM. Finally, we provide useful insights for\noptimizing the RAG technology for different scenarios.\nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027, \u0027Xinyue Chen, Pengyu Gao, Jiangjiang Song, Xiaoyang Tan\u0027):   Retrieval-augmented generation (RAG) has rapidly advanced the language model\nfield, particularly in question-answering (QA) systems. By integrating external\ndocuments during the response generation phase, RAG significantly enhances the\naccuracy and reliability of language models. This method elevates the quality\nof responses and reduces the frequency of hallucinations, where the model\ngenerates incorrect or misleading information. However, these methods exhibit\nlimited retrieval accuracy when faced with numerous indistinguishable\ndocuments, presenting notable challenges in their practical application. In\nresponse to these emerging challenges, we present HiQA, an advanced\nmulti-document question-answering (MDQA) framework that integrates cascading\nmetadata into content and a multi-route retrieval mechanism. We also release a\nbenchmark called MasQA to evaluate and research in MDQA. Finally, HiQA\ndemonstrates the state-of-the-art performance in multi-document environments.", "label": "(\u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027, \u0027Xinyue Chen, Pengyu Gao, Jiangjiang Song, Xiaoyang Tan\u0027):   Retrieval-augmented generation (RAG) has rapidly advanced the language model\nfield, particularly in question-answering (QA) systems. By integrating external\ndocuments during the response generation phase, RAG significantly enhances the\naccuracy and reliability of language models. This method elevates the quality\nof responses and reduces the frequency of hallucinations, where the model\ngenerates incorrect or misleading information. However, these methods exhibit\nlimited retrieval accuracy when faced with numerous indistinguishable\ndocuments, presenting notable challenges in their practical application. In\nresponse to these emerging challenges, we present HiQA, an advanced\nmulti-document question-answering (MDQA) framework that integrates cascading\nmetadata into content and a multi-route retrieval mechanism. We also release a\nbenchmark called MasQA to evaluate and research in MDQA. Finally, HiQA\ndemonstrates the state-of-the-art performance in multi-document environments.", "shape": "dot", "title": "Node: (\u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027, \u0027Xinyue Chen, Pengyu Gao, Jiangjiang Song, Xiaoyang Tan\u0027):   Retrieval-augmented generation (RAG) has rapidly advanced the language model\nfield, particularly in question-answering (QA) systems. By integrating external\ndocuments during the response generation phase, RAG significantly enhances the\naccuracy and reliability of language models. This method elevates the quality\nof responses and reduces the frequency of hallucinations, where the model\ngenerates incorrect or misleading information. However, these methods exhibit\nlimited retrieval accuracy when faced with numerous indistinguishable\ndocuments, presenting notable challenges in their practical application. In\nresponse to these emerging challenges, we present HiQA, an advanced\nmulti-document question-answering (MDQA) framework that integrates cascading\nmetadata into content and a multi-route retrieval mechanism. We also release a\nbenchmark called MasQA to evaluate and research in MDQA. Finally, HiQA\ndemonstrates the state-of-the-art performance in multi-document environments.\nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Enhancing Retrieval Processes for Language Generation with Augmented\\n  Queries\u0027, \u0027Julien Pierre Edmond Ghali, Kosuke Shima, Koichi Moriyama, Atsuko\\n  Mutoh, Nobuhiro Inuzuka\u0027):   In the rapidly changing world of smart technology, searching for documents\nhas become more challenging due to the rise of advanced language models. These\nmodels sometimes face difficulties, like providing inaccurate information,\ncommonly known as \"hallucination.\" This research focuses on addressing this\nissue through Retrieval-Augmented Generation (RAG), a technique that guides\nmodels to give accurate responses based on real facts. To overcome scalability\nissues, the study explores connecting user queries with sophisticated language\nmodels such as BERT and Orca2, using an innovative query optimization process.\nThe study unfolds in three scenarios: first, without RAG, second, without\nadditional assistance, and finally, with extra help. Choosing the compact yet\nefficient Orca2 7B model demonstrates a smart use of computing resources. The\nempirical results indicate a significant improvement in the initial language\nmodel\u0027s performance under RAG, particularly when assisted with prompts\naugmenters. Consistency in document retrieval across different encodings\nhighlights the effectiveness of using language model-generated queries. The\nintroduction of UMAP for BERT further simplifies document retrieval while\nmaintaining strong results.", "label": "(\u0027Enhancing Retrieval Processes for Language Generation with Augmented\\n  Queries\u0027, \u0027Julien Pierre Edmond Ghali, Kosuke Shima, Koichi Moriyama, Atsuko\\n  Mutoh, Nobuhiro Inuzuka\u0027):   In the rapidly changing world of smart technology, searching for documents\nhas become more challenging due to the rise of advanced language models. These\nmodels sometimes face difficulties, like providing inaccurate information,\ncommonly known as \"hallucination.\" This research focuses on addressing this\nissue through Retrieval-Augmented Generation (RAG), a technique that guides\nmodels to give accurate responses based on real facts. To overcome scalability\nissues, the study explores connecting user queries with sophisticated language\nmodels such as BERT and Orca2, using an innovative query optimization process.\nThe study unfolds in three scenarios: first, without RAG, second, without\nadditional assistance, and finally, with extra help. Choosing the compact yet\nefficient Orca2 7B model demonstrates a smart use of computing resources. The\nempirical results indicate a significant improvement in the initial language\nmodel\u0027s performance under RAG, particularly when assisted with prompts\naugmenters. Consistency in document retrieval across different encodings\nhighlights the effectiveness of using language model-generated queries. The\nintroduction of UMAP for BERT further simplifies document retrieval while\nmaintaining strong results.", "shape": "dot", "title": "Node: (\u0027Enhancing Retrieval Processes for Language Generation with Augmented\\n  Queries\u0027, \u0027Julien Pierre Edmond Ghali, Kosuke Shima, Koichi Moriyama, Atsuko\\n  Mutoh, Nobuhiro Inuzuka\u0027):   In the rapidly changing world of smart technology, searching for documents\nhas become more challenging due to the rise of advanced language models. These\nmodels sometimes face difficulties, like providing inaccurate information,\ncommonly known as \"hallucination.\" This research focuses on addressing this\nissue through Retrieval-Augmented Generation (RAG), a technique that guides\nmodels to give accurate responses based on real facts. To overcome scalability\nissues, the study explores connecting user queries with sophisticated language\nmodels such as BERT and Orca2, using an innovative query optimization process.\nThe study unfolds in three scenarios: first, without RAG, second, without\nadditional assistance, and finally, with extra help. Choosing the compact yet\nefficient Orca2 7B model demonstrates a smart use of computing resources. The\nempirical results indicate a significant improvement in the initial language\nmodel\u0027s performance under RAG, particularly when assisted with prompts\naugmenters. Consistency in document retrieval across different encodings\nhighlights the effectiveness of using language model-generated queries. The\nintroduction of UMAP for BERT further simplifies document retrieval while\nmaintaining strong results.\nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027, \u0027Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng,\\n  Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\u0027):   Advancements in model algorithms, the growth of foundational models, and\naccess to high-quality datasets have propelled the evolution of Artificial\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\nstill faces hurdles such as updating knowledge, handling long-tail data,\nmitigating data leakage, and managing high training and inference costs.\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\naddress such challenges. In particular, RAG introduces the information\nretrieval process, which enhances the generation process by retrieving relevant\nobjects from available data stores, leading to higher accuracy and better\nrobustness. In this paper, we comprehensively review existing efforts that\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\naccording to how the retriever augments the generator, distilling the\nfundamental abstractions of the augmentation methodologies for various\nretrievers and generators. This unified perspective encompasses all RAG\nscenarios, illuminating advancements and pivotal technologies that help with\npotential future progress. We also summarize additional enhancements methods\nfor RAG, facilitating effective engineering and implementation of RAG systems.\nThen from another view, we survey on practical applications of RAG across\ndifferent modalities and tasks, offering valuable references for researchers\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\nthe limitations of current RAG systems, and suggest potential directions for\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.", "label": "(\u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027, \u0027Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng,\\n  Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\u0027):   Advancements in model algorithms, the growth of foundational models, and\naccess to high-quality datasets have propelled the evolution of Artificial\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\nstill faces hurdles such as updating knowledge, handling long-tail data,\nmitigating data leakage, and managing high training and inference costs.\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\naddress such challenges. In particular, RAG introduces the information\nretrieval process, which enhances the generation process by retrieving relevant\nobjects from available data stores, leading to higher accuracy and better\nrobustness. In this paper, we comprehensively review existing efforts that\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\naccording to how the retriever augments the generator, distilling the\nfundamental abstractions of the augmentation methodologies for various\nretrievers and generators. This unified perspective encompasses all RAG\nscenarios, illuminating advancements and pivotal technologies that help with\npotential future progress. We also summarize additional enhancements methods\nfor RAG, facilitating effective engineering and implementation of RAG systems.\nThen from another view, we survey on practical applications of RAG across\ndifferent modalities and tasks, offering valuable references for researchers\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\nthe limitations of current RAG systems, and suggest potential directions for\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.", "shape": "dot", "title": "Node: (\u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027, \u0027Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng,\\n  Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, Bin Cui\u0027):   Advancements in model algorithms, the growth of foundational models, and\naccess to high-quality datasets have propelled the evolution of Artificial\nIntelligence Generated Content (AIGC). Despite its notable successes, AIGC\nstill faces hurdles such as updating knowledge, handling long-tail data,\nmitigating data leakage, and managing high training and inference costs.\nRetrieval-Augmented Generation (RAG) has recently emerged as a paradigm to\naddress such challenges. In particular, RAG introduces the information\nretrieval process, which enhances the generation process by retrieving relevant\nobjects from available data stores, leading to higher accuracy and better\nrobustness. In this paper, we comprehensively review existing efforts that\nintegrate RAG technique into AIGC scenarios. We first classify RAG foundations\naccording to how the retriever augments the generator, distilling the\nfundamental abstractions of the augmentation methodologies for various\nretrievers and generators. This unified perspective encompasses all RAG\nscenarios, illuminating advancements and pivotal technologies that help with\npotential future progress. We also summarize additional enhancements methods\nfor RAG, facilitating effective engineering and implementation of RAG systems.\nThen from another view, we survey on practical applications of RAG across\ndifferent modalities and tasks, offering valuable references for researchers\nand practitioners. Furthermore, we introduce the benchmarks for RAG, discuss\nthe limitations of current RAG systems, and suggest potential directions for\nfuture research. Github: https://github.com/PKU-DAIR/RAG-Survey.\nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieval Augmented Generation Systems: Automatic Dataset Creation,\\n  Evaluation and Boolean Agent Setup\u0027, \u0027Tristan Kenneweg and Philip Kenneweg and Barbara Hammer\u0027):   Retrieval Augmented Generation (RAG) systems have seen huge popularity in\naugmenting Large-Language Model (LLM) outputs with domain specific and time\nsensitive data. Very recently a shift is happening from simple RAG setups that\nquery a vector database for additional information with every user input to\nmore sophisticated forms of RAG. However, different concrete approaches compete\non mostly anecdotal evidence at the moment. In this paper we present a rigorous\ndataset creation and evaluation workflow to quantitatively compare different\nRAG strategies. We use a dataset created this way for the development and\nevaluation of a boolean agent RAG setup: A system in which a LLM can decide\nwhether to query a vector database or not, thus saving tokens on questions that\ncan be answered with internal knowledge. We publish our code and generated\ndataset online.", "label": "(\u0027Retrieval Augmented Generation Systems: Automatic Dataset Creation,\\n  Evaluation and Boolean Agent Setup\u0027, \u0027Tristan Kenneweg and Philip Kenneweg and Barbara Hammer\u0027):   Retrieval Augmented Generation (RAG) systems have seen huge popularity in\naugmenting Large-Language Model (LLM) outputs with domain specific and time\nsensitive data. Very recently a shift is happening from simple RAG setups that\nquery a vector database for additional information with every user input to\nmore sophisticated forms of RAG. However, different concrete approaches compete\non mostly anecdotal evidence at the moment. In this paper we present a rigorous\ndataset creation and evaluation workflow to quantitatively compare different\nRAG strategies. We use a dataset created this way for the development and\nevaluation of a boolean agent RAG setup: A system in which a LLM can decide\nwhether to query a vector database or not, thus saving tokens on questions that\ncan be answered with internal knowledge. We publish our code and generated\ndataset online.", "shape": "dot", "title": "Node: (\u0027Retrieval Augmented Generation Systems: Automatic Dataset Creation,\\n  Evaluation and Boolean Agent Setup\u0027, \u0027Tristan Kenneweg and Philip Kenneweg and Barbara Hammer\u0027):   Retrieval Augmented Generation (RAG) systems have seen huge popularity in\naugmenting Large-Language Model (LLM) outputs with domain specific and time\nsensitive data. Very recently a shift is happening from simple RAG setups that\nquery a vector database for additional information with every user input to\nmore sophisticated forms of RAG. However, different concrete approaches compete\non mostly anecdotal evidence at the moment. In this paper we present a rigorous\ndataset creation and evaluation workflow to quantitatively compare different\nRAG strategies. We use a dataset created this way for the development and\nevaluation of a boolean agent RAG setup: A system in which a LLM can decide\nwhether to query a vector database or not, thus saving tokens on questions that\ncan be answered with internal knowledge. We publish our code and generated\ndataset online.\nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System\\n  Co-design\u0027, \u0027Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, Tim Kraska\u0027):   Retrieval-augmented generation (RAG) can enhance the generation quality of\nlarge language models (LLMs) by incorporating external token databases.\nHowever, retrievals from large databases can constitute a substantial portion\nof the overall generation time, particularly when retrievals are periodically\nperformed to align the retrieved content with the latest states of generation.\nIn this paper, we introduce PipeRAG, a novel algorithm-system co-design\napproach to reduce generation latency and enhance generation quality. PipeRAG\nintegrates (1) pipeline parallelism to enable concurrent retrieval and\ngeneration processes, (2) flexible retrieval intervals to maximize the\nefficiency of pipeline parallelism, and (3) a performance model to\nautomatically balance retrieval quality and latency based on the generation\nstates and underlying hardware. Our evaluation shows that, by combining the\nthree aforementioned methods, PipeRAG achieves up to 2.6$\\times$ speedup in\nend-to-end generation latency while improving generation quality. These\npromising results showcase the effectiveness of co-designing algorithms with\nunderlying systems, paving the way for the adoption of PipeRAG in future RAG\nsystems.", "label": "(\u0027PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System\\n  Co-design\u0027, \u0027Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, Tim Kraska\u0027):   Retrieval-augmented generation (RAG) can enhance the generation quality of\nlarge language models (LLMs) by incorporating external token databases.\nHowever, retrievals from large databases can constitute a substantial portion\nof the overall generation time, particularly when retrievals are periodically\nperformed to align the retrieved content with the latest states of generation.\nIn this paper, we introduce PipeRAG, a novel algorithm-system co-design\napproach to reduce generation latency and enhance generation quality. PipeRAG\nintegrates (1) pipeline parallelism to enable concurrent retrieval and\ngeneration processes, (2) flexible retrieval intervals to maximize the\nefficiency of pipeline parallelism, and (3) a performance model to\nautomatically balance retrieval quality and latency based on the generation\nstates and underlying hardware. Our evaluation shows that, by combining the\nthree aforementioned methods, PipeRAG achieves up to 2.6$\\times$ speedup in\nend-to-end generation latency while improving generation quality. These\npromising results showcase the effectiveness of co-designing algorithms with\nunderlying systems, paving the way for the adoption of PipeRAG in future RAG\nsystems.", "shape": "dot", "title": "Node: (\u0027PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System\\n  Co-design\u0027, \u0027Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, Tim Kraska\u0027):   Retrieval-augmented generation (RAG) can enhance the generation quality of\nlarge language models (LLMs) by incorporating external token databases.\nHowever, retrievals from large databases can constitute a substantial portion\nof the overall generation time, particularly when retrievals are periodically\nperformed to align the retrieved content with the latest states of generation.\nIn this paper, we introduce PipeRAG, a novel algorithm-system co-design\napproach to reduce generation latency and enhance generation quality. PipeRAG\nintegrates (1) pipeline parallelism to enable concurrent retrieval and\ngeneration processes, (2) flexible retrieval intervals to maximize the\nefficiency of pipeline parallelism, and (3) a performance model to\nautomatically balance retrieval quality and latency based on the generation\nstates and underlying hardware. Our evaluation shows that, by combining the\nthree aforementioned methods, PipeRAG achieves up to 2.6$\\times$ speedup in\nend-to-end generation latency while improving generation quality. These\npromising results showcase the effectiveness of co-designing algorithms with\nunderlying systems, paving the way for the adoption of PipeRAG in future RAG\nsystems.\nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAGGED: Towards Informed Design of Retrieval Augmented Generation\\n  Systems\u0027, \u0027Jennifer Hsia, Afreen Shaikh, Zhiruo Wang, Graham Neubig\u0027):   Retrieval-augmented generation (RAG) can significantly improve the\nperformance of language models (LMs) by providing additional context for tasks\nsuch as document-based question answering (DBQA). However, the effectiveness of\nRAG is highly dependent on its configuration. To systematically find the\noptimal configuration, we introduce RAGGED, a framework for analyzing RAG\nconfigurations across various DBQA tasks. Using the framework, we discover\ndistinct LM behaviors in response to varying context quantities, context\nqualities, and retrievers. For instance, while some models are robust to noisy\ncontexts, monotonically performing better with more contexts, others are more\nnoise-sensitive and can effectively use only a few contexts before declining in\nperformance. This framework also provides a deeper analysis of these\ndifferences by evaluating the LMs\u0027 sensitivity to signal and noise under\nspecific context quality conditions. Using RAGGED, researchers and\npractitioners can derive actionable insights about how to optimally configure\ntheir RAG systems for their specific question-answering tasks.", "label": "(\u0027RAGGED: Towards Informed Design of Retrieval Augmented Generation\\n  Systems\u0027, \u0027Jennifer Hsia, Afreen Shaikh, Zhiruo Wang, Graham Neubig\u0027):   Retrieval-augmented generation (RAG) can significantly improve the\nperformance of language models (LMs) by providing additional context for tasks\nsuch as document-based question answering (DBQA). However, the effectiveness of\nRAG is highly dependent on its configuration. To systematically find the\noptimal configuration, we introduce RAGGED, a framework for analyzing RAG\nconfigurations across various DBQA tasks. Using the framework, we discover\ndistinct LM behaviors in response to varying context quantities, context\nqualities, and retrievers. For instance, while some models are robust to noisy\ncontexts, monotonically performing better with more contexts, others are more\nnoise-sensitive and can effectively use only a few contexts before declining in\nperformance. This framework also provides a deeper analysis of these\ndifferences by evaluating the LMs\u0027 sensitivity to signal and noise under\nspecific context quality conditions. Using RAGGED, researchers and\npractitioners can derive actionable insights about how to optimally configure\ntheir RAG systems for their specific question-answering tasks.", "shape": "dot", "title": "Node: (\u0027RAGGED: Towards Informed Design of Retrieval Augmented Generation\\n  Systems\u0027, \u0027Jennifer Hsia, Afreen Shaikh, Zhiruo Wang, Graham Neubig\u0027):   Retrieval-augmented generation (RAG) can significantly improve the\nperformance of language models (LMs) by providing additional context for tasks\nsuch as document-based question answering (DBQA). However, the effectiveness of\nRAG is highly dependent on its configuration. To systematically find the\noptimal configuration, we introduce RAGGED, a framework for analyzing RAG\nconfigurations across various DBQA tasks. Using the framework, we discover\ndistinct LM behaviors in response to varying context quantities, context\nqualities, and retrievers. For instance, while some models are robust to noisy\ncontexts, monotonically performing better with more contexts, others are more\nnoise-sensitive and can effectively use only a few contexts before declining in\nperformance. This framework also provides a deeper analysis of these\ndifferences by evaluating the LMs\u0027 sensitivity to signal and noise under\nspecific context quality conditions. Using RAGGED, researchers and\npractitioners can derive actionable insights about how to optimally configure\ntheir RAG systems for their specific question-answering tasks.\nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information\\n  Needs of Large Language Models\u0027, \u0027Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu\u0027):   Dynamic retrieval augmented generation (RAG) paradigm actively decides when\nand what to retrieve during the text generation process of Large Language\nModels (LLMs). There are two key elements of this paradigm: identifying the\noptimal moment to activate the retrieval module (deciding when to retrieve) and\ncrafting the appropriate query once retrieval is triggered (determining what to\nretrieve). However, current dynamic RAG methods fall short in both aspects.\nFirstly, the strategies for deciding when to retrieve often rely on static\nrules. Moreover, the strategies for deciding what to retrieve typically limit\nthemselves to the LLM\u0027s most recent sentence or the last few tokens, while the\nLLM\u0027s real-time information needs may span across the entire context. To\novercome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic\nRetrieval Augmented Generation based on the real-time Information Needs of\nLLMs. Our framework is specifically designed to make decisions on when and what\nto retrieve based on the LLM\u0027s real-time information needs during the text\ngeneration process. We evaluate DRAGIN along with existing methods\ncomprehensively over 4 knowledge-intensive generation datasets. Experimental\nresults show that DRAGIN achieves superior performance on all tasks,\ndemonstrating the effectiveness of our method. We have open-sourced all the\ncode, data, and models in GitHub: https://github.com/oneal2000/DRAGIN/tree/main", "label": "(\u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information\\n  Needs of Large Language Models\u0027, \u0027Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu\u0027):   Dynamic retrieval augmented generation (RAG) paradigm actively decides when\nand what to retrieve during the text generation process of Large Language\nModels (LLMs). There are two key elements of this paradigm: identifying the\noptimal moment to activate the retrieval module (deciding when to retrieve) and\ncrafting the appropriate query once retrieval is triggered (determining what to\nretrieve). However, current dynamic RAG methods fall short in both aspects.\nFirstly, the strategies for deciding when to retrieve often rely on static\nrules. Moreover, the strategies for deciding what to retrieve typically limit\nthemselves to the LLM\u0027s most recent sentence or the last few tokens, while the\nLLM\u0027s real-time information needs may span across the entire context. To\novercome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic\nRetrieval Augmented Generation based on the real-time Information Needs of\nLLMs. Our framework is specifically designed to make decisions on when and what\nto retrieve based on the LLM\u0027s real-time information needs during the text\ngeneration process. We evaluate DRAGIN along with existing methods\ncomprehensively over 4 knowledge-intensive generation datasets. Experimental\nresults show that DRAGIN achieves superior performance on all tasks,\ndemonstrating the effectiveness of our method. We have open-sourced all the\ncode, data, and models in GitHub: https://github.com/oneal2000/DRAGIN/tree/main", "shape": "dot", "title": "Node: (\u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information\\n  Needs of Large Language Models\u0027, \u0027Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu\u0027):   Dynamic retrieval augmented generation (RAG) paradigm actively decides when\nand what to retrieve during the text generation process of Large Language\nModels (LLMs). There are two key elements of this paradigm: identifying the\noptimal moment to activate the retrieval module (deciding when to retrieve) and\ncrafting the appropriate query once retrieval is triggered (determining what to\nretrieve). However, current dynamic RAG methods fall short in both aspects.\nFirstly, the strategies for deciding when to retrieve often rely on static\nrules. Moreover, the strategies for deciding what to retrieve typically limit\nthemselves to the LLM\u0027s most recent sentence or the last few tokens, while the\nLLM\u0027s real-time information needs may span across the entire context. To\novercome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic\nRetrieval Augmented Generation based on the real-time Information Needs of\nLLMs. Our framework is specifically designed to make decisions on when and what\nto retrieve based on the LLM\u0027s real-time information needs during the text\ngeneration process. We evaluate DRAGIN along with existing methods\ncomprehensively over 4 knowledge-intensive generation datasets. Experimental\nresults show that DRAGIN achieves superior performance on all tasks,\ndemonstrating the effectiveness of our method. We have open-sourced all the\ncode, data, and models in GitHub: https://github.com/oneal2000/DRAGIN/tree/main\nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Dynamic Contexts for Generating Suggestion Questions in RAG Based\\n  Conversational Systems\u0027, \u0027Anuja Tayal and Aman Tyagi\u0027):   When interacting with Retrieval-Augmented Generation (RAG)-based\nconversational agents, the users must carefully craft their queries to be\nunderstood correctly. Yet, understanding the system\u0027s capabilities can be\nchallenging for the users, leading to ambiguous questions that necessitate\nfurther clarification. This work aims to bridge the gap by developing a\nsuggestion question generator. To generate suggestion questions, our approach\ninvolves utilizing dynamic context, which includes both dynamic few-shot\nexamples and dynamically retrieved contexts. Through experiments, we show that\nthe dynamic contexts approach can generate better suggestion questions as\ncompared to other prompting approaches.", "label": "(\u0027Dynamic Contexts for Generating Suggestion Questions in RAG Based\\n  Conversational Systems\u0027, \u0027Anuja Tayal and Aman Tyagi\u0027):   When interacting with Retrieval-Augmented Generation (RAG)-based\nconversational agents, the users must carefully craft their queries to be\nunderstood correctly. Yet, understanding the system\u0027s capabilities can be\nchallenging for the users, leading to ambiguous questions that necessitate\nfurther clarification. This work aims to bridge the gap by developing a\nsuggestion question generator. To generate suggestion questions, our approach\ninvolves utilizing dynamic context, which includes both dynamic few-shot\nexamples and dynamically retrieved contexts. Through experiments, we show that\nthe dynamic contexts approach can generate better suggestion questions as\ncompared to other prompting approaches.", "shape": "dot", "title": "Node: (\u0027Dynamic Contexts for Generating Suggestion Questions in RAG Based\\n  Conversational Systems\u0027, \u0027Anuja Tayal and Aman Tyagi\u0027):   When interacting with Retrieval-Augmented Generation (RAG)-based\nconversational agents, the users must carefully craft their queries to be\nunderstood correctly. Yet, understanding the system\u0027s capabilities can be\nchallenging for the users, leading to ambiguous questions that necessitate\nfurther clarification. This work aims to bridge the gap by developing a\nsuggestion question generator. To generate suggestion questions, our approach\ninvolves utilizing dynamic context, which includes both dynamic few-shot\nexamples and dynamically retrieved contexts. Through experiments, we show that\nthe dynamic contexts approach can generate better suggestion questions as\ncompared to other prompting approaches.\nPaper ID: 2403.11413\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Loops On Retrieval Augmented Generation (LoRAG)\u0027, \u0027Ayush Thakur and Rashmi Vashisth\u0027):   This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new\nframework designed to enhance the quality of retrieval-augmented text\ngeneration through the incorporation of an iterative loop mechanism. The\narchitecture integrates a generative model, a retrieval mechanism, and a\ndynamic loop module, allowing for iterative refinement of the generated text\nthrough interactions with relevant information retrieved from the input\ncontext. Experimental evaluations on benchmark datasets demonstrate that LoRAG\nsurpasses existing state-of-the-art models in terms of BLEU score, ROUGE score,\nand perplexity, showcasing its effectiveness in achieving both coherence and\nrelevance in generated text. The qualitative assessment further illustrates\nLoRAG\u0027s capability to produce contextually rich and coherent outputs. This\nresearch contributes valuable insights into the potential of iterative loops in\nmitigating challenges in text generation, positioning LoRAG as a promising\nadvancement in the field.", "label": "(\u0027Loops On Retrieval Augmented Generation (LoRAG)\u0027, \u0027Ayush Thakur and Rashmi Vashisth\u0027):   This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new\nframework designed to enhance the quality of retrieval-augmented text\ngeneration through the incorporation of an iterative loop mechanism. The\narchitecture integrates a generative model, a retrieval mechanism, and a\ndynamic loop module, allowing for iterative refinement of the generated text\nthrough interactions with relevant information retrieved from the input\ncontext. Experimental evaluations on benchmark datasets demonstrate that LoRAG\nsurpasses existing state-of-the-art models in terms of BLEU score, ROUGE score,\nand perplexity, showcasing its effectiveness in achieving both coherence and\nrelevance in generated text. The qualitative assessment further illustrates\nLoRAG\u0027s capability to produce contextually rich and coherent outputs. This\nresearch contributes valuable insights into the potential of iterative loops in\nmitigating challenges in text generation, positioning LoRAG as a promising\nadvancement in the field.", "shape": "dot", "title": "Node: (\u0027Loops On Retrieval Augmented Generation (LoRAG)\u0027, \u0027Ayush Thakur and Rashmi Vashisth\u0027):   This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new\nframework designed to enhance the quality of retrieval-augmented text\ngeneration through the incorporation of an iterative loop mechanism. The\narchitecture integrates a generative model, a retrieval mechanism, and a\ndynamic loop module, allowing for iterative refinement of the generated text\nthrough interactions with relevant information retrieved from the input\ncontext. Experimental evaluations on benchmark datasets demonstrate that LoRAG\nsurpasses existing state-of-the-art models in terms of BLEU score, ROUGE score,\nand perplexity, showcasing its effectiveness in achieving both coherence and\nrelevance in generated text. The qualitative assessment further illustrates\nLoRAG\u0027s capability to produce contextually rich and coherent outputs. This\nresearch contributes valuable insights into the potential of iterative loops in\nmitigating challenges in text generation, positioning LoRAG as a promising\nadvancement in the field.\nPaper ID: 2403.1545\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, \u0027Karthik Suresh, Neeltje Kackar, Luke Schleck, Cristiano Fanelli\u0027):   The complexity and sheer volume of information encompassing documents,\npapers, data, and other resources from large-scale experiments demand\nsignificant time and effort to navigate, making the task of accessing and\nutilizing these varied forms of information daunting, particularly for new\ncollaborators and early-career scientists. To tackle this issue, a Retrieval\nAugmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under\ndevelopment. This AI-Agent not only condenses information but also effectively\nreferences relevant responses, offering substantial advantages for\ncollaborators. Our project involves a two-step approach: first, querying a\ncomprehensive vector database containing all pertinent experiment information;\nsecond, utilizing a Large Language Model (LLM) to generate concise summaries\nenriched with citations based on user queries and retrieved data. We describe\nthe evaluation methods that use RAG assessments (RAGAs) scoring mechanisms to\nassess the effectiveness of responses. Furthermore, we describe the concept of\nprompt template-based instruction-tuning which provides flexibility and\naccuracy in summarization. Importantly, the implementation relies on LangChain,\nwhich serves as the foundation of our entire workflow. This integration ensures\nefficiency and scalability, facilitating smooth deployment and accessibility\nfor various user groups within the Electron Ion Collider (EIC) community. This\ninnovative AI-driven framework not only simplifies the understanding of vast\ndatasets but also encourages collaborative participation, thereby empowering\nresearchers. As a demonstration, a web application has been developed to\nexplain each stage of the RAG Agent development in detail.", "label": "(\u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, \u0027Karthik Suresh, Neeltje Kackar, Luke Schleck, Cristiano Fanelli\u0027):   The complexity and sheer volume of information encompassing documents,\npapers, data, and other resources from large-scale experiments demand\nsignificant time and effort to navigate, making the task of accessing and\nutilizing these varied forms of information daunting, particularly for new\ncollaborators and early-career scientists. To tackle this issue, a Retrieval\nAugmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under\ndevelopment. This AI-Agent not only condenses information but also effectively\nreferences relevant responses, offering substantial advantages for\ncollaborators. Our project involves a two-step approach: first, querying a\ncomprehensive vector database containing all pertinent experiment information;\nsecond, utilizing a Large Language Model (LLM) to generate concise summaries\nenriched with citations based on user queries and retrieved data. We describe\nthe evaluation methods that use RAG assessments (RAGAs) scoring mechanisms to\nassess the effectiveness of responses. Furthermore, we describe the concept of\nprompt template-based instruction-tuning which provides flexibility and\naccuracy in summarization. Importantly, the implementation relies on LangChain,\nwhich serves as the foundation of our entire workflow. This integration ensures\nefficiency and scalability, facilitating smooth deployment and accessibility\nfor various user groups within the Electron Ion Collider (EIC) community. This\ninnovative AI-driven framework not only simplifies the understanding of vast\ndatasets but also encourages collaborative participation, thereby empowering\nresearchers. As a demonstration, a web application has been developed to\nexplain each stage of the RAG Agent development in detail.", "shape": "dot", "title": "Node: (\u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, \u0027Karthik Suresh, Neeltje Kackar, Luke Schleck, Cristiano Fanelli\u0027):   The complexity and sheer volume of information encompassing documents,\npapers, data, and other resources from large-scale experiments demand\nsignificant time and effort to navigate, making the task of accessing and\nutilizing these varied forms of information daunting, particularly for new\ncollaborators and early-career scientists. To tackle this issue, a Retrieval\nAugmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under\ndevelopment. This AI-Agent not only condenses information but also effectively\nreferences relevant responses, offering substantial advantages for\ncollaborators. Our project involves a two-step approach: first, querying a\ncomprehensive vector database containing all pertinent experiment information;\nsecond, utilizing a Large Language Model (LLM) to generate concise summaries\nenriched with citations based on user queries and retrieved data. We describe\nthe evaluation methods that use RAG assessments (RAGAs) scoring mechanisms to\nassess the effectiveness of responses. Furthermore, we describe the concept of\nprompt template-based instruction-tuning which provides flexibility and\naccuracy in summarization. Importantly, the implementation relies on LangChain,\nwhich serves as the foundation of our entire workflow. This integration ensures\nefficiency and scalability, facilitating smooth deployment and accessibility\nfor various user groups within the Electron Ion Collider (EIC) community. This\ninnovative AI-driven framework not only simplifies the understanding of vast\ndatasets but also encourages collaborative participation, thereby empowering\nresearchers. As a demonstration, a web application has been developed to\nexplain each stage of the RAG Agent development in detail.\nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\u0027, \u0027Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo,\\n  Jie Fu\u0027):   Large Language Models (LLMs) exhibit remarkable capabilities but are prone to\ngenerating inaccurate or hallucinatory responses. This limitation stems from\ntheir reliance on vast pretraining datasets, making them susceptible to errors\nin unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation\n(RAG) addresses this by incorporating external, relevant documents into the\nresponse generation process, thus leveraging non-parametric knowledge alongside\nLLMs\u0027 in-context learning abilities. However, existing RAG implementations\nprimarily focus on initial input for context retrieval, overlooking the nuances\nof ambiguous or complex queries that necessitate further clarification or\ndecomposition for accurate responses. To this end, we propose learning to\nRefine Query for Retrieval Augmented Generation (RQ-RAG) in this paper,\nendeavoring to enhance the model by equipping it with capabilities for explicit\nrewriting, decomposition, and disambiguation. Our experimental results indicate\nthat our method, when applied to a 7B Llama2 model, surpasses the previous\nstate-of-the-art (SOTA) by an average of 1.9\\% across three single-hop QA\ndatasets, and also demonstrates enhanced performance in handling complex,\nmulti-hop QA datasets. Our code is available at\nhttps://github.com/chanchimin/RQ-RAG.", "label": "(\u0027RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\u0027, \u0027Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo,\\n  Jie Fu\u0027):   Large Language Models (LLMs) exhibit remarkable capabilities but are prone to\ngenerating inaccurate or hallucinatory responses. This limitation stems from\ntheir reliance on vast pretraining datasets, making them susceptible to errors\nin unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation\n(RAG) addresses this by incorporating external, relevant documents into the\nresponse generation process, thus leveraging non-parametric knowledge alongside\nLLMs\u0027 in-context learning abilities. However, existing RAG implementations\nprimarily focus on initial input for context retrieval, overlooking the nuances\nof ambiguous or complex queries that necessitate further clarification or\ndecomposition for accurate responses. To this end, we propose learning to\nRefine Query for Retrieval Augmented Generation (RQ-RAG) in this paper,\nendeavoring to enhance the model by equipping it with capabilities for explicit\nrewriting, decomposition, and disambiguation. Our experimental results indicate\nthat our method, when applied to a 7B Llama2 model, surpasses the previous\nstate-of-the-art (SOTA) by an average of 1.9\\% across three single-hop QA\ndatasets, and also demonstrates enhanced performance in handling complex,\nmulti-hop QA datasets. Our code is available at\nhttps://github.com/chanchimin/RQ-RAG.", "shape": "dot", "title": "Node: (\u0027RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\u0027, \u0027Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo,\\n  Jie Fu\u0027):   Large Language Models (LLMs) exhibit remarkable capabilities but are prone to\ngenerating inaccurate or hallucinatory responses. This limitation stems from\ntheir reliance on vast pretraining datasets, making them susceptible to errors\nin unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation\n(RAG) addresses this by incorporating external, relevant documents into the\nresponse generation process, thus leveraging non-parametric knowledge alongside\nLLMs\u0027 in-context learning abilities. However, existing RAG implementations\nprimarily focus on initial input for context retrieval, overlooking the nuances\nof ambiguous or complex queries that necessitate further clarification or\ndecomposition for accurate responses. To this end, we propose learning to\nRefine Query for Retrieval Augmented Generation (RQ-RAG) in this paper,\nendeavoring to enhance the model by equipping it with capabilities for explicit\nrewriting, decomposition, and disambiguation. Our experimental results indicate\nthat our method, when applied to a 7B Llama2 model, surpasses the previous\nstate-of-the-art (SOTA) by an average of 1.9\\% across three single-hop QA\ndatasets, and also demonstrates enhanced performance in handling complex,\nmulti-hop QA datasets. Our code is available at\nhttps://github.com/chanchimin/RQ-RAG.\nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Observations on Building RAG Systems for Technical Documents\u0027, \u0027Sumit Soman, Sujoy Roychowdhury\u0027):   Retrieval augmented generation (RAG) for technical documents creates\nchallenges as embeddings do not often capture domain information. We review\nprior art for important factors affecting RAG and perform experiments to\nhighlight best practices and potential challenges to build RAG systems for\ntechnical documents.", "label": "(\u0027Observations on Building RAG Systems for Technical Documents\u0027, \u0027Sumit Soman, Sujoy Roychowdhury\u0027):   Retrieval augmented generation (RAG) for technical documents creates\nchallenges as embeddings do not often capture domain information. We review\nprior art for important factors affecting RAG and perform experiments to\nhighlight best practices and potential challenges to build RAG systems for\ntechnical documents.", "shape": "dot", "title": "Node: (\u0027Observations on Building RAG Systems for Technical Documents\u0027, \u0027Sumit Soman, Sujoy Roychowdhury\u0027):   Retrieval augmented generation (RAG) for technical documents creates\nchallenges as embeddings do not often capture domain information. We review\nprior art for important factors affecting RAG and perform experiments to\nhighlight best practices and potential challenges to build RAG systems for\ntechnical documents.\nPaper ID: 2404.00657\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027ARAGOG: Advanced RAG Output Grading\u0027, \u0027Matou\\\\v{s} Eibich, Shivay Nagpal, Alexander Fred-Ojala\u0027):   Retrieval-Augmented Generation (RAG) is essential for integrating external\nknowledge into Large Language Model (LLM) outputs. While the literature on RAG\nis growing, it primarily focuses on systematic reviews and comparisons of new\nstate-of-the-art (SoTA) techniques against their predecessors, with a gap in\nextensive experimental comparisons. This study begins to address this gap by\nassessing various RAG methods\u0027 impacts on retrieval precision and answer\nsimilarity. We found that Hypothetical Document Embedding (HyDE) and LLM\nreranking significantly enhance retrieval precision. However, Maximal Marginal\nRelevance (MMR) and Cohere rerank did not exhibit notable advantages over a\nbaseline Naive RAG system, and Multi-query approaches underperformed. Sentence\nWindow Retrieval emerged as the most effective for retrieval precision, despite\nits variable performance on answer similarity. The study confirms the potential\nof the Document Summary Index as a competent retrieval approach. All resources\nrelated to this research are publicly accessible for further investigation\nthrough our GitHub repository ARAGOG (https://github.com/predlico/ARAGOG). We\nwelcome the community to further this exploratory study in RAG systems.", "label": "(\u0027ARAGOG: Advanced RAG Output Grading\u0027, \u0027Matou\\\\v{s} Eibich, Shivay Nagpal, Alexander Fred-Ojala\u0027):   Retrieval-Augmented Generation (RAG) is essential for integrating external\nknowledge into Large Language Model (LLM) outputs. While the literature on RAG\nis growing, it primarily focuses on systematic reviews and comparisons of new\nstate-of-the-art (SoTA) techniques against their predecessors, with a gap in\nextensive experimental comparisons. This study begins to address this gap by\nassessing various RAG methods\u0027 impacts on retrieval precision and answer\nsimilarity. We found that Hypothetical Document Embedding (HyDE) and LLM\nreranking significantly enhance retrieval precision. However, Maximal Marginal\nRelevance (MMR) and Cohere rerank did not exhibit notable advantages over a\nbaseline Naive RAG system, and Multi-query approaches underperformed. Sentence\nWindow Retrieval emerged as the most effective for retrieval precision, despite\nits variable performance on answer similarity. The study confirms the potential\nof the Document Summary Index as a competent retrieval approach. All resources\nrelated to this research are publicly accessible for further investigation\nthrough our GitHub repository ARAGOG (https://github.com/predlico/ARAGOG). We\nwelcome the community to further this exploratory study in RAG systems.", "shape": "dot", "title": "Node: (\u0027ARAGOG: Advanced RAG Output Grading\u0027, \u0027Matou\\\\v{s} Eibich, Shivay Nagpal, Alexander Fred-Ojala\u0027):   Retrieval-Augmented Generation (RAG) is essential for integrating external\nknowledge into Large Language Model (LLM) outputs. While the literature on RAG\nis growing, it primarily focuses on systematic reviews and comparisons of new\nstate-of-the-art (SoTA) techniques against their predecessors, with a gap in\nextensive experimental comparisons. This study begins to address this gap by\nassessing various RAG methods\u0027 impacts on retrieval precision and answer\nsimilarity. We found that Hypothetical Document Embedding (HyDE) and LLM\nreranking significantly enhance retrieval precision. However, Maximal Marginal\nRelevance (MMR) and Cohere rerank did not exhibit notable advantages over a\nbaseline Naive RAG system, and Multi-query approaches underperformed. Sentence\nWindow Retrieval emerged as the most effective for retrieval precision, despite\nits variable performance on answer similarity. The study confirms the potential\nof the Document Summary Index as a competent retrieval approach. All resources\nrelated to this research are publicly accessible for further investigation\nthrough our GitHub repository ARAGOG (https://github.com/predlico/ARAGOG). We\nwelcome the community to further this exploratory study in RAG systems.\nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions\\n  for RAG systems\u0027, \u0027Sara Rosenthal, Avirup Sil, Radu Florian, Salim Roukos\u0027):   Retrieval Augmented Generation (RAG) has become a popular application for\nlarge language models. It is preferable that successful RAG systems provide\naccurate answers that are supported by being grounded in a passage without any\nhallucinations. While considerable work is required for building a full RAG\npipeline, being able to benchmark performance is also necessary. We present\nClapNQ, a benchmark Long-form Question Answering dataset for the full RAG\npipeline. ClapNQ includes long answers with grounded gold passages from Natural\nQuestions (NQ) and a corpus to perform either retrieval, generation, or the\nfull RAG pipeline. The ClapNQ answers are concise, 3x smaller than the full\npassage, and cohesive, with multiple pieces of the passage that are not\ncontiguous. RAG models must adapt to these properties to be successful at\nClapNQ. We present baseline experiments and analysis for ClapNQ that highlight\nareas where there is still significant room for improvement in grounded RAG.\nCLAPNQ is publicly available at https://github.com/primeqa/clapnq", "label": "(\u0027CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions\\n  for RAG systems\u0027, \u0027Sara Rosenthal, Avirup Sil, Radu Florian, Salim Roukos\u0027):   Retrieval Augmented Generation (RAG) has become a popular application for\nlarge language models. It is preferable that successful RAG systems provide\naccurate answers that are supported by being grounded in a passage without any\nhallucinations. While considerable work is required for building a full RAG\npipeline, being able to benchmark performance is also necessary. We present\nClapNQ, a benchmark Long-form Question Answering dataset for the full RAG\npipeline. ClapNQ includes long answers with grounded gold passages from Natural\nQuestions (NQ) and a corpus to perform either retrieval, generation, or the\nfull RAG pipeline. The ClapNQ answers are concise, 3x smaller than the full\npassage, and cohesive, with multiple pieces of the passage that are not\ncontiguous. RAG models must adapt to these properties to be successful at\nClapNQ. We present baseline experiments and analysis for ClapNQ that highlight\nareas where there is still significant room for improvement in grounded RAG.\nCLAPNQ is publicly available at https://github.com/primeqa/clapnq", "shape": "dot", "title": "Node: (\u0027CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions\\n  for RAG systems\u0027, \u0027Sara Rosenthal, Avirup Sil, Radu Florian, Salim Roukos\u0027):   Retrieval Augmented Generation (RAG) has become a popular application for\nlarge language models. It is preferable that successful RAG systems provide\naccurate answers that are supported by being grounded in a passage without any\nhallucinations. While considerable work is required for building a full RAG\npipeline, being able to benchmark performance is also necessary. We present\nClapNQ, a benchmark Long-form Question Answering dataset for the full RAG\npipeline. ClapNQ includes long answers with grounded gold passages from Natural\nQuestions (NQ) and a corpus to perform either retrieval, generation, or the\nfull RAG pipeline. The ClapNQ answers are concise, 3x smaller than the full\npassage, and cohesive, with multiple pieces of the passage that are not\ncontiguous. RAG models must adapt to these properties to be successful at\nClapNQ. We present baseline experiments and analysis for ClapNQ that highlight\nareas where there is still significant room for improvement in grounded RAG.\nCLAPNQ is publicly available at https://github.com/primeqa/clapnq\nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieving Examples from Memory for Retrieval Augmented Neural Machine\\n  Translation: A Systematic Comparison\u0027, \u0027Maxime Bouthors, Josep Crego, Francois Yvon\u0027):   Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve\nexamples from memory to guide the generation process. While most works in this\ntrend explore new ways to exploit the retrieved examples, the upstream\nretrieval step is mostly unexplored. In this paper, we study the effect of\nvarying retrieval methods for several translation architectures, to better\nunderstand the interplay between these two processes. We conduct experiments in\ntwo language pairs in a multi-domain setting and consider several downstream\narchitectures based on a standard autoregressive model, an edit-based model,\nand a large language model with in-context learning. Our experiments show that\nthe choice of the retrieval technique impacts the translation scores, with\nvariance across architectures. We also discuss the effects of increasing the\nnumber and diversity of examples, which are mostly positive across the board.", "label": "(\u0027Retrieving Examples from Memory for Retrieval Augmented Neural Machine\\n  Translation: A Systematic Comparison\u0027, \u0027Maxime Bouthors, Josep Crego, Francois Yvon\u0027):   Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve\nexamples from memory to guide the generation process. While most works in this\ntrend explore new ways to exploit the retrieved examples, the upstream\nretrieval step is mostly unexplored. In this paper, we study the effect of\nvarying retrieval methods for several translation architectures, to better\nunderstand the interplay between these two processes. We conduct experiments in\ntwo language pairs in a multi-domain setting and consider several downstream\narchitectures based on a standard autoregressive model, an edit-based model,\nand a large language model with in-context learning. Our experiments show that\nthe choice of the retrieval technique impacts the translation scores, with\nvariance across architectures. We also discuss the effects of increasing the\nnumber and diversity of examples, which are mostly positive across the board.", "shape": "dot", "title": "Node: (\u0027Retrieving Examples from Memory for Retrieval Augmented Neural Machine\\n  Translation: A Systematic Comparison\u0027, \u0027Maxime Bouthors, Josep Crego, Francois Yvon\u0027):   Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve\nexamples from memory to guide the generation process. While most works in this\ntrend explore new ways to exploit the retrieved examples, the upstream\nretrieval step is mostly unexplored. In this paper, we study the effect of\nvarying retrieval methods for several translation architectures, to better\nunderstand the interplay between these two processes. We conduct experiments in\ntwo language pairs in a multi-domain setting and consider several downstream\narchitectures based on a standard autoregressive model, an edit-based model,\nand a large language model with in-context learning. Our experiments show that\nthe choice of the retrieval technique impacts the translation scores, with\nvariance across architectures. We also discuss the effects of increasing the\nnumber and diversity of examples, which are mostly positive across the board.\nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Improving Retrieval for RAG based Question Answering Models on Financial\\n  Documents\u0027, \u0027Spurthi Setty, Harsh Thakkar, Alyssa Lee, Eden Chung, Natan Vidra\u0027):   The effectiveness of Large Language Models (LLMs) in generating accurate\nresponses relies heavily on the quality of input provided, particularly when\nemploying Retrieval Augmented Generation (RAG) techniques. RAG enhances LLMs by\nsourcing the most relevant text chunk(s) to base queries upon. Despite the\nsignificant advancements in LLMs\u0027 response quality in recent years, users may\nstill encounter inaccuracies or irrelevant answers; these issues often stem\nfrom suboptimal text chunk retrieval by RAG rather than the inherent\ncapabilities of LLMs. To augment the efficacy of LLMs, it is crucial to refine\nthe RAG process. This paper explores the existing constraints of RAG pipelines\nand introduces methodologies for enhancing text retrieval. It delves into\nstrategies such as sophisticated chunking techniques, query expansion, the\nincorporation of metadata annotations, the application of re-ranking\nalgorithms, and the fine-tuning of embedding algorithms. Implementing these\napproaches can substantially improve the retrieval quality, thereby elevating\nthe overall performance and reliability of LLMs in processing and responding to\nqueries.", "label": "(\u0027Improving Retrieval for RAG based Question Answering Models on Financial\\n  Documents\u0027, \u0027Spurthi Setty, Harsh Thakkar, Alyssa Lee, Eden Chung, Natan Vidra\u0027):   The effectiveness of Large Language Models (LLMs) in generating accurate\nresponses relies heavily on the quality of input provided, particularly when\nemploying Retrieval Augmented Generation (RAG) techniques. RAG enhances LLMs by\nsourcing the most relevant text chunk(s) to base queries upon. Despite the\nsignificant advancements in LLMs\u0027 response quality in recent years, users may\nstill encounter inaccuracies or irrelevant answers; these issues often stem\nfrom suboptimal text chunk retrieval by RAG rather than the inherent\ncapabilities of LLMs. To augment the efficacy of LLMs, it is crucial to refine\nthe RAG process. This paper explores the existing constraints of RAG pipelines\nand introduces methodologies for enhancing text retrieval. It delves into\nstrategies such as sophisticated chunking techniques, query expansion, the\nincorporation of metadata annotations, the application of re-ranking\nalgorithms, and the fine-tuning of embedding algorithms. Implementing these\napproaches can substantially improve the retrieval quality, thereby elevating\nthe overall performance and reliability of LLMs in processing and responding to\nqueries.", "shape": "dot", "title": "Node: (\u0027Improving Retrieval for RAG based Question Answering Models on Financial\\n  Documents\u0027, \u0027Spurthi Setty, Harsh Thakkar, Alyssa Lee, Eden Chung, Natan Vidra\u0027):   The effectiveness of Large Language Models (LLMs) in generating accurate\nresponses relies heavily on the quality of input provided, particularly when\nemploying Retrieval Augmented Generation (RAG) techniques. RAG enhances LLMs by\nsourcing the most relevant text chunk(s) to base queries upon. Despite the\nsignificant advancements in LLMs\u0027 response quality in recent years, users may\nstill encounter inaccuracies or irrelevant answers; these issues often stem\nfrom suboptimal text chunk retrieval by RAG rather than the inherent\ncapabilities of LLMs. To augment the efficacy of LLMs, it is crucial to refine\nthe RAG process. This paper explores the existing constraints of RAG pipelines\nand introduces methodologies for enhancing text retrieval. It delves into\nstrategies such as sophisticated chunking techniques, query expansion, the\nincorporation of metadata annotations, the application of re-ranking\nalgorithms, and the fine-tuning of embedding algorithms. Implementing these\napproaches can substantially improve the retrieval quality, thereby elevating\nthe overall performance and reliability of LLMs in processing and responding to\nqueries.\nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Reducing hallucination in structured outputs via Retrieval-Augmented\\n  Generation\u0027, \"Patrice B\\\\\u0027echard and Orlando Marquez Ayala\"):   A common and fundamental limitation of Generative AI (GenAI) is its\npropensity to hallucinate. While large language models (LLM) have taken the\nworld by storm, without eliminating or at least reducing hallucinations,\nreal-world GenAI systems may face challenges in user adoption. In the process\nof deploying an enterprise application that produces workflows based on natural\nlanguage requirements, we devised a system leveraging Retrieval Augmented\nGeneration (RAG) to greatly improve the quality of the structured output that\nrepresents such workflows. Thanks to our implementation of RAG, our proposed\nsystem significantly reduces hallucinations in the output and improves the\ngeneralization of our LLM in out-of-domain settings. In addition, we show that\nusing a small, well-trained retriever encoder can reduce the size of the\naccompanying LLM, thereby making deployments of LLM-based systems less\nresource-intensive.", "label": "(\u0027Reducing hallucination in structured outputs via Retrieval-Augmented\\n  Generation\u0027, \"Patrice B\\\\\u0027echard and Orlando Marquez Ayala\"):   A common and fundamental limitation of Generative AI (GenAI) is its\npropensity to hallucinate. While large language models (LLM) have taken the\nworld by storm, without eliminating or at least reducing hallucinations,\nreal-world GenAI systems may face challenges in user adoption. In the process\nof deploying an enterprise application that produces workflows based on natural\nlanguage requirements, we devised a system leveraging Retrieval Augmented\nGeneration (RAG) to greatly improve the quality of the structured output that\nrepresents such workflows. Thanks to our implementation of RAG, our proposed\nsystem significantly reduces hallucinations in the output and improves the\ngeneralization of our LLM in out-of-domain settings. In addition, we show that\nusing a small, well-trained retriever encoder can reduce the size of the\naccompanying LLM, thereby making deployments of LLM-based systems less\nresource-intensive.", "shape": "dot", "title": "Node: (\u0027Reducing hallucination in structured outputs via Retrieval-Augmented\\n  Generation\u0027, \"Patrice B\\\\\u0027echard and Orlando Marquez Ayala\"):   A common and fundamental limitation of Generative AI (GenAI) is its\npropensity to hallucinate. While large language models (LLM) have taken the\nworld by storm, without eliminating or at least reducing hallucinations,\nreal-world GenAI systems may face challenges in user adoption. In the process\nof deploying an enterprise application that produces workflows based on natural\nlanguage requirements, we devised a system leveraging Retrieval Augmented\nGeneration (RAG) to greatly improve the quality of the structured output that\nrepresents such workflows. Thanks to our implementation of RAG, our proposed\nsystem significantly reduces hallucinations in the output and improves the\ngeneralization of our LLM in out-of-domain settings. In addition, we show that\nusing a small, well-trained retriever encoder can reduce the size of the\naccompanying LLM, thereby making deployments of LLM-based systems less\nresource-intensive.\nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Survey on Retrieval-Augmented Text Generation for Large Language\\n  Models\u0027, \u0027Yizheng Huang and Jimmy Huang\u0027):   Retrieval-Augmented Generation (RAG) merges retrieval methods with deep\nlearning advancements to address the static limitations of large language\nmodels (LLMs) by enabling the dynamic integration of up-to-date external\ninformation. This methodology, focusing primarily on the text domain, provides\na cost-effective solution to the generation of plausible but possibly incorrect\nresponses by LLMs, thereby enhancing the accuracy and reliability of their\noutputs through the use of real-world data. As RAG grows in complexity and\nincorporates multiple concepts that can influence its performance, this paper\norganizes the RAG paradigm into four categories: pre-retrieval, retrieval,\npost-retrieval, and generation, offering a detailed perspective from the\nretrieval viewpoint. It outlines RAG\u0027s evolution and discusses the field\u0027s\nprogression through the analysis of significant studies. Additionally, the\npaper introduces evaluation methods for RAG, addressing the challenges faced\nand proposing future research directions. By offering an organized framework\nand categorization, the study aims to consolidate existing research on RAG,\nclarify its technological underpinnings, and highlight its potential to broaden\nthe adaptability and applications of LLMs.", "label": "(\u0027A Survey on Retrieval-Augmented Text Generation for Large Language\\n  Models\u0027, \u0027Yizheng Huang and Jimmy Huang\u0027):   Retrieval-Augmented Generation (RAG) merges retrieval methods with deep\nlearning advancements to address the static limitations of large language\nmodels (LLMs) by enabling the dynamic integration of up-to-date external\ninformation. This methodology, focusing primarily on the text domain, provides\na cost-effective solution to the generation of plausible but possibly incorrect\nresponses by LLMs, thereby enhancing the accuracy and reliability of their\noutputs through the use of real-world data. As RAG grows in complexity and\nincorporates multiple concepts that can influence its performance, this paper\norganizes the RAG paradigm into four categories: pre-retrieval, retrieval,\npost-retrieval, and generation, offering a detailed perspective from the\nretrieval viewpoint. It outlines RAG\u0027s evolution and discusses the field\u0027s\nprogression through the analysis of significant studies. Additionally, the\npaper introduces evaluation methods for RAG, addressing the challenges faced\nand proposing future research directions. By offering an organized framework\nand categorization, the study aims to consolidate existing research on RAG,\nclarify its technological underpinnings, and highlight its potential to broaden\nthe adaptability and applications of LLMs.", "shape": "dot", "title": "Node: (\u0027A Survey on Retrieval-Augmented Text Generation for Large Language\\n  Models\u0027, \u0027Yizheng Huang and Jimmy Huang\u0027):   Retrieval-Augmented Generation (RAG) merges retrieval methods with deep\nlearning advancements to address the static limitations of large language\nmodels (LLMs) by enabling the dynamic integration of up-to-date external\ninformation. This methodology, focusing primarily on the text domain, provides\na cost-effective solution to the generation of plausible but possibly incorrect\nresponses by LLMs, thereby enhancing the accuracy and reliability of their\noutputs through the use of real-world data. As RAG grows in complexity and\nincorporates multiple concepts that can influence its performance, this paper\norganizes the RAG paradigm into four categories: pre-retrieval, retrieval,\npost-retrieval, and generation, offering a detailed perspective from the\nretrieval viewpoint. It outlines RAG\u0027s evolution and discusses the field\u0027s\nprogression through the analysis of significant studies. Additionally, the\npaper introduces evaluation methods for RAG, addressing the challenges faced\nand proposing future research directions. By offering an organized framework\nand categorization, the study aims to consolidate existing research on RAG,\nclarify its technological underpinnings, and highlight its potential to broaden\nthe adaptability and applications of LLMs.\nPaper ID: 2404.10981\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation\u0027, \u0027Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe\\n  Liu, Xin Jin\u0027):   Retrieval-Augmented Generation (RAG) has shown significant improvements in\nvarious natural language processing tasks by integrating the strengths of large\nlanguage models (LLMs) and external knowledge databases. However, RAG\nintroduces long sequence generation and leads to high computation and memory\ncosts. We propose RAGCache, a novel multilevel dynamic caching system tailored\nfor RAG. Our analysis benchmarks current RAG systems, pinpointing the\nperformance bottleneck (i.e., long sequence due to knowledge injection) and\noptimization opportunities (i.e., caching knowledge\u0027s intermediate states).\nBased on these insights, we design RAGCache, which organizes the intermediate\nstates of retrieved knowledge in a knowledge tree and caches them in the GPU\nand host memory hierarchy. RAGCache proposes a replacement policy that is aware\nof LLM inference characteristics and RAG retrieval patterns. It also\ndynamically overlaps the retrieval and inference steps to minimize the\nend-to-end latency. We implement RAGCache and evaluate it on vLLM, a\nstate-of-the-art LLM inference system and Faiss, a state-of-the-art vector\ndatabase. The experimental results show that RAGCache reduces the time to first\ntoken (TTFT) by up to 4x and improves the throughput by up to 2.1x compared to\nvLLM integrated with Faiss.", "label": "(\u0027RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation\u0027, \u0027Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe\\n  Liu, Xin Jin\u0027):   Retrieval-Augmented Generation (RAG) has shown significant improvements in\nvarious natural language processing tasks by integrating the strengths of large\nlanguage models (LLMs) and external knowledge databases. However, RAG\nintroduces long sequence generation and leads to high computation and memory\ncosts. We propose RAGCache, a novel multilevel dynamic caching system tailored\nfor RAG. Our analysis benchmarks current RAG systems, pinpointing the\nperformance bottleneck (i.e., long sequence due to knowledge injection) and\noptimization opportunities (i.e., caching knowledge\u0027s intermediate states).\nBased on these insights, we design RAGCache, which organizes the intermediate\nstates of retrieved knowledge in a knowledge tree and caches them in the GPU\nand host memory hierarchy. RAGCache proposes a replacement policy that is aware\nof LLM inference characteristics and RAG retrieval patterns. It also\ndynamically overlaps the retrieval and inference steps to minimize the\nend-to-end latency. We implement RAGCache and evaluate it on vLLM, a\nstate-of-the-art LLM inference system and Faiss, a state-of-the-art vector\ndatabase. The experimental results show that RAGCache reduces the time to first\ntoken (TTFT) by up to 4x and improves the throughput by up to 2.1x compared to\nvLLM integrated with Faiss.", "shape": "dot", "title": "Node: (\u0027RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation\u0027, \u0027Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe\\n  Liu, Xin Jin\u0027):   Retrieval-Augmented Generation (RAG) has shown significant improvements in\nvarious natural language processing tasks by integrating the strengths of large\nlanguage models (LLMs) and external knowledge databases. However, RAG\nintroduces long sequence generation and leads to high computation and memory\ncosts. We propose RAGCache, a novel multilevel dynamic caching system tailored\nfor RAG. Our analysis benchmarks current RAG systems, pinpointing the\nperformance bottleneck (i.e., long sequence due to knowledge injection) and\noptimization opportunities (i.e., caching knowledge\u0027s intermediate states).\nBased on these insights, we design RAGCache, which organizes the intermediate\nstates of retrieved knowledge in a knowledge tree and caches them in the GPU\nand host memory hierarchy. RAGCache proposes a replacement policy that is aware\nof LLM inference characteristics and RAG retrieval patterns. It also\ndynamically overlaps the retrieval and inference steps to minimize the\nend-to-end latency. We implement RAGCache and evaluate it on vLLM, a\nstate-of-the-art LLM inference system and Faiss, a state-of-the-art vector\ndatabase. The experimental results show that RAGCache reduces the time to first\ntoken (TTFT) by up to 4x and improves the throughput by up to 2.1x compared to\nvLLM integrated with Faiss.\nPaper ID: 2404.12457\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural\\n  Language Processing\u0027, \u0027Yucheng Hu, Yuxing Lu\u0027):   Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey.", "label": "(\u0027RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural\\n  Language Processing\u0027, \u0027Yucheng Hu, Yuxing Lu\u0027):   Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey.", "shape": "dot", "title": "Node: (\u0027RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural\\n  Language Processing\u0027, \u0027Yucheng Hu, Yuxing Lu\u0027):   Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey.\nPaper ID: 2404.19543\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Towards a Search Engine for Machines: Unified Ranking for Multiple\\n  Retrieval-Augmented Large Language Models\u0027, \u0027Alireza Salemi, Hamed Zamani\u0027):   This paper introduces uRAG--a framework with a unified retrieval engine that\nserves multiple downstream retrieval-augmented generation (RAG) systems. Each\nRAG system consumes the retrieval results for a unique purpose, such as\nopen-domain question answering, fact verification, entity linking, and relation\nextraction. We introduce a generic training guideline that standardizes the\ncommunication between the search engine and the downstream RAG systems that\nengage in optimizing the retrieval model. This lays the groundwork for us to\nbuild a large-scale experimentation ecosystem consisting of 18 RAG systems that\nengage in training and 18 unknown RAG systems that use the uRAG as the new\nusers of the search engine. Using this experimentation ecosystem, we answer a\nnumber of fundamental research questions that improve our understanding of\npromises and challenges in developing search engines for machines.", "label": "(\u0027Towards a Search Engine for Machines: Unified Ranking for Multiple\\n  Retrieval-Augmented Large Language Models\u0027, \u0027Alireza Salemi, Hamed Zamani\u0027):   This paper introduces uRAG--a framework with a unified retrieval engine that\nserves multiple downstream retrieval-augmented generation (RAG) systems. Each\nRAG system consumes the retrieval results for a unique purpose, such as\nopen-domain question answering, fact verification, entity linking, and relation\nextraction. We introduce a generic training guideline that standardizes the\ncommunication between the search engine and the downstream RAG systems that\nengage in optimizing the retrieval model. This lays the groundwork for us to\nbuild a large-scale experimentation ecosystem consisting of 18 RAG systems that\nengage in training and 18 unknown RAG systems that use the uRAG as the new\nusers of the search engine. Using this experimentation ecosystem, we answer a\nnumber of fundamental research questions that improve our understanding of\npromises and challenges in developing search engines for machines.", "shape": "dot", "title": "Node: (\u0027Towards a Search Engine for Machines: Unified Ranking for Multiple\\n  Retrieval-Augmented Large Language Models\u0027, \u0027Alireza Salemi, Hamed Zamani\u0027):   This paper introduces uRAG--a framework with a unified retrieval engine that\nserves multiple downstream retrieval-augmented generation (RAG) systems. Each\nRAG system consumes the retrieval results for a unique purpose, such as\nopen-domain question answering, fact verification, entity linking, and relation\nextraction. We introduce a generic training guideline that standardizes the\ncommunication between the search engine and the downstream RAG systems that\nengage in optimizing the retrieval model. This lays the groundwork for us to\nbuild a large-scale experimentation ecosystem consisting of 18 RAG systems that\nengage in training and 18 unknown RAG systems that use the uRAG as the new\nusers of the search engine. Using this experimentation ecosystem, we answer a\nnumber of fundamental research questions that improve our understanding of\npromises and challenges in developing search engines for machines.\nPaper ID: 2405.00175\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027GAIA: A General AI Assistant for Intelligent Accelerator Operations\u0027, \u0027Frank Mayet\u0027):   Large-scale machines like particle accelerators are usually run by a team of\nexperienced operators. In case of a particle accelerator, these operators\npossess suitable background knowledge on both accelerator physics and the\ntechnology comprising the machine. Due to the complexity of the machine,\nparticular subsystems of the machine are taken care of by experts, who the\noperators can turn to. In this work the reasoning and action (ReAct) prompting\nparadigm is used to couple an open-weights large language model (LLM) with a\nhigh-level machine control system framework and other tools, e.g. the\nelectronic logbook or machine design documentation. By doing so, a multi-expert\nretrieval augmented generation (RAG) system is implemented, which assists\noperators in knowledge retrieval tasks, interacts with the machine directly if\nneeded, or writes high level control system scripts. This consolidation of\nexpert knowledge and machine interaction can simplify and speed up machine\noperation tasks for both new and experienced human operators.", "label": "(\u0027GAIA: A General AI Assistant for Intelligent Accelerator Operations\u0027, \u0027Frank Mayet\u0027):   Large-scale machines like particle accelerators are usually run by a team of\nexperienced operators. In case of a particle accelerator, these operators\npossess suitable background knowledge on both accelerator physics and the\ntechnology comprising the machine. Due to the complexity of the machine,\nparticular subsystems of the machine are taken care of by experts, who the\noperators can turn to. In this work the reasoning and action (ReAct) prompting\nparadigm is used to couple an open-weights large language model (LLM) with a\nhigh-level machine control system framework and other tools, e.g. the\nelectronic logbook or machine design documentation. By doing so, a multi-expert\nretrieval augmented generation (RAG) system is implemented, which assists\noperators in knowledge retrieval tasks, interacts with the machine directly if\nneeded, or writes high level control system scripts. This consolidation of\nexpert knowledge and machine interaction can simplify and speed up machine\noperation tasks for both new and experienced human operators.", "shape": "dot", "title": "Node: (\u0027GAIA: A General AI Assistant for Intelligent Accelerator Operations\u0027, \u0027Frank Mayet\u0027):   Large-scale machines like particle accelerators are usually run by a team of\nexperienced operators. In case of a particle accelerator, these operators\npossess suitable background knowledge on both accelerator physics and the\ntechnology comprising the machine. Due to the complexity of the machine,\nparticular subsystems of the machine are taken care of by experts, who the\noperators can turn to. In this work the reasoning and action (ReAct) prompting\nparadigm is used to couple an open-weights large language model (LLM) with a\nhigh-level machine control system framework and other tools, e.g. the\nelectronic logbook or machine design documentation. By doing so, a multi-expert\nretrieval augmented generation (RAG) system is implemented, which assists\noperators in knowledge retrieval tasks, interacts with the machine directly if\nneeded, or writes high level control system scripts. This consolidation of\nexpert knowledge and machine interaction can simplify and speed up machine\noperation tasks for both new and experienced human operators.\nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language\\n  Models\u0027, \u0027Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei\\n  Yin, Tat-Seng Chua, and Qing Li\u0027):   As one of the most advanced techniques in AI, Retrieval-Augmented Generation\n(RAG) can offer reliable and up-to-date external knowledge, providing huge\nconvenience for numerous tasks. Particularly in the era of AI-Generated Content\n(AIGC), the powerful capacity of retrieval in providing additional knowledge\nenables RAG to assist existing generative AI in producing high-quality outputs.\nRecently, Large Language Models (LLMs) have demonstrated revolutionary\nabilities in language understanding and generation, while still facing inherent\nlimitations, such as hallucinations and out-of-date internal knowledge. Given\nthe powerful abilities of RAG in providing the latest and helpful auxiliary\ninformation, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged\nto harness external and authoritative knowledge bases, rather than solely\nrelying on the model\u0027s internal knowledge, to augment the generation quality of\nLLMs. In this survey, we comprehensively review existing research studies in\nRA-LLMs, covering three primary technical perspectives: architectures, training\nstrategies, and applications. As the preliminary knowledge, we briefly\nintroduce the foundations and recent advances of LLMs. Then, to illustrate the\npractical significance of RAG for LLMs, we systematically review mainstream\nrelevant work by their architectures, training strategies, and application\nareas, detailing specifically the challenges of each and the corresponding\ncapabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss\ncurrent limitations and several promising directions for future research.\nUpdated information about this survey can be found at\nhttps://advanced-recommender-systems.github.io/RAG-Meets-LLMs/", "label": "(\u0027A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language\\n  Models\u0027, \u0027Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei\\n  Yin, Tat-Seng Chua, and Qing Li\u0027):   As one of the most advanced techniques in AI, Retrieval-Augmented Generation\n(RAG) can offer reliable and up-to-date external knowledge, providing huge\nconvenience for numerous tasks. Particularly in the era of AI-Generated Content\n(AIGC), the powerful capacity of retrieval in providing additional knowledge\nenables RAG to assist existing generative AI in producing high-quality outputs.\nRecently, Large Language Models (LLMs) have demonstrated revolutionary\nabilities in language understanding and generation, while still facing inherent\nlimitations, such as hallucinations and out-of-date internal knowledge. Given\nthe powerful abilities of RAG in providing the latest and helpful auxiliary\ninformation, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged\nto harness external and authoritative knowledge bases, rather than solely\nrelying on the model\u0027s internal knowledge, to augment the generation quality of\nLLMs. In this survey, we comprehensively review existing research studies in\nRA-LLMs, covering three primary technical perspectives: architectures, training\nstrategies, and applications. As the preliminary knowledge, we briefly\nintroduce the foundations and recent advances of LLMs. Then, to illustrate the\npractical significance of RAG for LLMs, we systematically review mainstream\nrelevant work by their architectures, training strategies, and application\nareas, detailing specifically the challenges of each and the corresponding\ncapabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss\ncurrent limitations and several promising directions for future research.\nUpdated information about this survey can be found at\nhttps://advanced-recommender-systems.github.io/RAG-Meets-LLMs/", "shape": "dot", "title": "Node: (\u0027A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language\\n  Models\u0027, \u0027Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei\\n  Yin, Tat-Seng Chua, and Qing Li\u0027):   As one of the most advanced techniques in AI, Retrieval-Augmented Generation\n(RAG) can offer reliable and up-to-date external knowledge, providing huge\nconvenience for numerous tasks. Particularly in the era of AI-Generated Content\n(AIGC), the powerful capacity of retrieval in providing additional knowledge\nenables RAG to assist existing generative AI in producing high-quality outputs.\nRecently, Large Language Models (LLMs) have demonstrated revolutionary\nabilities in language understanding and generation, while still facing inherent\nlimitations, such as hallucinations and out-of-date internal knowledge. Given\nthe powerful abilities of RAG in providing the latest and helpful auxiliary\ninformation, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged\nto harness external and authoritative knowledge bases, rather than solely\nrelying on the model\u0027s internal knowledge, to augment the generation quality of\nLLMs. In this survey, we comprehensively review existing research studies in\nRA-LLMs, covering three primary technical perspectives: architectures, training\nstrategies, and applications. As the preliminary knowledge, we briefly\nintroduce the foundations and recent advances of LLMs. Then, to illustrate the\npractical significance of RAG for LLMs, we systematically review mainstream\nrelevant work by their architectures, training strategies, and application\nareas, detailing specifically the challenges of each and the corresponding\ncapabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss\ncurrent limitations and several promising directions for future research.\nUpdated information about this survey can be found at\nhttps://advanced-recommender-systems.github.io/RAG-Meets-LLMs/\nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027, \u0027Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, Zhaofeng Liu\u0027):   Retrieval-Augmented Generation (RAG) has recently gained traction in natural\nlanguage processing. Numerous studies and real-world applications are\nleveraging its ability to enhance generative models through external\ninformation retrieval. Evaluating these RAG systems, however, poses unique\nchallenges due to their hybrid structure and reliance on dynamic knowledge\nsources. To better understand these challenges, we conduct A Unified Evaluation\nProcess of RAG (Auepora) and aim to provide a comprehensive overview of the\nevaluation and benchmarks of RAG systems. Specifically, we examine and compare\nseveral quantifiable metrics of the Retrieval and Generation components, such\nas relevance, accuracy, and faithfulness, within the current RAG benchmarks,\nencompassing the possible output and ground truth pairs. We then analyze the\nvarious datasets and metrics, discuss the limitations of current benchmarks,\nand suggest potential directions to advance the field of RAG benchmarks.", "label": "(\u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027, \u0027Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, Zhaofeng Liu\u0027):   Retrieval-Augmented Generation (RAG) has recently gained traction in natural\nlanguage processing. Numerous studies and real-world applications are\nleveraging its ability to enhance generative models through external\ninformation retrieval. Evaluating these RAG systems, however, poses unique\nchallenges due to their hybrid structure and reliance on dynamic knowledge\nsources. To better understand these challenges, we conduct A Unified Evaluation\nProcess of RAG (Auepora) and aim to provide a comprehensive overview of the\nevaluation and benchmarks of RAG systems. Specifically, we examine and compare\nseveral quantifiable metrics of the Retrieval and Generation components, such\nas relevance, accuracy, and faithfulness, within the current RAG benchmarks,\nencompassing the possible output and ground truth pairs. We then analyze the\nvarious datasets and metrics, discuss the limitations of current benchmarks,\nand suggest potential directions to advance the field of RAG benchmarks.", "shape": "dot", "title": "Node: (\u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027, \u0027Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, Zhaofeng Liu\u0027):   Retrieval-Augmented Generation (RAG) has recently gained traction in natural\nlanguage processing. Numerous studies and real-world applications are\nleveraging its ability to enhance generative models through external\ninformation retrieval. Evaluating these RAG systems, however, poses unique\nchallenges due to their hybrid structure and reliance on dynamic knowledge\nsources. To better understand these challenges, we conduct A Unified Evaluation\nProcess of RAG (Auepora) and aim to provide a comprehensive overview of the\nevaluation and benchmarks of RAG systems. Specifically, we examine and compare\nseveral quantifiable metrics of the Retrieval and Generation components, such\nas relevance, accuracy, and faithfulness, within the current RAG benchmarks,\nencompassing the possible output and ground truth pairs. We then analyze the\nvarious datasets and metrics, discuss the limitations of current benchmarks,\nand suggest potential directions to advance the field of RAG benchmarks.\nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Question-Based Retrieval using Atomic Units for Enterprise RAG\u0027, \u0027Vatsal Raina, Mark Gales\u0027):   Enterprise retrieval augmented generation (RAG) offers a highly flexible\nframework for combining powerful large language models (LLMs) with internal,\npossibly temporally changing, documents. In RAG, documents are first chunked.\nRelevant chunks are then retrieved for a user query, which are passed as\ncontext to a synthesizer LLM to generate the query response. However, the\nretrieval step can limit performance, as incorrect chunks can lead the\nsynthesizer LLM to generate a false response. This work applies a zero-shot\nadaptation of standard dense retrieval steps for more accurate chunk recall.\nSpecifically, a chunk is first decomposed into atomic statements. A set of\nsynthetic questions are then generated on these atoms (with the chunk as the\ncontext). Dense retrieval involves finding the closest set of synthetic\nquestions, and associated chunks, to the user query. It is found that retrieval\nwith the atoms leads to higher recall than retrieval with chunks. Further\nperformance gain is observed with retrieval using the synthetic questions\ngenerated over the atoms. Higher recall at the retrieval step enables higher\nperformance of the enterprise LLM using the RAG pipeline.", "label": "(\u0027Question-Based Retrieval using Atomic Units for Enterprise RAG\u0027, \u0027Vatsal Raina, Mark Gales\u0027):   Enterprise retrieval augmented generation (RAG) offers a highly flexible\nframework for combining powerful large language models (LLMs) with internal,\npossibly temporally changing, documents. In RAG, documents are first chunked.\nRelevant chunks are then retrieved for a user query, which are passed as\ncontext to a synthesizer LLM to generate the query response. However, the\nretrieval step can limit performance, as incorrect chunks can lead the\nsynthesizer LLM to generate a false response. This work applies a zero-shot\nadaptation of standard dense retrieval steps for more accurate chunk recall.\nSpecifically, a chunk is first decomposed into atomic statements. A set of\nsynthetic questions are then generated on these atoms (with the chunk as the\ncontext). Dense retrieval involves finding the closest set of synthetic\nquestions, and associated chunks, to the user query. It is found that retrieval\nwith the atoms leads to higher recall than retrieval with chunks. Further\nperformance gain is observed with retrieval using the synthetic questions\ngenerated over the atoms. Higher recall at the retrieval step enables higher\nperformance of the enterprise LLM using the RAG pipeline.", "shape": "dot", "title": "Node: (\u0027Question-Based Retrieval using Atomic Units for Enterprise RAG\u0027, \u0027Vatsal Raina, Mark Gales\u0027):   Enterprise retrieval augmented generation (RAG) offers a highly flexible\nframework for combining powerful large language models (LLMs) with internal,\npossibly temporally changing, documents. In RAG, documents are first chunked.\nRelevant chunks are then retrieved for a user query, which are passed as\ncontext to a synthesizer LLM to generate the query response. However, the\nretrieval step can limit performance, as incorrect chunks can lead the\nsynthesizer LLM to generate a false response. This work applies a zero-shot\nadaptation of standard dense retrieval steps for more accurate chunk recall.\nSpecifically, a chunk is first decomposed into atomic statements. A set of\nsynthetic questions are then generated on these atoms (with the chunk as the\ncontext). Dense retrieval involves finding the closest set of synthetic\nquestions, and associated chunks, to the user query. It is found that retrieval\nwith the atoms leads to higher recall than retrieval with chunks. Further\nperformance gain is observed with retrieval using the synthetic questions\ngenerated over the atoms. Higher recall at the retrieval step enables higher\nperformance of the enterprise LLM using the RAG pipeline.\nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027DuetRAG: Collaborative Retrieval-Augmented Generation\u0027, \u0027Dian Jiao, Li Cai, Jingsheng Huang, Wenqiao Zhang, Siliang Tang,\\n  Yueting Zhuang\u0027):   Retrieval-Augmented Generation (RAG) methods augment the input of Large\nLanguage Models (LLMs) with relevant retrieved passages, reducing factual\nerrors in knowledge-intensive tasks. However, contemporary RAG approaches\nsuffer from irrelevant knowledge retrieval issues in complex domain questions\n(e.g., HotPot QA) due to the lack of corresponding domain knowledge, leading to\nlow-quality generations. To address this issue, we propose a novel\nCollaborative Retrieval-Augmented Generation framework, DuetRAG. Our\nbootstrapping philosophy is to simultaneously integrate the domain fintuning\nand RAG models to improve the knowledge retrieval quality, thereby enhancing\ngeneration quality. Finally, we demonstrate DuetRAG\u0027 s matches with expert\nhuman researchers on HotPot QA.", "label": "(\u0027DuetRAG: Collaborative Retrieval-Augmented Generation\u0027, \u0027Dian Jiao, Li Cai, Jingsheng Huang, Wenqiao Zhang, Siliang Tang,\\n  Yueting Zhuang\u0027):   Retrieval-Augmented Generation (RAG) methods augment the input of Large\nLanguage Models (LLMs) with relevant retrieved passages, reducing factual\nerrors in knowledge-intensive tasks. However, contemporary RAG approaches\nsuffer from irrelevant knowledge retrieval issues in complex domain questions\n(e.g., HotPot QA) due to the lack of corresponding domain knowledge, leading to\nlow-quality generations. To address this issue, we propose a novel\nCollaborative Retrieval-Augmented Generation framework, DuetRAG. Our\nbootstrapping philosophy is to simultaneously integrate the domain fintuning\nand RAG models to improve the knowledge retrieval quality, thereby enhancing\ngeneration quality. Finally, we demonstrate DuetRAG\u0027 s matches with expert\nhuman researchers on HotPot QA.", "shape": "dot", "title": "Node: (\u0027DuetRAG: Collaborative Retrieval-Augmented Generation\u0027, \u0027Dian Jiao, Li Cai, Jingsheng Huang, Wenqiao Zhang, Siliang Tang,\\n  Yueting Zhuang\u0027):   Retrieval-Augmented Generation (RAG) methods augment the input of Large\nLanguage Models (LLMs) with relevant retrieved passages, reducing factual\nerrors in knowledge-intensive tasks. However, contemporary RAG approaches\nsuffer from irrelevant knowledge retrieval issues in complex domain questions\n(e.g., HotPot QA) due to the lack of corresponding domain knowledge, leading to\nlow-quality generations. To address this issue, we propose a novel\nCollaborative Retrieval-Augmented Generation framework, DuetRAG. Our\nbootstrapping philosophy is to simultaneously integrate the domain fintuning\nand RAG models to improve the knowledge retrieval quality, thereby enhancing\ngeneration quality. Finally, we demonstrate DuetRAG\u0027 s matches with expert\nhuman researchers on HotPot QA.\nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\\n  Research\u0027, \u0027Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang, Zhicheng Dou\u0027):   With the advent of Large Language Models (LLMs), the potential of Retrieval\nAugmented Generation (RAG) techniques have garnered considerable research\nattention. Numerous novel algorithms and models have been introduced to enhance\nvarious aspects of RAG systems. However, the absence of a standardized\nframework for implementation, coupled with the inherently intricate RAG\nprocess, makes it challenging and time-consuming for researchers to compare and\nevaluate these approaches in a consistent environment. Existing RAG toolkits\nlike LangChain and LlamaIndex, while available, are often heavy and unwieldy,\nfailing to meet the personalized needs of researchers. In response to this\nchallenge, we propose FlashRAG, an efficient and modular open-source toolkit\ndesigned to assist researchers in reproducing existing RAG methods and in\ndeveloping their own RAG algorithms within a unified framework. Our toolkit\nimplements 12 advanced RAG methods and has gathered and organized 32 benchmark\ndatasets. Our toolkit has various features, including customizable modular\nframework, rich collection of pre-implemented RAG works, comprehensive\ndatasets, efficient auxiliary pre-processing scripts, and extensive and\nstandard evaluation metrics. Our toolkit and resources are available at\nhttps://github.com/RUC-NLPIR/FlashRAG.", "label": "(\u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\\n  Research\u0027, \u0027Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang, Zhicheng Dou\u0027):   With the advent of Large Language Models (LLMs), the potential of Retrieval\nAugmented Generation (RAG) techniques have garnered considerable research\nattention. Numerous novel algorithms and models have been introduced to enhance\nvarious aspects of RAG systems. However, the absence of a standardized\nframework for implementation, coupled with the inherently intricate RAG\nprocess, makes it challenging and time-consuming for researchers to compare and\nevaluate these approaches in a consistent environment. Existing RAG toolkits\nlike LangChain and LlamaIndex, while available, are often heavy and unwieldy,\nfailing to meet the personalized needs of researchers. In response to this\nchallenge, we propose FlashRAG, an efficient and modular open-source toolkit\ndesigned to assist researchers in reproducing existing RAG methods and in\ndeveloping their own RAG algorithms within a unified framework. Our toolkit\nimplements 12 advanced RAG methods and has gathered and organized 32 benchmark\ndatasets. Our toolkit has various features, including customizable modular\nframework, rich collection of pre-implemented RAG works, comprehensive\ndatasets, efficient auxiliary pre-processing scripts, and extensive and\nstandard evaluation metrics. Our toolkit and resources are available at\nhttps://github.com/RUC-NLPIR/FlashRAG.", "shape": "dot", "title": "Node: (\u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\\n  Research\u0027, \u0027Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang, Zhicheng Dou\u0027):   With the advent of Large Language Models (LLMs), the potential of Retrieval\nAugmented Generation (RAG) techniques have garnered considerable research\nattention. Numerous novel algorithms and models have been introduced to enhance\nvarious aspects of RAG systems. However, the absence of a standardized\nframework for implementation, coupled with the inherently intricate RAG\nprocess, makes it challenging and time-consuming for researchers to compare and\nevaluate these approaches in a consistent environment. Existing RAG toolkits\nlike LangChain and LlamaIndex, while available, are often heavy and unwieldy,\nfailing to meet the personalized needs of researchers. In response to this\nchallenge, we propose FlashRAG, an efficient and modular open-source toolkit\ndesigned to assist researchers in reproducing existing RAG methods and in\ndeveloping their own RAG algorithms within a unified framework. Our toolkit\nimplements 12 advanced RAG methods and has gathered and organized 32 benchmark\ndatasets. Our toolkit has various features, including customizable modular\nframework, rich collection of pre-implemented RAG works, comprehensive\ndatasets, efficient auxiliary pre-processing scripts, and extensive and\nstandard evaluation metrics. Our toolkit and resources are available at\nhttps://github.com/RUC-NLPIR/FlashRAG.\nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Accelerating Inference of Retrieval-Augmented Generation via Sparse\\n  Context Selection\u0027, \u0027Yun Zhu, Jia-Chen Gu, Caitlin Sikora, Ho Ko, Yinxiao Liu, Chu-Cheng\\n  Lin, Lei Shu, Liangchen Luo, Lei Meng, Bang Liu, Jindong Chen\u0027):   Large language models (LLMs) augmented with retrieval exhibit robust\nperformance and extensive versatility by incorporating external contexts.\nHowever, the input length grows linearly in the number of retrieved documents,\ncausing a dramatic increase in latency. In this paper, we propose a novel\nparadigm named Sparse RAG, which seeks to cut computation costs through\nsparsity. Specifically, Sparse RAG encodes retrieved documents in parallel,\nwhich eliminates latency introduced by long-range attention of retrieved\ndocuments. Then, LLMs selectively decode the output by only attending to highly\nrelevant caches auto-regressively, which are chosen via prompting LLMs with\nspecial control tokens. It is notable that Sparse RAG combines the assessment\nof each individual document and the generation of the response into a single\nprocess. The designed sparse mechanism in a RAG system can facilitate the\nreduction of the number of documents loaded during decoding for accelerating\nthe inference of the RAG system. Additionally, filtering out undesirable\ncontexts enhances the model\u0027s focus on relevant context, inherently improving\nits generation quality. Evaluation results of two datasets show that Sparse RAG\ncan strike an optimal balance between generation quality and computational\nefficiency, demonstrating its generalizability across both short- and long-form\ngeneration tasks.", "label": "(\u0027Accelerating Inference of Retrieval-Augmented Generation via Sparse\\n  Context Selection\u0027, \u0027Yun Zhu, Jia-Chen Gu, Caitlin Sikora, Ho Ko, Yinxiao Liu, Chu-Cheng\\n  Lin, Lei Shu, Liangchen Luo, Lei Meng, Bang Liu, Jindong Chen\u0027):   Large language models (LLMs) augmented with retrieval exhibit robust\nperformance and extensive versatility by incorporating external contexts.\nHowever, the input length grows linearly in the number of retrieved documents,\ncausing a dramatic increase in latency. In this paper, we propose a novel\nparadigm named Sparse RAG, which seeks to cut computation costs through\nsparsity. Specifically, Sparse RAG encodes retrieved documents in parallel,\nwhich eliminates latency introduced by long-range attention of retrieved\ndocuments. Then, LLMs selectively decode the output by only attending to highly\nrelevant caches auto-regressively, which are chosen via prompting LLMs with\nspecial control tokens. It is notable that Sparse RAG combines the assessment\nof each individual document and the generation of the response into a single\nprocess. The designed sparse mechanism in a RAG system can facilitate the\nreduction of the number of documents loaded during decoding for accelerating\nthe inference of the RAG system. Additionally, filtering out undesirable\ncontexts enhances the model\u0027s focus on relevant context, inherently improving\nits generation quality. Evaluation results of two datasets show that Sparse RAG\ncan strike an optimal balance between generation quality and computational\nefficiency, demonstrating its generalizability across both short- and long-form\ngeneration tasks.", "shape": "dot", "title": "Node: (\u0027Accelerating Inference of Retrieval-Augmented Generation via Sparse\\n  Context Selection\u0027, \u0027Yun Zhu, Jia-Chen Gu, Caitlin Sikora, Ho Ko, Yinxiao Liu, Chu-Cheng\\n  Lin, Lei Shu, Liangchen Luo, Lei Meng, Bang Liu, Jindong Chen\u0027):   Large language models (LLMs) augmented with retrieval exhibit robust\nperformance and extensive versatility by incorporating external contexts.\nHowever, the input length grows linearly in the number of retrieved documents,\ncausing a dramatic increase in latency. In this paper, we propose a novel\nparadigm named Sparse RAG, which seeks to cut computation costs through\nsparsity. Specifically, Sparse RAG encodes retrieved documents in parallel,\nwhich eliminates latency introduced by long-range attention of retrieved\ndocuments. Then, LLMs selectively decode the output by only attending to highly\nrelevant caches auto-regressively, which are chosen via prompting LLMs with\nspecial control tokens. It is notable that Sparse RAG combines the assessment\nof each individual document and the generation of the response into a single\nprocess. The designed sparse mechanism in a RAG system can facilitate the\nreduction of the number of documents loaded during decoding for accelerating\nthe inference of the RAG system. Additionally, filtering out undesirable\ncontexts enhances the model\u0027s focus on relevant context, inherently improving\nits generation quality. Evaluation results of two datasets show that Sparse RAG\ncan strike an optimal balance between generation quality and computational\nefficiency, demonstrating its generalizability across both short- and long-form\ngeneration tasks.\nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027M-RAG: Reinforcing Large Language Model Performance through\\n  Retrieval-Augmented Generation with Multiple Partitions\u0027, \u0027Zheng Wang, Shu Xian Teo, Jieer Ouyang, Yongjun Xu, Wei Shi\u0027):   Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by\nretrieving relevant memories from an external database. However, existing RAG\nmethods typically organize all memories in a whole database, potentially\nlimiting focus on crucial memories and introducing noise. In this paper, we\nintroduce a multiple partition paradigm for RAG (called M-RAG), where each\ndatabase partition serves as a basic unit for RAG execution. Based on this\nparadigm, we propose a novel framework that leverages LLMs with Multi-Agent\nReinforcement Learning to optimize different language generation tasks\nexplicitly. Through comprehensive experiments conducted on seven datasets,\nspanning three language generation tasks and involving three distinct language\nmodel architectures, we confirm that M-RAG consistently outperforms various\nbaseline methods, achieving improvements of 11%, 8%, and 12% for text\nsummarization, machine translation, and dialogue generation, respectively.", "label": "(\u0027M-RAG: Reinforcing Large Language Model Performance through\\n  Retrieval-Augmented Generation with Multiple Partitions\u0027, \u0027Zheng Wang, Shu Xian Teo, Jieer Ouyang, Yongjun Xu, Wei Shi\u0027):   Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by\nretrieving relevant memories from an external database. However, existing RAG\nmethods typically organize all memories in a whole database, potentially\nlimiting focus on crucial memories and introducing noise. In this paper, we\nintroduce a multiple partition paradigm for RAG (called M-RAG), where each\ndatabase partition serves as a basic unit for RAG execution. Based on this\nparadigm, we propose a novel framework that leverages LLMs with Multi-Agent\nReinforcement Learning to optimize different language generation tasks\nexplicitly. Through comprehensive experiments conducted on seven datasets,\nspanning three language generation tasks and involving three distinct language\nmodel architectures, we confirm that M-RAG consistently outperforms various\nbaseline methods, achieving improvements of 11%, 8%, and 12% for text\nsummarization, machine translation, and dialogue generation, respectively.", "shape": "dot", "title": "Node: (\u0027M-RAG: Reinforcing Large Language Model Performance through\\n  Retrieval-Augmented Generation with Multiple Partitions\u0027, \u0027Zheng Wang, Shu Xian Teo, Jieer Ouyang, Yongjun Xu, Wei Shi\u0027):   Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by\nretrieving relevant memories from an external database. However, existing RAG\nmethods typically organize all memories in a whole database, potentially\nlimiting focus on crucial memories and introducing noise. In this paper, we\nintroduce a multiple partition paradigm for RAG (called M-RAG), where each\ndatabase partition serves as a basic unit for RAG execution. Based on this\nparadigm, we propose a novel framework that leverages LLMs with Multi-Agent\nReinforcement Learning to optimize different language generation tasks\nexplicitly. Through comprehensive experiments conducted on seven datasets,\nspanning three language generation tasks and involving three distinct language\nmodel architectures, we confirm that M-RAG consistently outperforms various\nbaseline methods, achieving improvements of 11%, 8%, and 12% for text\nsummarization, machine translation, and dialogue generation, respectively.\nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Two-layer retrieval augmented generation framework for low-resource\\n  medical question-answering: proof of concept using Reddit data\u0027, \u0027Sudeshna Das, Yao Ge, Yuting Guo, Swati Rajwal, JaMor Hairston, Jeanne\\n  Powell, Drew Walker, Snigdha Peddireddy, Sahithi Lakamana, Selen Bozkurt,\\n  Matthew Reyna, Reza Sameni, Yunyu Xiao, Sangmi Kim, Rasheeta Chandler,\\n  Natalie Hernandez, Danielle Mowery, Rachel Wightman, Jennifer Love, Anthony\\n  Spadaro, Jeanmarie Perrone, Abeed Sarker\u0027):   Retrieval augmented generation (RAG) provides the capability to constrain\ngenerative model outputs, and mitigate the possibility of hallucination, by\nproviding relevant in-context text. The number of tokens a generative large\nlanguage model (LLM) can incorporate as context is finite, thus limiting the\nvolume of knowledge from which to generate an answer. We propose a two-layer\nRAG framework for query-focused answer generation and evaluate a\nproof-of-concept for this framework in the context of query-focused summary\ngeneration from social media forums, focusing on emerging drug-related\ninformation. The evaluations demonstrate the effectiveness of the two-layer\nframework in resource constrained settings to enable researchers in obtaining\nnear real-time data from users.", "label": "(\u0027Two-layer retrieval augmented generation framework for low-resource\\n  medical question-answering: proof of concept using Reddit data\u0027, \u0027Sudeshna Das, Yao Ge, Yuting Guo, Swati Rajwal, JaMor Hairston, Jeanne\\n  Powell, Drew Walker, Snigdha Peddireddy, Sahithi Lakamana, Selen Bozkurt,\\n  Matthew Reyna, Reza Sameni, Yunyu Xiao, Sangmi Kim, Rasheeta Chandler,\\n  Natalie Hernandez, Danielle Mowery, Rachel Wightman, Jennifer Love, Anthony\\n  Spadaro, Jeanmarie Perrone, Abeed Sarker\u0027):   Retrieval augmented generation (RAG) provides the capability to constrain\ngenerative model outputs, and mitigate the possibility of hallucination, by\nproviding relevant in-context text. The number of tokens a generative large\nlanguage model (LLM) can incorporate as context is finite, thus limiting the\nvolume of knowledge from which to generate an answer. We propose a two-layer\nRAG framework for query-focused answer generation and evaluate a\nproof-of-concept for this framework in the context of query-focused summary\ngeneration from social media forums, focusing on emerging drug-related\ninformation. The evaluations demonstrate the effectiveness of the two-layer\nframework in resource constrained settings to enable researchers in obtaining\nnear real-time data from users.", "shape": "dot", "title": "Node: (\u0027Two-layer retrieval augmented generation framework for low-resource\\n  medical question-answering: proof of concept using Reddit data\u0027, \u0027Sudeshna Das, Yao Ge, Yuting Guo, Swati Rajwal, JaMor Hairston, Jeanne\\n  Powell, Drew Walker, Snigdha Peddireddy, Sahithi Lakamana, Selen Bozkurt,\\n  Matthew Reyna, Reza Sameni, Yunyu Xiao, Sangmi Kim, Rasheeta Chandler,\\n  Natalie Hernandez, Danielle Mowery, Rachel Wightman, Jennifer Love, Anthony\\n  Spadaro, Jeanmarie Perrone, Abeed Sarker\u0027):   Retrieval augmented generation (RAG) provides the capability to constrain\ngenerative model outputs, and mitigate the possibility of hallucination, by\nproviding relevant in-context text. The number of tokens a generative large\nlanguage model (LLM) can incorporate as context is finite, thus limiting the\nvolume of knowledge from which to generate an answer. We propose a two-layer\nRAG framework for query-focused answer generation and evaluate a\nproof-of-concept for this framework in the context of query-focused summary\ngeneration from social media forums, focusing on emerging drug-related\ninformation. The evaluations demonstrate the effectiveness of the two-layer\nframework in resource constrained settings to enable researchers in obtaining\nnear real-time data from users.\nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for\\n  Retrieval-Augmented Large Language Models\u0027, \u0027Yutao Zhu, Zhaoheng Huang, Zhicheng Dou, Ji-Rong Wen\u0027):   Retrieval-augmented generation (RAG) is a promising way to improve large\nlanguage models (LLMs) for generating more factual, accurate, and up-to-date\ncontent. Existing methods either optimize prompts to guide LLMs in leveraging\nretrieved information or directly fine-tune LLMs to adapt to RAG scenarios.\nAlthough fine-tuning can yield better performance, it often compromises the\nLLMs\u0027 general generation capabilities by modifying their parameters. This\nlimitation poses challenges in practical applications, especially when LLMs are\nalready deployed, as parameter adjustments may affect their original\nfunctionality. To address this, we propose a novel method that involves\nlearning scalable and pluggable virtual tokens for RAG. By maintaining the\nLLMs\u0027 original parameters and fine-tuning only the embeddings of these\npluggable tokens, our approach not only enhances LLMs\u0027 performance but also\npreserves their general generation capabilities. Furthermore, we design several\ntraining strategies to improve the scalability, flexibility, and\ngeneralizability of our method. Comprehensive experiments across nine\nquestion-answering tasks demonstrate the superiority of our approach.", "label": "(\u0027One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for\\n  Retrieval-Augmented Large Language Models\u0027, \u0027Yutao Zhu, Zhaoheng Huang, Zhicheng Dou, Ji-Rong Wen\u0027):   Retrieval-augmented generation (RAG) is a promising way to improve large\nlanguage models (LLMs) for generating more factual, accurate, and up-to-date\ncontent. Existing methods either optimize prompts to guide LLMs in leveraging\nretrieved information or directly fine-tune LLMs to adapt to RAG scenarios.\nAlthough fine-tuning can yield better performance, it often compromises the\nLLMs\u0027 general generation capabilities by modifying their parameters. This\nlimitation poses challenges in practical applications, especially when LLMs are\nalready deployed, as parameter adjustments may affect their original\nfunctionality. To address this, we propose a novel method that involves\nlearning scalable and pluggable virtual tokens for RAG. By maintaining the\nLLMs\u0027 original parameters and fine-tuning only the embeddings of these\npluggable tokens, our approach not only enhances LLMs\u0027 performance but also\npreserves their general generation capabilities. Furthermore, we design several\ntraining strategies to improve the scalability, flexibility, and\ngeneralizability of our method. Comprehensive experiments across nine\nquestion-answering tasks demonstrate the superiority of our approach.", "shape": "dot", "title": "Node: (\u0027One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for\\n  Retrieval-Augmented Large Language Models\u0027, \u0027Yutao Zhu, Zhaoheng Huang, Zhicheng Dou, Ji-Rong Wen\u0027):   Retrieval-augmented generation (RAG) is a promising way to improve large\nlanguage models (LLMs) for generating more factual, accurate, and up-to-date\ncontent. Existing methods either optimize prompts to guide LLMs in leveraging\nretrieved information or directly fine-tune LLMs to adapt to RAG scenarios.\nAlthough fine-tuning can yield better performance, it often compromises the\nLLMs\u0027 general generation capabilities by modifying their parameters. This\nlimitation poses challenges in practical applications, especially when LLMs are\nalready deployed, as parameter adjustments may affect their original\nfunctionality. To address this, we propose a novel method that involves\nlearning scalable and pluggable virtual tokens for RAG. By maintaining the\nLLMs\u0027 original parameters and fine-tuning only the embeddings of these\npluggable tokens, our approach not only enhances LLMs\u0027 performance but also\npreserves their general generation capabilities. Furthermore, we design several\ntraining strategies to improve the scalability, flexibility, and\ngeneralizability of our method. Comprehensive experiments across nine\nquestion-answering tasks demonstrate the superiority of our approach.\nPaper ID: 2405.1967\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A + B: A General Generator-Reader Framework for Optimizing LLMs to\\n  Unleash Synergy Potential\u0027, \u0027Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao,\\n  Pengyuan Zhou\u0027):   Retrieval-Augmented Generation (RAG) is an effective solution to supplement\nnecessary knowledge to large language models (LLMs). Targeting its bottleneck\nof retriever performance, \"generate-then-read\" pipeline is proposed to replace\nthe retrieval stage with generation from the LLM itself. Although promising,\nthis research direction is underexplored and still cannot work in the scenario\nwhen source knowledge is given. In this paper, we formalize a general \"A + B\"\nframework with varying combinations of foundation models and types for\nsystematic investigation. We explore the efficacy of the base and chat versions\nof LLMs and found their different functionalities suitable for generator A and\nreader B, respectively. Their combinations consistently outperform single\nmodels, especially in complex scenarios. Furthermore, we extend the application\nof the \"A + B\" framework to scenarios involving source documents through\ncontinuous learning, enabling the direct integration of external knowledge into\nLLMs. This approach not only facilitates effective acquisition of new knowledge\nbut also addresses the challenges of safety and helpfulness post-adaptation.\nThe paper underscores the versatility of the \"A + B\" framework, demonstrating\nits potential to enhance the practical application of LLMs across various\ndomains.", "label": "(\u0027A + B: A General Generator-Reader Framework for Optimizing LLMs to\\n  Unleash Synergy Potential\u0027, \u0027Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao,\\n  Pengyuan Zhou\u0027):   Retrieval-Augmented Generation (RAG) is an effective solution to supplement\nnecessary knowledge to large language models (LLMs). Targeting its bottleneck\nof retriever performance, \"generate-then-read\" pipeline is proposed to replace\nthe retrieval stage with generation from the LLM itself. Although promising,\nthis research direction is underexplored and still cannot work in the scenario\nwhen source knowledge is given. In this paper, we formalize a general \"A + B\"\nframework with varying combinations of foundation models and types for\nsystematic investigation. We explore the efficacy of the base and chat versions\nof LLMs and found their different functionalities suitable for generator A and\nreader B, respectively. Their combinations consistently outperform single\nmodels, especially in complex scenarios. Furthermore, we extend the application\nof the \"A + B\" framework to scenarios involving source documents through\ncontinuous learning, enabling the direct integration of external knowledge into\nLLMs. This approach not only facilitates effective acquisition of new knowledge\nbut also addresses the challenges of safety and helpfulness post-adaptation.\nThe paper underscores the versatility of the \"A + B\" framework, demonstrating\nits potential to enhance the practical application of LLMs across various\ndomains.", "shape": "dot", "title": "Node: (\u0027A + B: A General Generator-Reader Framework for Optimizing LLMs to\\n  Unleash Synergy Potential\u0027, \u0027Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao,\\n  Pengyuan Zhou\u0027):   Retrieval-Augmented Generation (RAG) is an effective solution to supplement\nnecessary knowledge to large language models (LLMs). Targeting its bottleneck\nof retriever performance, \"generate-then-read\" pipeline is proposed to replace\nthe retrieval stage with generation from the LLM itself. Although promising,\nthis research direction is underexplored and still cannot work in the scenario\nwhen source knowledge is given. In this paper, we formalize a general \"A + B\"\nframework with varying combinations of foundation models and types for\nsystematic investigation. We explore the efficacy of the base and chat versions\nof LLMs and found their different functionalities suitable for generator A and\nreader B, respectively. Their combinations consistently outperform single\nmodels, especially in complex scenarios. Furthermore, we extend the application\nof the \"A + B\" framework to scenarios involving source documents through\ncontinuous learning, enabling the direct integration of external knowledge into\nLLMs. This approach not only facilitates effective acquisition of new knowledge\nbut also addresses the challenges of safety and helpfulness post-adaptation.\nThe paper underscores the versatility of the \"A + B\" framework, demonstrating\nits potential to enhance the practical application of LLMs across various\ndomains.\nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Multi-Head RAG: Solving Multi-Aspect Problems with LLMs\u0027, \u0027Maciej Besta, Ales Kubicek, Roman Niggli, Robert Gerstenberger, Lucas\\n  Weitzendorf, Mingyuan Chi, Patrick Iff, Joanna Gajda, Piotr Nyczyk, J\\\\\"urgen\\n  M\\\\\"uller, Hubert Niewiadomski, Marcin Chrapek, Micha{\\\\l} Podstawski, Torsten\\n  Hoefler\u0027):   Retrieval Augmented Generation (RAG) enhances the abilities of Large Language\nModels (LLMs) by enabling the retrieval of documents into the LLM context to\nprovide more accurate and relevant responses. Existing RAG solutions do not\nfocus on queries that may require fetching multiple documents with\nsubstantially different contents. Such queries occur frequently, but are\nchallenging because the embeddings of these documents may be distant in the\nembedding space, making it hard to retrieve them all. This paper introduces\nMulti-Head RAG (MRAG), a novel scheme designed to address this gap with a\nsimple yet powerful idea: leveraging activations of Transformer\u0027s multi-head\nattention layer, instead of the decoder layer, as keys for fetching\nmulti-aspect documents. The driving motivation is that different attention\nheads can learn to capture different data aspects. Harnessing the corresponding\nactivations results in embeddings that represent various facets of data items\nand queries, improving the retrieval accuracy for complex queries. We provide\nan evaluation methodology and metrics, synthetic datasets, and real-world use\ncases to demonstrate MRAG\u0027s effectiveness, showing improvements of up to 20% in\nrelevance over standard RAG baselines. MRAG can be seamlessly integrated with\nexisting RAG frameworks and benchmarking tools like RAGAS as well as different\nclasses of data stores.", "label": "(\u0027Multi-Head RAG: Solving Multi-Aspect Problems with LLMs\u0027, \u0027Maciej Besta, Ales Kubicek, Roman Niggli, Robert Gerstenberger, Lucas\\n  Weitzendorf, Mingyuan Chi, Patrick Iff, Joanna Gajda, Piotr Nyczyk, J\\\\\"urgen\\n  M\\\\\"uller, Hubert Niewiadomski, Marcin Chrapek, Micha{\\\\l} Podstawski, Torsten\\n  Hoefler\u0027):   Retrieval Augmented Generation (RAG) enhances the abilities of Large Language\nModels (LLMs) by enabling the retrieval of documents into the LLM context to\nprovide more accurate and relevant responses. Existing RAG solutions do not\nfocus on queries that may require fetching multiple documents with\nsubstantially different contents. Such queries occur frequently, but are\nchallenging because the embeddings of these documents may be distant in the\nembedding space, making it hard to retrieve them all. This paper introduces\nMulti-Head RAG (MRAG), a novel scheme designed to address this gap with a\nsimple yet powerful idea: leveraging activations of Transformer\u0027s multi-head\nattention layer, instead of the decoder layer, as keys for fetching\nmulti-aspect documents. The driving motivation is that different attention\nheads can learn to capture different data aspects. Harnessing the corresponding\nactivations results in embeddings that represent various facets of data items\nand queries, improving the retrieval accuracy for complex queries. We provide\nan evaluation methodology and metrics, synthetic datasets, and real-world use\ncases to demonstrate MRAG\u0027s effectiveness, showing improvements of up to 20% in\nrelevance over standard RAG baselines. MRAG can be seamlessly integrated with\nexisting RAG frameworks and benchmarking tools like RAGAS as well as different\nclasses of data stores.", "shape": "dot", "title": "Node: (\u0027Multi-Head RAG: Solving Multi-Aspect Problems with LLMs\u0027, \u0027Maciej Besta, Ales Kubicek, Roman Niggli, Robert Gerstenberger, Lucas\\n  Weitzendorf, Mingyuan Chi, Patrick Iff, Joanna Gajda, Piotr Nyczyk, J\\\\\"urgen\\n  M\\\\\"uller, Hubert Niewiadomski, Marcin Chrapek, Micha{\\\\l} Podstawski, Torsten\\n  Hoefler\u0027):   Retrieval Augmented Generation (RAG) enhances the abilities of Large Language\nModels (LLMs) by enabling the retrieval of documents into the LLM context to\nprovide more accurate and relevant responses. Existing RAG solutions do not\nfocus on queries that may require fetching multiple documents with\nsubstantially different contents. Such queries occur frequently, but are\nchallenging because the embeddings of these documents may be distant in the\nembedding space, making it hard to retrieve them all. This paper introduces\nMulti-Head RAG (MRAG), a novel scheme designed to address this gap with a\nsimple yet powerful idea: leveraging activations of Transformer\u0027s multi-head\nattention layer, instead of the decoder layer, as keys for fetching\nmulti-aspect documents. The driving motivation is that different attention\nheads can learn to capture different data aspects. Harnessing the corresponding\nactivations results in embeddings that represent various facets of data items\nand queries, improving the retrieval accuracy for complex queries. We provide\nan evaluation methodology and metrics, synthetic datasets, and real-world use\ncases to demonstrate MRAG\u0027s effectiveness, showing improvements of up to 20% in\nrelevance over standard RAG baselines. MRAG can be seamlessly integrated with\nexisting RAG frameworks and benchmarking tools like RAGAS as well as different\nclasses of data stores.\nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented\\n  Generation for Question-Answering\u0027, \u0027Zijian Hei and Weiling Liu and Wenjie Ou and Juyi Qiao and Junming\\n  Jiao and Guowen Song and Ting Tian and Yi Lin\u0027):   Retrieval-Augmented Generation (RAG) has recently demonstrated the\nperformance of Large Language Models (LLMs) in the knowledge-intensive tasks\nsuch as Question-Answering (QA). RAG expands the query context by incorporating\nexternal knowledge bases to enhance the response accuracy. However, it would be\ninefficient to access LLMs multiple times for each query and unreliable to\nretrieve all the relevant documents by a single query. We have found that even\nthough there is low relevance between some critical documents and query, it is\npossible to retrieve the remaining documents by combining parts of the\ndocuments with the query. To mine the relevance, a two-stage retrieval\nframework called Dynamic-Relevant Retrieval-Augmented Generation (DR-RAG) is\nproposed to improve document retrieval recall and the accuracy of answers while\nmaintaining efficiency. Additionally, a compact classifier is applied to two\ndifferent selection strategies to determine the contribution of the retrieved\ndocuments to answering the query and retrieve the relatively relevant\ndocuments. Meanwhile, DR-RAG call the LLMs only once, which significantly\nimproves the efficiency of the experiment. The experimental results on\nmulti-hop QA datasets show that DR-RAG can significantly improve the accuracy\nof the answers and achieve new progress in QA systems.", "label": "(\u0027DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented\\n  Generation for Question-Answering\u0027, \u0027Zijian Hei and Weiling Liu and Wenjie Ou and Juyi Qiao and Junming\\n  Jiao and Guowen Song and Ting Tian and Yi Lin\u0027):   Retrieval-Augmented Generation (RAG) has recently demonstrated the\nperformance of Large Language Models (LLMs) in the knowledge-intensive tasks\nsuch as Question-Answering (QA). RAG expands the query context by incorporating\nexternal knowledge bases to enhance the response accuracy. However, it would be\ninefficient to access LLMs multiple times for each query and unreliable to\nretrieve all the relevant documents by a single query. We have found that even\nthough there is low relevance between some critical documents and query, it is\npossible to retrieve the remaining documents by combining parts of the\ndocuments with the query. To mine the relevance, a two-stage retrieval\nframework called Dynamic-Relevant Retrieval-Augmented Generation (DR-RAG) is\nproposed to improve document retrieval recall and the accuracy of answers while\nmaintaining efficiency. Additionally, a compact classifier is applied to two\ndifferent selection strategies to determine the contribution of the retrieved\ndocuments to answering the query and retrieve the relatively relevant\ndocuments. Meanwhile, DR-RAG call the LLMs only once, which significantly\nimproves the efficiency of the experiment. The experimental results on\nmulti-hop QA datasets show that DR-RAG can significantly improve the accuracy\nof the answers and achieve new progress in QA systems.", "shape": "dot", "title": "Node: (\u0027DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented\\n  Generation for Question-Answering\u0027, \u0027Zijian Hei and Weiling Liu and Wenjie Ou and Juyi Qiao and Junming\\n  Jiao and Guowen Song and Ting Tian and Yi Lin\u0027):   Retrieval-Augmented Generation (RAG) has recently demonstrated the\nperformance of Large Language Models (LLMs) in the knowledge-intensive tasks\nsuch as Question-Answering (QA). RAG expands the query context by incorporating\nexternal knowledge bases to enhance the response accuracy. However, it would be\ninefficient to access LLMs multiple times for each query and unreliable to\nretrieve all the relevant documents by a single query. We have found that even\nthough there is low relevance between some critical documents and query, it is\npossible to retrieve the remaining documents by combining parts of the\ndocuments with the query. To mine the relevance, a two-stage retrieval\nframework called Dynamic-Relevant Retrieval-Augmented Generation (DR-RAG) is\nproposed to improve document retrieval recall and the accuracy of answers while\nmaintaining efficiency. Additionally, a compact classifier is applied to two\ndifferent selection strategies to determine the contribution of the retrieved\ndocuments to answering the query and retrieve the relatively relevant\ndocuments. Meanwhile, DR-RAG call the LLMs only once, which significantly\nimproves the efficiency of the experiment. The experimental results on\nmulti-hop QA datasets show that DR-RAG can significantly improve the accuracy\nof the answers and achieve new progress in QA systems.\nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Fine-Tuning or Fine-Failing? Debunking Performance Myths in Large\\n  Language Models\u0027, \u0027Scott Barnett, Zac Brannelly, Stefanus Kurniawan, Sheng Wong\u0027):   Large Language Models (LLMs) have the unique capability to understand and\ngenerate human-like text from input queries. When fine-tuned, these models show\nenhanced performance on domain-specific queries. OpenAI highlights the process\nof fine-tuning, stating: \"To fine-tune a model, you are required to provide at\nleast 10 examples. We typically see clear improvements from fine-tuning on 50\nto 100 training examples, but the right number varies greatly based on the\nexact use case.\" This study extends this concept to the integration of LLMs\nwithin Retrieval-Augmented Generation (RAG) pipelines, which aim to improve\naccuracy and relevance by leveraging external corpus data for information\nretrieval. However, RAG\u0027s promise of delivering optimal responses often falls\nshort in complex query scenarios. This study aims to specifically examine the\neffects of fine-tuning LLMs on their ability to extract and integrate\ncontextual data to enhance the performance of RAG systems across multiple\ndomains. We evaluate the impact of fine-tuning on the LLMs\u0027 capacity for data\nextraction and contextual understanding by comparing the accuracy and\ncompleteness of fine-tuned models against baseline performances across datasets\nfrom multiple domains. Our findings indicate that fine-tuning resulted in a\ndecline in performance compared to the baseline models, contrary to the\nimprovements observed in standalone LLM applications as suggested by OpenAI.\nThis study highlights the need for vigorous investigation and validation of\nfine-tuned models for domain-specific tasks.", "label": "(\u0027Fine-Tuning or Fine-Failing? Debunking Performance Myths in Large\\n  Language Models\u0027, \u0027Scott Barnett, Zac Brannelly, Stefanus Kurniawan, Sheng Wong\u0027):   Large Language Models (LLMs) have the unique capability to understand and\ngenerate human-like text from input queries. When fine-tuned, these models show\nenhanced performance on domain-specific queries. OpenAI highlights the process\nof fine-tuning, stating: \"To fine-tune a model, you are required to provide at\nleast 10 examples. We typically see clear improvements from fine-tuning on 50\nto 100 training examples, but the right number varies greatly based on the\nexact use case.\" This study extends this concept to the integration of LLMs\nwithin Retrieval-Augmented Generation (RAG) pipelines, which aim to improve\naccuracy and relevance by leveraging external corpus data for information\nretrieval. However, RAG\u0027s promise of delivering optimal responses often falls\nshort in complex query scenarios. This study aims to specifically examine the\neffects of fine-tuning LLMs on their ability to extract and integrate\ncontextual data to enhance the performance of RAG systems across multiple\ndomains. We evaluate the impact of fine-tuning on the LLMs\u0027 capacity for data\nextraction and contextual understanding by comparing the accuracy and\ncompleteness of fine-tuned models against baseline performances across datasets\nfrom multiple domains. Our findings indicate that fine-tuning resulted in a\ndecline in performance compared to the baseline models, contrary to the\nimprovements observed in standalone LLM applications as suggested by OpenAI.\nThis study highlights the need for vigorous investigation and validation of\nfine-tuned models for domain-specific tasks.", "shape": "dot", "title": "Node: (\u0027Fine-Tuning or Fine-Failing? Debunking Performance Myths in Large\\n  Language Models\u0027, \u0027Scott Barnett, Zac Brannelly, Stefanus Kurniawan, Sheng Wong\u0027):   Large Language Models (LLMs) have the unique capability to understand and\ngenerate human-like text from input queries. When fine-tuned, these models show\nenhanced performance on domain-specific queries. OpenAI highlights the process\nof fine-tuning, stating: \"To fine-tune a model, you are required to provide at\nleast 10 examples. We typically see clear improvements from fine-tuning on 50\nto 100 training examples, but the right number varies greatly based on the\nexact use case.\" This study extends this concept to the integration of LLMs\nwithin Retrieval-Augmented Generation (RAG) pipelines, which aim to improve\naccuracy and relevance by leveraging external corpus data for information\nretrieval. However, RAG\u0027s promise of delivering optimal responses often falls\nshort in complex query scenarios. This study aims to specifically examine the\neffects of fine-tuning LLMs on their ability to extract and integrate\ncontextual data to enhance the performance of RAG systems across multiple\ndomains. We evaluate the impact of fine-tuning on the LLMs\u0027 capacity for data\nextraction and contextual understanding by comparing the accuracy and\ncompleteness of fine-tuned models against baseline performances across datasets\nfrom multiple domains. Our findings indicate that fine-tuning resulted in a\ndecline in performance compared to the baseline models, contrary to the\nimprovements observed in standalone LLM applications as suggested by OpenAI.\nThis study highlights the need for vigorous investigation and validation of\nfine-tuned models for domain-specific tasks.\nPaper ID: 2406.11201\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG\\n  Systems: A Comparative Study of Performance and Scalability\u0027, \u0027Gautam B and Anupam Purwar\u0027):   This paper presents an analysis of open-source large language models (LLMs)\nand their application in Retrieval-Augmented Generation (RAG) tasks, specific\nfor enterprise-specific data sets scraped from their websites. With the\nincreasing reliance on LLMs in natural language processing, it is crucial to\nevaluate their performance, accessibility, and integration within specific\norganizational contexts. This study examines various open-source LLMs, explores\ntheir integration into RAG frameworks using enterprise-specific data, and\nassesses the performance of different open-source embeddings in enhancing the\nretrieval and generation process. Our findings indicate that open-source LLMs,\ncombined with effective embedding techniques, can significantly improve the\naccuracy and efficiency of RAG systems, offering a viable alternative to\nproprietary solutions for enterprises.", "label": "(\u0027Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG\\n  Systems: A Comparative Study of Performance and Scalability\u0027, \u0027Gautam B and Anupam Purwar\u0027):   This paper presents an analysis of open-source large language models (LLMs)\nand their application in Retrieval-Augmented Generation (RAG) tasks, specific\nfor enterprise-specific data sets scraped from their websites. With the\nincreasing reliance on LLMs in natural language processing, it is crucial to\nevaluate their performance, accessibility, and integration within specific\norganizational contexts. This study examines various open-source LLMs, explores\ntheir integration into RAG frameworks using enterprise-specific data, and\nassesses the performance of different open-source embeddings in enhancing the\nretrieval and generation process. Our findings indicate that open-source LLMs,\ncombined with effective embedding techniques, can significantly improve the\naccuracy and efficiency of RAG systems, offering a viable alternative to\nproprietary solutions for enterprises.", "shape": "dot", "title": "Node: (\u0027Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG\\n  Systems: A Comparative Study of Performance and Scalability\u0027, \u0027Gautam B and Anupam Purwar\u0027):   This paper presents an analysis of open-source large language models (LLMs)\nand their application in Retrieval-Augmented Generation (RAG) tasks, specific\nfor enterprise-specific data sets scraped from their websites. With the\nincreasing reliance on LLMs in natural language processing, it is crucial to\nevaluate their performance, accessibility, and integration within specific\norganizational contexts. This study examines various open-source LLMs, explores\ntheir integration into RAG frameworks using enterprise-specific data, and\nassesses the performance of different open-source embeddings in enhancing the\nretrieval and generation process. Our findings indicate that open-source LLMs,\ncombined with effective embedding techniques, can significantly improve the\naccuracy and efficiency of RAG systems, offering a viable alternative to\nproprietary solutions for enterprises.\nPaper ID: 2406.11424\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Towards Unlocking Insights from Logbooks Using AI\u0027, \u0027Antonin Sulc, Alex Bien, Annika Eichler, Daniel Ratner, Florian Rehm,\\n  Frank Mayet, Gregor Hartmann, Hayden Hoschouer, Henrik Tuennermann, Jan\\n  Kaiser, Jason St. John, Jennefer Maldonado, Kyle Hazelwood, Raimund\\n  Kammering, Thorsten Hellert, Tim Wilksen, Verena Kain, Wan-Lin Hu\u0027):   Electronic logbooks contain valuable information about activities and events\nconcerning their associated particle accelerator facilities. However, the\nhighly technical nature of logbook entries can hinder their usability and\nautomation. As natural language processing (NLP) continues advancing, it offers\nopportunities to address various challenges that logbooks present. This work\nexplores jointly testing a tailored Retrieval Augmented Generation (RAG) model\nfor enhancing the usability of particle accelerator logbooks at institutes like\nDESY, BESSY, Fermilab, BNL, SLAC, LBNL, and CERN. The RAG model uses a corpus\nbuilt on logbook contributions and aims to unlock insights from these logbooks\nby leveraging retrieval over facility datasets, including discussion about\npotential multimodal sources. Our goals are to increase the FAIR-ness\n(findability, accessibility, interoperability, and reusability) of logbooks by\nexploiting their information content to streamline everyday use, enable\nmacro-analysis for root cause analysis, and facilitate problem-solving\nautomation.", "label": "(\u0027Towards Unlocking Insights from Logbooks Using AI\u0027, \u0027Antonin Sulc, Alex Bien, Annika Eichler, Daniel Ratner, Florian Rehm,\\n  Frank Mayet, Gregor Hartmann, Hayden Hoschouer, Henrik Tuennermann, Jan\\n  Kaiser, Jason St. John, Jennefer Maldonado, Kyle Hazelwood, Raimund\\n  Kammering, Thorsten Hellert, Tim Wilksen, Verena Kain, Wan-Lin Hu\u0027):   Electronic logbooks contain valuable information about activities and events\nconcerning their associated particle accelerator facilities. However, the\nhighly technical nature of logbook entries can hinder their usability and\nautomation. As natural language processing (NLP) continues advancing, it offers\nopportunities to address various challenges that logbooks present. This work\nexplores jointly testing a tailored Retrieval Augmented Generation (RAG) model\nfor enhancing the usability of particle accelerator logbooks at institutes like\nDESY, BESSY, Fermilab, BNL, SLAC, LBNL, and CERN. The RAG model uses a corpus\nbuilt on logbook contributions and aims to unlock insights from these logbooks\nby leveraging retrieval over facility datasets, including discussion about\npotential multimodal sources. Our goals are to increase the FAIR-ness\n(findability, accessibility, interoperability, and reusability) of logbooks by\nexploiting their information content to streamline everyday use, enable\nmacro-analysis for root cause analysis, and facilitate problem-solving\nautomation.", "shape": "dot", "title": "Node: (\u0027Towards Unlocking Insights from Logbooks Using AI\u0027, \u0027Antonin Sulc, Alex Bien, Annika Eichler, Daniel Ratner, Florian Rehm,\\n  Frank Mayet, Gregor Hartmann, Hayden Hoschouer, Henrik Tuennermann, Jan\\n  Kaiser, Jason St. John, Jennefer Maldonado, Kyle Hazelwood, Raimund\\n  Kammering, Thorsten Hellert, Tim Wilksen, Verena Kain, Wan-Lin Hu\u0027):   Electronic logbooks contain valuable information about activities and events\nconcerning their associated particle accelerator facilities. However, the\nhighly technical nature of logbook entries can hinder their usability and\nautomation. As natural language processing (NLP) continues advancing, it offers\nopportunities to address various challenges that logbooks present. This work\nexplores jointly testing a tailored Retrieval Augmented Generation (RAG) model\nfor enhancing the usability of particle accelerator logbooks at institutes like\nDESY, BESSY, Fermilab, BNL, SLAC, LBNL, and CERN. The RAG model uses a corpus\nbuilt on logbook contributions and aims to unlock insights from these logbooks\nby leveraging retrieval over facility datasets, including discussion about\npotential multimodal sources. Our goals are to increase the FAIR-ness\n(findability, accessibility, interoperability, and reusability) of logbooks by\nexploiting their information content to streamline everyday use, enable\nmacro-analysis for root cause analysis, and facilitate problem-solving\nautomation.\nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database\\n  Filtering with LLM-Extracted Metadata\u0027, \u0027Mykhailo Poliakov and Nadiya Shvai\u0027):   The retrieval-augmented generation (RAG) enables retrieval of relevant\ninformation from an external knowledge source and allows large language models\n(LLMs) to answer queries over previously unseen document collections. However,\nit was demonstrated that traditional RAG applications perform poorly in\nanswering multi-hop questions, which require retrieving and reasoning over\nmultiple elements of supporting evidence. We introduce a new method called\nMulti-Meta-RAG, which uses database filtering with LLM-extracted metadata to\nimprove the RAG selection of the relevant documents from various sources,\nrelevant to the question. While database filtering is specific to a set of\nquestions from a particular domain and format, we found out that Multi-Meta-RAG\ngreatly improves the results on the MultiHop-RAG benchmark. The code is\navailable at https://github.com/mxpoliakov/Multi-Meta-RAG.", "label": "(\u0027Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database\\n  Filtering with LLM-Extracted Metadata\u0027, \u0027Mykhailo Poliakov and Nadiya Shvai\u0027):   The retrieval-augmented generation (RAG) enables retrieval of relevant\ninformation from an external knowledge source and allows large language models\n(LLMs) to answer queries over previously unseen document collections. However,\nit was demonstrated that traditional RAG applications perform poorly in\nanswering multi-hop questions, which require retrieving and reasoning over\nmultiple elements of supporting evidence. We introduce a new method called\nMulti-Meta-RAG, which uses database filtering with LLM-extracted metadata to\nimprove the RAG selection of the relevant documents from various sources,\nrelevant to the question. While database filtering is specific to a set of\nquestions from a particular domain and format, we found out that Multi-Meta-RAG\ngreatly improves the results on the MultiHop-RAG benchmark. The code is\navailable at https://github.com/mxpoliakov/Multi-Meta-RAG.", "shape": "dot", "title": "Node: (\u0027Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database\\n  Filtering with LLM-Extracted Metadata\u0027, \u0027Mykhailo Poliakov and Nadiya Shvai\u0027):   The retrieval-augmented generation (RAG) enables retrieval of relevant\ninformation from an external knowledge source and allows large language models\n(LLMs) to answer queries over previously unseen document collections. However,\nit was demonstrated that traditional RAG applications perform poorly in\nanswering multi-hop questions, which require retrieving and reasoning over\nmultiple elements of supporting evidence. We introduce a new method called\nMulti-Meta-RAG, which uses database filtering with LLM-extracted metadata to\nimprove the RAG selection of the relevant documents from various sources,\nrelevant to the question. While database filtering is specific to a set of\nquestions from a particular domain and format, we found out that Multi-Meta-RAG\ngreatly improves the results on the MultiHop-RAG benchmark. The code is\navailable at https://github.com/mxpoliakov/Multi-Meta-RAG.\nPaper ID: 2406.13213\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027R^2AG: Incorporating Retrieval Information into Retrieval Augmented\\n  Generation\u0027, \u0027Fuda Ye, Shuangyin Li, Yongqi Zhang, Lei Chen\u0027):   Retrieval augmented generation (RAG) has been applied in many scenarios to\naugment large language models (LLMs) with external documents provided by\nretrievers. However, a semantic gap exists between LLMs and retrievers due to\ndifferences in their training objectives and architectures. This misalignment\nforces LLMs to passively accept the documents provided by the retrievers,\nleading to incomprehension in the generation process, where the LLMs are\nburdened with the task of distinguishing these documents using their inherent\nknowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill\nthis gap by incorporating Retrieval information into Retrieval Augmented\nGeneration. Specifically, R$^2$AG utilizes the nuanced features from the\nretrievers and employs a R$^2$-Former to capture retrieval information. Then, a\nretrieval-aware prompting strategy is designed to integrate retrieval\ninformation into LLMs\u0027 generation. Notably, R$^2$AG suits low-source scenarios\nwhere LLMs and retrievers are frozen. Extensive experiments across five\ndatasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our\nanalysis reveals that retrieval information serves as an anchor to aid LLMs in\nthe generation process, thereby filling the semantic gap.", "label": "(\u0027R^2AG: Incorporating Retrieval Information into Retrieval Augmented\\n  Generation\u0027, \u0027Fuda Ye, Shuangyin Li, Yongqi Zhang, Lei Chen\u0027):   Retrieval augmented generation (RAG) has been applied in many scenarios to\naugment large language models (LLMs) with external documents provided by\nretrievers. However, a semantic gap exists between LLMs and retrievers due to\ndifferences in their training objectives and architectures. This misalignment\nforces LLMs to passively accept the documents provided by the retrievers,\nleading to incomprehension in the generation process, where the LLMs are\nburdened with the task of distinguishing these documents using their inherent\nknowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill\nthis gap by incorporating Retrieval information into Retrieval Augmented\nGeneration. Specifically, R$^2$AG utilizes the nuanced features from the\nretrievers and employs a R$^2$-Former to capture retrieval information. Then, a\nretrieval-aware prompting strategy is designed to integrate retrieval\ninformation into LLMs\u0027 generation. Notably, R$^2$AG suits low-source scenarios\nwhere LLMs and retrievers are frozen. Extensive experiments across five\ndatasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our\nanalysis reveals that retrieval information serves as an anchor to aid LLMs in\nthe generation process, thereby filling the semantic gap.", "shape": "dot", "title": "Node: (\u0027R^2AG: Incorporating Retrieval Information into Retrieval Augmented\\n  Generation\u0027, \u0027Fuda Ye, Shuangyin Li, Yongqi Zhang, Lei Chen\u0027):   Retrieval augmented generation (RAG) has been applied in many scenarios to\naugment large language models (LLMs) with external documents provided by\nretrievers. However, a semantic gap exists between LLMs and retrievers due to\ndifferences in their training objectives and architectures. This misalignment\nforces LLMs to passively accept the documents provided by the retrievers,\nleading to incomprehension in the generation process, where the LLMs are\nburdened with the task of distinguishing these documents using their inherent\nknowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill\nthis gap by incorporating Retrieval information into Retrieval Augmented\nGeneration. Specifically, R$^2$AG utilizes the nuanced features from the\nretrievers and employs a R$^2$-Former to capture retrieval information. Then, a\nretrieval-aware prompting strategy is designed to integrate retrieval\ninformation into LLMs\u0027 generation. Notably, R$^2$AG suits low-source scenarios\nwhere LLMs and retrievers are frozen. Extensive experiments across five\ndatasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our\nanalysis reveals that retrieval information serves as an anchor to aid LLMs in\nthe generation process, thereby filling the semantic gap.\nPaper ID: 2406.13249\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems\u0027, \u0027Florin Cuconasu, Giovanni Trappolini, Nicola Tonellotto, Fabrizio\\n  Silvestri\u0027):   Retrieval Augmented Generation (RAG) represents a significant advancement in\nartificial intelligence combining a retrieval phase with a generative phase,\nwith the latter typically being powered by large language models (LLMs). The\ncurrent common practices in RAG involve using \"instructed\" LLMs, which are\nfine-tuned with supervised training to enhance their ability to follow\ninstructions and are aligned with human preferences using state-of-the-art\ntechniques. Contrary to popular belief, our study demonstrates that base models\noutperform their instructed counterparts in RAG tasks by 20% on average under\nour experimental settings. This finding challenges the prevailing assumptions\nabout the superiority of instructed LLMs in RAG applications. Further\ninvestigations reveal a more nuanced situation, questioning fundamental aspects\nof RAG and suggesting the need for broader discussions on the topic; or, as\nFromm would have it, \"Seldom is a glance at the statistics enough to understand\nthe meaning of the figures\".", "label": "(\u0027A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems\u0027, \u0027Florin Cuconasu, Giovanni Trappolini, Nicola Tonellotto, Fabrizio\\n  Silvestri\u0027):   Retrieval Augmented Generation (RAG) represents a significant advancement in\nartificial intelligence combining a retrieval phase with a generative phase,\nwith the latter typically being powered by large language models (LLMs). The\ncurrent common practices in RAG involve using \"instructed\" LLMs, which are\nfine-tuned with supervised training to enhance their ability to follow\ninstructions and are aligned with human preferences using state-of-the-art\ntechniques. Contrary to popular belief, our study demonstrates that base models\noutperform their instructed counterparts in RAG tasks by 20% on average under\nour experimental settings. This finding challenges the prevailing assumptions\nabout the superiority of instructed LLMs in RAG applications. Further\ninvestigations reveal a more nuanced situation, questioning fundamental aspects\nof RAG and suggesting the need for broader discussions on the topic; or, as\nFromm would have it, \"Seldom is a glance at the statistics enough to understand\nthe meaning of the figures\".", "shape": "dot", "title": "Node: (\u0027A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems\u0027, \u0027Florin Cuconasu, Giovanni Trappolini, Nicola Tonellotto, Fabrizio\\n  Silvestri\u0027):   Retrieval Augmented Generation (RAG) represents a significant advancement in\nartificial intelligence combining a retrieval phase with a generative phase,\nwith the latter typically being powered by large language models (LLMs). The\ncurrent common practices in RAG involve using \"instructed\" LLMs, which are\nfine-tuned with supervised training to enhance their ability to follow\ninstructions and are aligned with human preferences using state-of-the-art\ntechniques. Contrary to popular belief, our study demonstrates that base models\noutperform their instructed counterparts in RAG tasks by 20% on average under\nour experimental settings. This finding challenges the prevailing assumptions\nabout the superiority of instructed LLMs in RAG applications. Further\ninvestigations reveal a more nuanced situation, questioning fundamental aspects\nof RAG and suggesting the need for broader discussions on the topic; or, as\nFromm would have it, \"Seldom is a glance at the statistics enough to understand\nthe meaning of the figures\".\nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy\\n  in Large Language Models\u0027, \u0027Harish Tayyar Madabushi\u0027):   We present a novel extension to Retrieval Augmented Generation with the goal\nof mitigating factual inaccuracies in the output of large language models.\nSpecifically, our method draws on the cognitive linguistic theory of frame\nsemantics for the indexing and retrieval of factual information relevant to\nhelping large language models answer queries. We conduct experiments to\ndemonstrate the effectiveness of this method both in terms of retrieval\neffectiveness and in terms of the relevance of the frames and frame relations\nautomatically generated. Our results show that this novel mechanism of Frame\nSemantic-based retrieval, designed to improve Retrieval Augmented Generation\n(FS-RAG), is effective and offers potential for providing data-driven insights\ninto frame semantics theory. We provide open access to our program code and\nprompts.", "label": "(\u0027FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy\\n  in Large Language Models\u0027, \u0027Harish Tayyar Madabushi\u0027):   We present a novel extension to Retrieval Augmented Generation with the goal\nof mitigating factual inaccuracies in the output of large language models.\nSpecifically, our method draws on the cognitive linguistic theory of frame\nsemantics for the indexing and retrieval of factual information relevant to\nhelping large language models answer queries. We conduct experiments to\ndemonstrate the effectiveness of this method both in terms of retrieval\neffectiveness and in terms of the relevance of the frames and frame relations\nautomatically generated. Our results show that this novel mechanism of Frame\nSemantic-based retrieval, designed to improve Retrieval Augmented Generation\n(FS-RAG), is effective and offers potential for providing data-driven insights\ninto frame semantics theory. We provide open access to our program code and\nprompts.", "shape": "dot", "title": "Node: (\u0027FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy\\n  in Large Language Models\u0027, \u0027Harish Tayyar Madabushi\u0027):   We present a novel extension to Retrieval Augmented Generation with the goal\nof mitigating factual inaccuracies in the output of large language models.\nSpecifically, our method draws on the cognitive linguistic theory of frame\nsemantics for the indexing and retrieval of factual information relevant to\nhelping large language models answer queries. We conduct experiments to\ndemonstrate the effectiveness of this method both in terms of retrieval\neffectiveness and in terms of the relevance of the frames and frame relations\nautomatically generated. Our results show that this novel mechanism of Frame\nSemantic-based retrieval, designed to improve Retrieval Augmented Generation\n(FS-RAG), is effective and offers potential for providing data-driven insights\ninto frame semantics theory. We provide open access to our program code and\nprompts.\nPaper ID: 2406.16167\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Ragnar\\\\\"ok: A Reusable RAG Framework and Baselines for TREC 2024\\n  Retrieval-Augmented Generation Track\u0027, \u0027Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan\\n  Nguyen, Daniel Campos, Nick Craswell, Jimmy Lin\u0027):   Did you try out the new Bing Search? Or maybe you fiddled around with Google\nAI~Overviews? These might sound familiar because the modern-day search stack\nhas recently evolved to include retrieval-augmented generation (RAG) systems.\nThey allow searching and incorporating real-time data into large language\nmodels (LLMs) to provide a well-informed, attributed, concise summary in\ncontrast to the traditional search paradigm that relies on displaying a ranked\nlist of documents. Therefore, given these recent advancements, it is crucial to\nhave an arena to build, test, visualize, and systematically evaluate RAG-based\nsearch systems. With this in mind, we propose the TREC 2024 RAG Track to foster\ninnovation in evaluating RAG systems. In our work, we lay out the steps we\u0027ve\nmade towards making this track a reality -- we describe the details of our\nreusable framework, Ragnar\\\"ok, explain the curation of the new MS MARCO V2.1\ncollection choice, release the development topics for the track, and\nstandardize the I/O definitions which assist the end user. Next, using\nRagnar\\\"ok, we identify and provide key industrial baselines such as OpenAI\u0027s\nGPT-4o or Cohere\u0027s Command R+. Further, we introduce a web-based user interface\nfor an interactive arena allowing benchmarking pairwise RAG systems by\ncrowdsourcing. We open-source our Ragnar\\\"ok framework and baselines to achieve\na unified standard for future RAG systems.", "label": "(\u0027Ragnar\\\\\"ok: A Reusable RAG Framework and Baselines for TREC 2024\\n  Retrieval-Augmented Generation Track\u0027, \u0027Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan\\n  Nguyen, Daniel Campos, Nick Craswell, Jimmy Lin\u0027):   Did you try out the new Bing Search? Or maybe you fiddled around with Google\nAI~Overviews? These might sound familiar because the modern-day search stack\nhas recently evolved to include retrieval-augmented generation (RAG) systems.\nThey allow searching and incorporating real-time data into large language\nmodels (LLMs) to provide a well-informed, attributed, concise summary in\ncontrast to the traditional search paradigm that relies on displaying a ranked\nlist of documents. Therefore, given these recent advancements, it is crucial to\nhave an arena to build, test, visualize, and systematically evaluate RAG-based\nsearch systems. With this in mind, we propose the TREC 2024 RAG Track to foster\ninnovation in evaluating RAG systems. In our work, we lay out the steps we\u0027ve\nmade towards making this track a reality -- we describe the details of our\nreusable framework, Ragnar\\\"ok, explain the curation of the new MS MARCO V2.1\ncollection choice, release the development topics for the track, and\nstandardize the I/O definitions which assist the end user. Next, using\nRagnar\\\"ok, we identify and provide key industrial baselines such as OpenAI\u0027s\nGPT-4o or Cohere\u0027s Command R+. Further, we introduce a web-based user interface\nfor an interactive arena allowing benchmarking pairwise RAG systems by\ncrowdsourcing. We open-source our Ragnar\\\"ok framework and baselines to achieve\na unified standard for future RAG systems.", "shape": "dot", "title": "Node: (\u0027Ragnar\\\\\"ok: A Reusable RAG Framework and Baselines for TREC 2024\\n  Retrieval-Augmented Generation Track\u0027, \u0027Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan\\n  Nguyen, Daniel Campos, Nick Craswell, Jimmy Lin\u0027):   Did you try out the new Bing Search? Or maybe you fiddled around with Google\nAI~Overviews? These might sound familiar because the modern-day search stack\nhas recently evolved to include retrieval-augmented generation (RAG) systems.\nThey allow searching and incorporating real-time data into large language\nmodels (LLMs) to provide a well-informed, attributed, concise summary in\ncontrast to the traditional search paradigm that relies on displaying a ranked\nlist of documents. Therefore, given these recent advancements, it is crucial to\nhave an arena to build, test, visualize, and systematically evaluate RAG-based\nsearch systems. With this in mind, we propose the TREC 2024 RAG Track to foster\ninnovation in evaluating RAG systems. In our work, we lay out the steps we\u0027ve\nmade towards making this track a reality -- we describe the details of our\nreusable framework, Ragnar\\\"ok, explain the curation of the new MS MARCO V2.1\ncollection choice, release the development topics for the track, and\nstandardize the I/O definitions which assist the end user. Next, using\nRagnar\\\"ok, we identify and provide key industrial baselines such as OpenAI\u0027s\nGPT-4o or Cohere\u0027s Command R+. Further, we introduce a web-based user interface\nfor an interactive arena allowing benchmarking pairwise RAG systems by\ncrowdsourcing. We open-source our Ragnar\\\"ok framework and baselines to achieve\na unified standard for future RAG systems.\nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027From RAG to RICHES: Retrieval Interlaced with Sequence Generation\u0027, \u0027Palak Jain, Livio Baldini Soares and Tom Kwiatkowski\u0027):   We present RICHES, a novel approach that interleaves retrieval with sequence\ngeneration tasks. RICHES offers an alternative to conventional RAG systems by\neliminating the need for separate retriever and generator. It retrieves\ndocuments by directly decoding their contents, constrained on the corpus.\nUnifying retrieval with generation allows us to adapt to diverse new tasks via\nprompting alone. RICHES can work with any Instruction-tuned model, without\nadditional training. It provides attributed evidence, supports multi-hop\nretrievals and interleaves thoughts to plan on what to retrieve next, all\nwithin a single decoding pass of the LLM. We demonstrate the strong performance\nof RICHES across ODQA tasks including attributed and multi-hop QA.", "label": "(\u0027From RAG to RICHES: Retrieval Interlaced with Sequence Generation\u0027, \u0027Palak Jain, Livio Baldini Soares and Tom Kwiatkowski\u0027):   We present RICHES, a novel approach that interleaves retrieval with sequence\ngeneration tasks. RICHES offers an alternative to conventional RAG systems by\neliminating the need for separate retriever and generator. It retrieves\ndocuments by directly decoding their contents, constrained on the corpus.\nUnifying retrieval with generation allows us to adapt to diverse new tasks via\nprompting alone. RICHES can work with any Instruction-tuned model, without\nadditional training. It provides attributed evidence, supports multi-hop\nretrievals and interleaves thoughts to plan on what to retrieve next, all\nwithin a single decoding pass of the LLM. We demonstrate the strong performance\nof RICHES across ODQA tasks including attributed and multi-hop QA.", "shape": "dot", "title": "Node: (\u0027From RAG to RICHES: Retrieval Interlaced with Sequence Generation\u0027, \u0027Palak Jain, Livio Baldini Soares and Tom Kwiatkowski\u0027):   We present RICHES, a novel approach that interleaves retrieval with sequence\ngeneration tasks. RICHES offers an alternative to conventional RAG systems by\neliminating the need for separate retriever and generator. It retrieves\ndocuments by directly decoding their contents, constrained on the corpus.\nUnifying retrieval with generation allows us to adapt to diverse new tasks via\nprompting alone. RICHES can work with any Instruction-tuned model, without\nadditional training. It provides attributed evidence, supports multi-hop\nretrievals and interleaves thoughts to plan on what to retrieve next, all\nwithin a single decoding pass of the LLM. We demonstrate the strong performance\nof RICHES across ODQA tasks including attributed and multi-hop QA.\nPaper ID: 2407.00361\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027, \"David Rau, Herv\\\\\u0027e D\\\\\u0027ejean, Nadezhda Chirkova, Thibault Formal, Shuai\\n  Wang, Vassilina Nikoulina, St\\\\\u0027ephane Clinchant\"):   Retrieval-Augmented Generation allows to enhance Large Language Models with\nexternal knowledge. In response to the recent popularity of generative LLMs,\nmany RAG approaches have been proposed, which involve an intricate number of\ndifferent configurations such as evaluation datasets, collections, metrics,\nretrievers, and LLMs. Inconsistent benchmarking poses a major challenge in\ncomparing approaches and understanding the impact of each component in the\npipeline. In this work, we study best practices that lay the groundwork for a\nsystematic evaluation of RAG and present BERGEN, an end-to-end library for\nreproducible research standardizing RAG experiments. In an extensive study\nfocusing on QA, we benchmark different state-of-the-art retrievers, rerankers,\nand LLMs. Additionally, we analyze existing RAG metrics and datasets. Our\nopen-source library BERGEN is available under\n\\url{https://github.com/naver/bergen}.", "label": "(\u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027, \"David Rau, Herv\\\\\u0027e D\\\\\u0027ejean, Nadezhda Chirkova, Thibault Formal, Shuai\\n  Wang, Vassilina Nikoulina, St\\\\\u0027ephane Clinchant\"):   Retrieval-Augmented Generation allows to enhance Large Language Models with\nexternal knowledge. In response to the recent popularity of generative LLMs,\nmany RAG approaches have been proposed, which involve an intricate number of\ndifferent configurations such as evaluation datasets, collections, metrics,\nretrievers, and LLMs. Inconsistent benchmarking poses a major challenge in\ncomparing approaches and understanding the impact of each component in the\npipeline. In this work, we study best practices that lay the groundwork for a\nsystematic evaluation of RAG and present BERGEN, an end-to-end library for\nreproducible research standardizing RAG experiments. In an extensive study\nfocusing on QA, we benchmark different state-of-the-art retrievers, rerankers,\nand LLMs. Additionally, we analyze existing RAG metrics and datasets. Our\nopen-source library BERGEN is available under\n\\url{https://github.com/naver/bergen}.", "shape": "dot", "title": "Node: (\u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027, \"David Rau, Herv\\\\\u0027e D\\\\\u0027ejean, Nadezhda Chirkova, Thibault Formal, Shuai\\n  Wang, Vassilina Nikoulina, St\\\\\u0027ephane Clinchant\"):   Retrieval-Augmented Generation allows to enhance Large Language Models with\nexternal knowledge. In response to the recent popularity of generative LLMs,\nmany RAG approaches have been proposed, which involve an intricate number of\ndifferent configurations such as evaluation datasets, collections, metrics,\nretrievers, and LLMs. Inconsistent benchmarking poses a major challenge in\ncomparing approaches and understanding the impact of each component in the\npipeline. In this work, we study best practices that lay the groundwork for a\nsystematic evaluation of RAG and present BERGEN, an end-to-end library for\nreproducible research standardizing RAG experiments. In an extensive study\nfocusing on QA, we benchmark different state-of-the-art retrievers, rerankers,\nand LLMs. Additionally, we analyze existing RAG metrics and datasets. Our\nopen-source library BERGEN is available under\n\\url{https://github.com/naver/bergen}.\nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Searching for Best Practices in Retrieval-Augmented Generation\u0027, \u0027Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo\\n  Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze\\n  Lv, Xiaoqing Zheng, Xuanjing Huang\u0027):   Retrieval-augmented generation (RAG) techniques have proven to be effective\nin integrating up-to-date information, mitigating hallucinations, and enhancing\nresponse quality, particularly in specialized domains. While many RAG\napproaches have been proposed to enhance large language models through\nquery-dependent retrievals, these approaches still suffer from their complex\nimplementation and prolonged response times. Typically, a RAG workflow involves\nmultiple processing steps, each of which can be executed in various ways. Here,\nwe investigate existing RAG approaches and their potential combinations to\nidentify optimal RAG practices. Through extensive experiments, we suggest\nseveral strategies for deploying RAG that balance both performance and\nefficiency. Moreover, we demonstrate that multimodal retrieval techniques can\nsignificantly enhance question-answering capabilities about visual inputs and\naccelerate the generation of multimodal content using a \"retrieval as\ngeneration\" strategy.", "label": "(\u0027Searching for Best Practices in Retrieval-Augmented Generation\u0027, \u0027Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo\\n  Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze\\n  Lv, Xiaoqing Zheng, Xuanjing Huang\u0027):   Retrieval-augmented generation (RAG) techniques have proven to be effective\nin integrating up-to-date information, mitigating hallucinations, and enhancing\nresponse quality, particularly in specialized domains. While many RAG\napproaches have been proposed to enhance large language models through\nquery-dependent retrievals, these approaches still suffer from their complex\nimplementation and prolonged response times. Typically, a RAG workflow involves\nmultiple processing steps, each of which can be executed in various ways. Here,\nwe investigate existing RAG approaches and their potential combinations to\nidentify optimal RAG practices. Through extensive experiments, we suggest\nseveral strategies for deploying RAG that balance both performance and\nefficiency. Moreover, we demonstrate that multimodal retrieval techniques can\nsignificantly enhance question-answering capabilities about visual inputs and\naccelerate the generation of multimodal content using a \"retrieval as\ngeneration\" strategy.", "shape": "dot", "title": "Node: (\u0027Searching for Best Practices in Retrieval-Augmented Generation\u0027, \u0027Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo\\n  Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze\\n  Lv, Xiaoqing Zheng, Xuanjing Huang\u0027):   Retrieval-augmented generation (RAG) techniques have proven to be effective\nin integrating up-to-date information, mitigating hallucinations, and enhancing\nresponse quality, particularly in specialized domains. While many RAG\napproaches have been proposed to enhance large language models through\nquery-dependent retrievals, these approaches still suffer from their complex\nimplementation and prolonged response times. Typically, a RAG workflow involves\nmultiple processing steps, each of which can be executed in various ways. Here,\nwe investigate existing RAG approaches and their potential combinations to\nidentify optimal RAG practices. Through extensive experiments, we suggest\nseveral strategies for deploying RAG that balance both performance and\nefficiency. Moreover, we demonstrate that multimodal retrieval techniques can\nsignificantly enhance question-answering capabilities about visual inputs and\naccelerate the generation of multimodal content using a \"retrieval as\ngeneration\" strategy.\nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Meta-prompting Optimized Retrieval-augmented Generation\u0027, \"Jo\\\\~ao Rodrigues, Ant\\\\\u0027onio Branco\"):   Retrieval-augmented generation resorts to content retrieved from external\nsources in order to leverage the performance of large language models in\ndownstream tasks. The excessive volume of retrieved content, the possible\ndispersion of its parts, or their out of focus range may happen nevertheless to\neventually have a detrimental rather than an incremental effect. To mitigate\nthis issue and improve retrieval-augmented generation, we propose a method to\nrefine the retrieved content before it is included in the prompt by resorting\nto meta-prompting optimization. Put to empirical test with the demanding\nmulti-hop question answering task from the StrategyQA dataset, the evaluation\nresults indicate that this method outperforms a similar retrieval-augmented\nsystem but without this method by over 30%.", "label": "(\u0027Meta-prompting Optimized Retrieval-augmented Generation\u0027, \"Jo\\\\~ao Rodrigues, Ant\\\\\u0027onio Branco\"):   Retrieval-augmented generation resorts to content retrieved from external\nsources in order to leverage the performance of large language models in\ndownstream tasks. The excessive volume of retrieved content, the possible\ndispersion of its parts, or their out of focus range may happen nevertheless to\neventually have a detrimental rather than an incremental effect. To mitigate\nthis issue and improve retrieval-augmented generation, we propose a method to\nrefine the retrieved content before it is included in the prompt by resorting\nto meta-prompting optimization. Put to empirical test with the demanding\nmulti-hop question answering task from the StrategyQA dataset, the evaluation\nresults indicate that this method outperforms a similar retrieval-augmented\nsystem but without this method by over 30%.", "shape": "dot", "title": "Node: (\u0027Meta-prompting Optimized Retrieval-augmented Generation\u0027, \"Jo\\\\~ao Rodrigues, Ant\\\\\u0027onio Branco\"):   Retrieval-augmented generation resorts to content retrieved from external\nsources in order to leverage the performance of large language models in\ndownstream tasks. The excessive volume of retrieved content, the possible\ndispersion of its parts, or their out of focus range may happen nevertheless to\neventually have a detrimental rather than an incremental effect. To mitigate\nthis issue and improve retrieval-augmented generation, we propose a method to\nrefine the retrieved content before it is included in the prompt by resorting\nto meta-prompting optimization. Put to empirical test with the demanding\nmulti-hop question answering task from the StrategyQA dataset, the evaluation\nresults indicate that this method outperforms a similar retrieval-augmented\nsystem but without this method by over 30%.\nPaper ID: 2407.03955\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Speculative RAG: Enhancing Retrieval Augmented Generation through\\n  Drafting\u0027, \u0027Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop\\n  Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo\\n  Shang, Chen-Yu Lee, Tomas Pfister\u0027):   Retrieval augmented generation (RAG) combines the generative abilities of\nlarge language models (LLMs) with external knowledge sources to provide more\naccurate and up-to-date responses. Recent RAG advancements focus on improving\nretrieval outcomes through iterative LLM refinement or self-critique\ncapabilities acquired through additional instruction tuning of LLMs. In this\nwork, we introduce Speculative RAG - a framework that leverages a larger\ngeneralist LM to efficiently verify multiple RAG drafts produced in parallel by\na smaller, distilled specialist LM. Each draft is generated from a distinct\nsubset of retrieved documents, offering diverse perspectives on the evidence\nwhile reducing input token counts per draft. This approach enhances\ncomprehension of each subset and mitigates potential position bias over long\ncontext. Our method accelerates RAG by delegating drafting to the smaller\nspecialist LM, with the larger generalist LM performing a single verification\npass over the drafts. Extensive experiments demonstrate that Speculative RAG\nachieves state-of-the-art performance with reduced latency on TriviaQA,\nMuSiQue, PubHealth, and ARC-Challenge benchmarks. It notably enhances accuracy\nby up to 12.97% while reducing latency by 51% compared to conventional RAG\nsystems on PubHealth.", "label": "(\u0027Speculative RAG: Enhancing Retrieval Augmented Generation through\\n  Drafting\u0027, \u0027Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop\\n  Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo\\n  Shang, Chen-Yu Lee, Tomas Pfister\u0027):   Retrieval augmented generation (RAG) combines the generative abilities of\nlarge language models (LLMs) with external knowledge sources to provide more\naccurate and up-to-date responses. Recent RAG advancements focus on improving\nretrieval outcomes through iterative LLM refinement or self-critique\ncapabilities acquired through additional instruction tuning of LLMs. In this\nwork, we introduce Speculative RAG - a framework that leverages a larger\ngeneralist LM to efficiently verify multiple RAG drafts produced in parallel by\na smaller, distilled specialist LM. Each draft is generated from a distinct\nsubset of retrieved documents, offering diverse perspectives on the evidence\nwhile reducing input token counts per draft. This approach enhances\ncomprehension of each subset and mitigates potential position bias over long\ncontext. Our method accelerates RAG by delegating drafting to the smaller\nspecialist LM, with the larger generalist LM performing a single verification\npass over the drafts. Extensive experiments demonstrate that Speculative RAG\nachieves state-of-the-art performance with reduced latency on TriviaQA,\nMuSiQue, PubHealth, and ARC-Challenge benchmarks. It notably enhances accuracy\nby up to 12.97% while reducing latency by 51% compared to conventional RAG\nsystems on PubHealth.", "shape": "dot", "title": "Node: (\u0027Speculative RAG: Enhancing Retrieval Augmented Generation through\\n  Drafting\u0027, \u0027Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop\\n  Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo\\n  Shang, Chen-Yu Lee, Tomas Pfister\u0027):   Retrieval augmented generation (RAG) combines the generative abilities of\nlarge language models (LLMs) with external knowledge sources to provide more\naccurate and up-to-date responses. Recent RAG advancements focus on improving\nretrieval outcomes through iterative LLM refinement or self-critique\ncapabilities acquired through additional instruction tuning of LLMs. In this\nwork, we introduce Speculative RAG - a framework that leverages a larger\ngeneralist LM to efficiently verify multiple RAG drafts produced in parallel by\na smaller, distilled specialist LM. Each draft is generated from a distinct\nsubset of retrieved documents, offering diverse perspectives on the evidence\nwhile reducing input token counts per draft. This approach enhances\ncomprehension of each subset and mitigates potential position bias over long\ncontext. Our method accelerates RAG by delegating drafting to the smaller\nspecialist LM, with the larger generalist LM performing a single verification\npass over the drafts. Extensive experiments demonstrate that Speculative RAG\nachieves state-of-the-art performance with reduced latency on TriviaQA,\nMuSiQue, PubHealth, and ARC-Challenge benchmarks. It notably enhances accuracy\nby up to 12.97% while reducing latency by 51% compared to conventional RAG\nsystems on PubHealth.\nPaper ID: 2407.08223\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAGBench: Explainable Benchmark for Retrieval-Augmented Generation\\n  Systems\u0027, \u0027Robert Friel, Masha Belyi, Atindriyo Sanyal\u0027):   Retrieval-Augmented Generation (RAG) has become a standard architectural\npattern for incorporating domain-specific knowledge into user-facing chat\napplications powered by Large Language Models (LLMs). RAG systems are\ncharacterized by (1) a document retriever that queries a domain-specific corpus\nfor context information relevant to an input query, and (2) an LLM that\ngenerates a response based on the provided query and context. However,\ncomprehensive evaluation of RAG systems remains a challenge due to the lack of\nunified evaluation criteria and annotated datasets. In response, we introduce\nRAGBench: the first comprehensive, large-scale RAG benchmark dataset of 100k\nexamples. It covers five unique industry-specific domains and various RAG task\ntypes. RAGBench examples are sourced from industry corpora such as user\nmanuals, making it particularly relevant for industry applications. Further, we\nformalize the TRACe evaluation framework: a set of explainable and actionable\nRAG evaluation metrics applicable across all RAG domains. We release the\nlabeled dataset at https://huggingface.co/datasets/rungalileo/ragbench.\nRAGBench explainable labels facilitate holistic evaluation of RAG systems,\nenabling actionable feedback for continuous improvement of production\napplications. Thorough extensive benchmarking, we find that LLM-based RAG\nevaluation methods struggle to compete with a finetuned RoBERTa model on the\nRAG evaluation task. We identify areas where existing approaches fall short and\npropose the adoption of RAGBench with TRACe towards advancing the state of RAG\nevaluation systems.", "label": "(\u0027RAGBench: Explainable Benchmark for Retrieval-Augmented Generation\\n  Systems\u0027, \u0027Robert Friel, Masha Belyi, Atindriyo Sanyal\u0027):   Retrieval-Augmented Generation (RAG) has become a standard architectural\npattern for incorporating domain-specific knowledge into user-facing chat\napplications powered by Large Language Models (LLMs). RAG systems are\ncharacterized by (1) a document retriever that queries a domain-specific corpus\nfor context information relevant to an input query, and (2) an LLM that\ngenerates a response based on the provided query and context. However,\ncomprehensive evaluation of RAG systems remains a challenge due to the lack of\nunified evaluation criteria and annotated datasets. In response, we introduce\nRAGBench: the first comprehensive, large-scale RAG benchmark dataset of 100k\nexamples. It covers five unique industry-specific domains and various RAG task\ntypes. RAGBench examples are sourced from industry corpora such as user\nmanuals, making it particularly relevant for industry applications. Further, we\nformalize the TRACe evaluation framework: a set of explainable and actionable\nRAG evaluation metrics applicable across all RAG domains. We release the\nlabeled dataset at https://huggingface.co/datasets/rungalileo/ragbench.\nRAGBench explainable labels facilitate holistic evaluation of RAG systems,\nenabling actionable feedback for continuous improvement of production\napplications. Thorough extensive benchmarking, we find that LLM-based RAG\nevaluation methods struggle to compete with a finetuned RoBERTa model on the\nRAG evaluation task. We identify areas where existing approaches fall short and\npropose the adoption of RAGBench with TRACe towards advancing the state of RAG\nevaluation systems.", "shape": "dot", "title": "Node: (\u0027RAGBench: Explainable Benchmark for Retrieval-Augmented Generation\\n  Systems\u0027, \u0027Robert Friel, Masha Belyi, Atindriyo Sanyal\u0027):   Retrieval-Augmented Generation (RAG) has become a standard architectural\npattern for incorporating domain-specific knowledge into user-facing chat\napplications powered by Large Language Models (LLMs). RAG systems are\ncharacterized by (1) a document retriever that queries a domain-specific corpus\nfor context information relevant to an input query, and (2) an LLM that\ngenerates a response based on the provided query and context. However,\ncomprehensive evaluation of RAG systems remains a challenge due to the lack of\nunified evaluation criteria and annotated datasets. In response, we introduce\nRAGBench: the first comprehensive, large-scale RAG benchmark dataset of 100k\nexamples. It covers five unique industry-specific domains and various RAG task\ntypes. RAGBench examples are sourced from industry corpora such as user\nmanuals, making it particularly relevant for industry applications. Further, we\nformalize the TRACe evaluation framework: a set of explainable and actionable\nRAG evaluation metrics applicable across all RAG domains. We release the\nlabeled dataset at https://huggingface.co/datasets/rungalileo/ragbench.\nRAGBench explainable labels facilitate holistic evaluation of RAG systems,\nenabling actionable feedback for continuous improvement of production\napplications. Thorough extensive benchmarking, we find that LLM-based RAG\nevaluation methods struggle to compete with a finetuned RoBERTa model on the\nRAG evaluation task. We identify areas where existing approaches fall short and\npropose the adoption of RAGBench with TRACe towards advancing the state of RAG\nevaluation systems.\nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker\\n  and AWS Trainium and Inferentia2\u0027, \u0027Tengfei Xue, Xuefeng Li, Roman Smirnov, Tahir Azim, Arash Sadrieh and\\n  Babak Pahlavan\u0027):   Retrieval-augmented generation (RAG) techniques are widely used today to\nretrieve and present information in a conversational format. This paper\npresents a set of enhancements to traditional RAG techniques, focusing on large\nlanguage models (LLMs) fine-tuned and hosted on AWS Trainium and Inferentia2 AI\nchips via SageMaker. These chips are characterized by their elasticity,\naffordability, and efficient performance for AI compute tasks. Besides enabling\ndeployment on these chips, this work aims to improve tool usage, add citation\ncapabilities, and mitigate the risks of hallucinations and unsafe responses due\nto context bias. We benchmark our RAG system\u0027s performance on the Natural\nQuestions and HotPotQA datasets, achieving an accuracy of 62% and 59%\nrespectively, exceeding other models such as DBRX and Mixtral Instruct.", "label": "(\u0027NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker\\n  and AWS Trainium and Inferentia2\u0027, \u0027Tengfei Xue, Xuefeng Li, Roman Smirnov, Tahir Azim, Arash Sadrieh and\\n  Babak Pahlavan\u0027):   Retrieval-augmented generation (RAG) techniques are widely used today to\nretrieve and present information in a conversational format. This paper\npresents a set of enhancements to traditional RAG techniques, focusing on large\nlanguage models (LLMs) fine-tuned and hosted on AWS Trainium and Inferentia2 AI\nchips via SageMaker. These chips are characterized by their elasticity,\naffordability, and efficient performance for AI compute tasks. Besides enabling\ndeployment on these chips, this work aims to improve tool usage, add citation\ncapabilities, and mitigate the risks of hallucinations and unsafe responses due\nto context bias. We benchmark our RAG system\u0027s performance on the Natural\nQuestions and HotPotQA datasets, achieving an accuracy of 62% and 59%\nrespectively, exceeding other models such as DBRX and Mixtral Instruct.", "shape": "dot", "title": "Node: (\u0027NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker\\n  and AWS Trainium and Inferentia2\u0027, \u0027Tengfei Xue, Xuefeng Li, Roman Smirnov, Tahir Azim, Arash Sadrieh and\\n  Babak Pahlavan\u0027):   Retrieval-augmented generation (RAG) techniques are widely used today to\nretrieve and present information in a conversational format. This paper\npresents a set of enhancements to traditional RAG techniques, focusing on large\nlanguage models (LLMs) fine-tuned and hosted on AWS Trainium and Inferentia2 AI\nchips via SageMaker. These chips are characterized by their elasticity,\naffordability, and efficient performance for AI compute tasks. Besides enabling\ndeployment on these chips, this work aims to improve tool usage, add citation\ncapabilities, and mitigate the risks of hallucinations and unsafe responses due\nto context bias. We benchmark our RAG system\u0027s performance on the Natural\nQuestions and HotPotQA datasets, achieving an accuracy of 62% and 59%\nrespectively, exceeding other models such as DBRX and Mixtral Instruct.\nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieval-Augmented Generation for Natural Language Processing: A Survey\u0027, \u0027Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan,\\n  Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue\u0027):   Large language models (LLMs) have demonstrated great success in various\nfields, benefiting from their huge amount of parameters that store knowledge.\nHowever, LLMs still suffer from several key issues, such as hallucination\nproblems, knowledge update issues, and lacking domain-specific expertise. The\nappearance of retrieval-augmented generation (RAG), which leverages an external\nknowledge database to augment LLMs, makes up those drawbacks of LLMs. This\npaper reviews all significant techniques of RAG, especially in the retriever\nand the retrieval fusions. Besides, tutorial codes are provided for\nimplementing the representative techniques in RAG. This paper further discusses\nthe RAG training, including RAG with/without datastore update. Then, we\nintroduce the application of RAG in representative natural language processing\ntasks and industrial scenarios. Finally, this paper discusses the future\ndirections and challenges of RAG for promoting its development.", "label": "(\u0027Retrieval-Augmented Generation for Natural Language Processing: A Survey\u0027, \u0027Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan,\\n  Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue\u0027):   Large language models (LLMs) have demonstrated great success in various\nfields, benefiting from their huge amount of parameters that store knowledge.\nHowever, LLMs still suffer from several key issues, such as hallucination\nproblems, knowledge update issues, and lacking domain-specific expertise. The\nappearance of retrieval-augmented generation (RAG), which leverages an external\nknowledge database to augment LLMs, makes up those drawbacks of LLMs. This\npaper reviews all significant techniques of RAG, especially in the retriever\nand the retrieval fusions. Besides, tutorial codes are provided for\nimplementing the representative techniques in RAG. This paper further discusses\nthe RAG training, including RAG with/without datastore update. Then, we\nintroduce the application of RAG in representative natural language processing\ntasks and industrial scenarios. Finally, this paper discusses the future\ndirections and challenges of RAG for promoting its development.", "shape": "dot", "title": "Node: (\u0027Retrieval-Augmented Generation for Natural Language Processing: A Survey\u0027, \u0027Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan,\\n  Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue\u0027):   Large language models (LLMs) have demonstrated great success in various\nfields, benefiting from their huge amount of parameters that store knowledge.\nHowever, LLMs still suffer from several key issues, such as hallucination\nproblems, knowledge update issues, and lacking domain-specific expertise. The\nappearance of retrieval-augmented generation (RAG), which leverages an external\nknowledge database to augment LLMs, makes up those drawbacks of LLMs. This\npaper reviews all significant techniques of RAG, especially in the retriever\nand the retrieval fusions. Besides, tutorial codes are provided for\nimplementing the representative techniques in RAG. This paper further discusses\nthe RAG training, including RAG with/without datastore update. Then, we\nintroduce the application of RAG in representative natural language processing\ntasks and industrial scenarios. Finally, this paper discusses the future\ndirections and challenges of RAG for promoting its development.\nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Customized Retrieval Augmented Generation and Benchmarking for EDA Tool\\n  Documentation QA\u0027, \u0027Yuan Pu, Zhuolun He, Tairu Qiu, Haoyuan Wu, Bei Yu\u0027):   Retrieval augmented generation (RAG) enhances the accuracy and reliability of\ngenerative AI models by sourcing factual information from external databases,\nwhich is extensively employed in document-grounded question-answering (QA)\ntasks. Off-the-shelf RAG flows are well pretrained on general-purpose\ndocuments, yet they encounter significant challenges when being applied to\nknowledge-intensive vertical domains, such as electronic design automation\n(EDA). This paper addresses such issue by proposing a customized RAG framework\nalong with three domain-specific techniques for EDA tool documentation QA,\nincluding a contrastive learning scheme for text embedding model fine-tuning, a\nreranker distilled from proprietary LLM, and a generative LLM fine-tuned with\nhigh-quality domain corpus. Furthermore, we have developed and released a\ndocumentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced\nRTL-to-GDSII design platform. Experimental results demonstrate that our\nproposed RAG flow and techniques have achieved superior performance on ORD-QA\nas well as on a commercial tool, compared with state-of-the-arts. The ORD-QA\nbenchmark and the training dataset for our customized RAG flow are open-source\nat https://github.com/lesliepy99/RAG-EDA.", "label": "(\u0027Customized Retrieval Augmented Generation and Benchmarking for EDA Tool\\n  Documentation QA\u0027, \u0027Yuan Pu, Zhuolun He, Tairu Qiu, Haoyuan Wu, Bei Yu\u0027):   Retrieval augmented generation (RAG) enhances the accuracy and reliability of\ngenerative AI models by sourcing factual information from external databases,\nwhich is extensively employed in document-grounded question-answering (QA)\ntasks. Off-the-shelf RAG flows are well pretrained on general-purpose\ndocuments, yet they encounter significant challenges when being applied to\nknowledge-intensive vertical domains, such as electronic design automation\n(EDA). This paper addresses such issue by proposing a customized RAG framework\nalong with three domain-specific techniques for EDA tool documentation QA,\nincluding a contrastive learning scheme for text embedding model fine-tuning, a\nreranker distilled from proprietary LLM, and a generative LLM fine-tuned with\nhigh-quality domain corpus. Furthermore, we have developed and released a\ndocumentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced\nRTL-to-GDSII design platform. Experimental results demonstrate that our\nproposed RAG flow and techniques have achieved superior performance on ORD-QA\nas well as on a commercial tool, compared with state-of-the-arts. The ORD-QA\nbenchmark and the training dataset for our customized RAG flow are open-source\nat https://github.com/lesliepy99/RAG-EDA.", "shape": "dot", "title": "Node: (\u0027Customized Retrieval Augmented Generation and Benchmarking for EDA Tool\\n  Documentation QA\u0027, \u0027Yuan Pu, Zhuolun He, Tairu Qiu, Haoyuan Wu, Bei Yu\u0027):   Retrieval augmented generation (RAG) enhances the accuracy and reliability of\ngenerative AI models by sourcing factual information from external databases,\nwhich is extensively employed in document-grounded question-answering (QA)\ntasks. Off-the-shelf RAG flows are well pretrained on general-purpose\ndocuments, yet they encounter significant challenges when being applied to\nknowledge-intensive vertical domains, such as electronic design automation\n(EDA). This paper addresses such issue by proposing a customized RAG framework\nalong with three domain-specific techniques for EDA tool documentation QA,\nincluding a contrastive learning scheme for text embedding model fine-tuning, a\nreranker distilled from proprietary LLM, and a generative LLM fine-tuned with\nhigh-quality domain corpus. Furthermore, we have developed and released a\ndocumentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced\nRTL-to-GDSII design platform. Experimental results demonstrate that our\nproposed RAG flow and techniques have achieved superior performance on ORD-QA\nas well as on a commercial tool, compared with state-of-the-arts. The ORD-QA\nbenchmark and the training dataset for our customized RAG flow are open-source\nat https://github.com/lesliepy99/RAG-EDA.\nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\\n  Study and Hybrid Approach\u0027, \u0027Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky\u0027):   Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG\u0027s significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.", "label": "(\u0027Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\\n  Study and Hybrid Approach\u0027, \u0027Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky\u0027):   Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG\u0027s significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.", "shape": "dot", "title": "Node: (\u0027Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\\n  Study and Hybrid Approach\u0027, \u0027Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky\u0027):   Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG\u0027s significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.\nPaper ID: 2407.16833\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Introducing a new hyper-parameter for RAG: Context Window Utilization\u0027, \u0027Kush Juvekar, Anupam Purwar\u0027):   This paper introduces a new hyper-parameter for Retrieval-Augmented\nGeneration (RAG) systems called Context Window Utilization. RAG systems enhance\ngenerative models by incorporating relevant information retrieved from external\nknowledge bases, improving the factual accuracy and contextual relevance of\ngenerated responses. The size of the text chunks retrieved and processed is a\ncritical factor influencing RAG performance. This study aims to identify the\noptimal chunk size that maximizes answer generation quality. Through systematic\nexperimentation, we analyze the effects of varying chunk sizes on the\nefficiency and effectiveness of RAG frameworks. Our findings reveal that an\noptimal chunk size balances the trade-off between providing sufficient context\nand minimizing irrelevant information. These insights are crucial for enhancing\nthe design and implementation of RAG systems, underscoring the importance of\nselecting an appropriate chunk size to achieve superior performance.", "label": "(\u0027Introducing a new hyper-parameter for RAG: Context Window Utilization\u0027, \u0027Kush Juvekar, Anupam Purwar\u0027):   This paper introduces a new hyper-parameter for Retrieval-Augmented\nGeneration (RAG) systems called Context Window Utilization. RAG systems enhance\ngenerative models by incorporating relevant information retrieved from external\nknowledge bases, improving the factual accuracy and contextual relevance of\ngenerated responses. The size of the text chunks retrieved and processed is a\ncritical factor influencing RAG performance. This study aims to identify the\noptimal chunk size that maximizes answer generation quality. Through systematic\nexperimentation, we analyze the effects of varying chunk sizes on the\nefficiency and effectiveness of RAG frameworks. Our findings reveal that an\noptimal chunk size balances the trade-off between providing sufficient context\nand minimizing irrelevant information. These insights are crucial for enhancing\nthe design and implementation of RAG systems, underscoring the importance of\nselecting an appropriate chunk size to achieve superior performance.", "shape": "dot", "title": "Node: (\u0027Introducing a new hyper-parameter for RAG: Context Window Utilization\u0027, \u0027Kush Juvekar, Anupam Purwar\u0027):   This paper introduces a new hyper-parameter for Retrieval-Augmented\nGeneration (RAG) systems called Context Window Utilization. RAG systems enhance\ngenerative models by incorporating relevant information retrieved from external\nknowledge bases, improving the factual accuracy and contextual relevance of\ngenerated responses. The size of the text chunks retrieved and processed is a\ncritical factor influencing RAG performance. This study aims to identify the\noptimal chunk size that maximizes answer generation quality. Through systematic\nexperimentation, we analyze the effects of varying chunk sizes on the\nefficiency and effectiveness of RAG frameworks. Our findings reveal that an\noptimal chunk size balances the trade-off between providing sufficient context\nand minimizing irrelevant information. These insights are crucial for enhancing\nthe design and implementation of RAG systems, underscoring the importance of\nselecting an appropriate chunk size to achieve superior performance.\nPaper ID: 2407.19794\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework\\n  for Medical Applications\u0027, \u0027Cui Long, Yongbin Liu, Chunping Ouyang, Ying Yu\u0027):   Large Language Models (LLMs) have exhibited remarkable proficiency in natural\nlanguage understanding, prompting extensive exploration of their potential\napplications across diverse domains. In the medical domain, open-source LLMs\nhave demonstrated moderate efficacy following domain-specific fine-tuning;\nhowever, they remain substantially inferior to proprietary models such as GPT-4\nand GPT-3.5. These open-source models encounter limitations in the\ncomprehensiveness of domain-specific knowledge and exhibit a propensity for\n\u0027hallucinations\u0027 during text generation. To mitigate these issues, researchers\nhave implemented the Retrieval-Augmented Generation (RAG) approach, which\naugments LLMs with background information from external knowledge bases while\npreserving the model\u0027s internal parameters. However, document noise can\nadversely affect performance, and the application of RAG in the medical field\nremains in its nascent stages. This study presents the Bailicai framework: a\nnovel integration of retrieval-augmented generation with large language models\noptimized for the medical domain. The Bailicai framework augments the\nperformance of LLMs in medicine through the implementation of four sub-modules.\nExperimental results demonstrate that the Bailicai approach surpasses existing\nmedical domain LLMs across multiple medical benchmarks and exceeds the\nperformance of GPT-3.5. Furthermore, the Bailicai method effectively attenuates\nthe prevalent issue of hallucinations in medical applications of LLMs and\nameliorates the noise-related challenges associated with traditional RAG\ntechniques when processing irrelevant or pseudo-relevant documents.", "label": "(\u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework\\n  for Medical Applications\u0027, \u0027Cui Long, Yongbin Liu, Chunping Ouyang, Ying Yu\u0027):   Large Language Models (LLMs) have exhibited remarkable proficiency in natural\nlanguage understanding, prompting extensive exploration of their potential\napplications across diverse domains. In the medical domain, open-source LLMs\nhave demonstrated moderate efficacy following domain-specific fine-tuning;\nhowever, they remain substantially inferior to proprietary models such as GPT-4\nand GPT-3.5. These open-source models encounter limitations in the\ncomprehensiveness of domain-specific knowledge and exhibit a propensity for\n\u0027hallucinations\u0027 during text generation. To mitigate these issues, researchers\nhave implemented the Retrieval-Augmented Generation (RAG) approach, which\naugments LLMs with background information from external knowledge bases while\npreserving the model\u0027s internal parameters. However, document noise can\nadversely affect performance, and the application of RAG in the medical field\nremains in its nascent stages. This study presents the Bailicai framework: a\nnovel integration of retrieval-augmented generation with large language models\noptimized for the medical domain. The Bailicai framework augments the\nperformance of LLMs in medicine through the implementation of four sub-modules.\nExperimental results demonstrate that the Bailicai approach surpasses existing\nmedical domain LLMs across multiple medical benchmarks and exceeds the\nperformance of GPT-3.5. Furthermore, the Bailicai method effectively attenuates\nthe prevalent issue of hallucinations in medical applications of LLMs and\nameliorates the noise-related challenges associated with traditional RAG\ntechniques when processing irrelevant or pseudo-relevant documents.", "shape": "dot", "title": "Node: (\u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework\\n  for Medical Applications\u0027, \u0027Cui Long, Yongbin Liu, Chunping Ouyang, Ying Yu\u0027):   Large Language Models (LLMs) have exhibited remarkable proficiency in natural\nlanguage understanding, prompting extensive exploration of their potential\napplications across diverse domains. In the medical domain, open-source LLMs\nhave demonstrated moderate efficacy following domain-specific fine-tuning;\nhowever, they remain substantially inferior to proprietary models such as GPT-4\nand GPT-3.5. These open-source models encounter limitations in the\ncomprehensiveness of domain-specific knowledge and exhibit a propensity for\n\u0027hallucinations\u0027 during text generation. To mitigate these issues, researchers\nhave implemented the Retrieval-Augmented Generation (RAG) approach, which\naugments LLMs with background information from external knowledge bases while\npreserving the model\u0027s internal parameters. However, document noise can\nadversely affect performance, and the application of RAG in the medical field\nremains in its nascent stages. This study presents the Bailicai framework: a\nnovel integration of retrieval-augmented generation with large language models\noptimized for the medical domain. The Bailicai framework augments the\nperformance of LLMs in medicine through the implementation of four sub-modules.\nExperimental results demonstrate that the Bailicai approach surpasses existing\nmedical domain LLMs across multiple medical benchmarks and exceeds the\nperformance of GPT-3.5. Furthermore, the Bailicai method effectively attenuates\nthe prevalent issue of hallucinations in medical applications of LLMs and\nameliorates the noise-related challenges associated with traditional RAG\ntechniques when processing irrelevant or pseudo-relevant documents.\nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable\\n  Frameworks\u0027, \u0027Yunfan Gao, Yun Xiong, Meng Wang and Haofen Wang\u0027):   Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\nincreasing demands of application scenarios have driven the evolution of RAG,\nleading to the integration of advanced retrievers, LLMs and other complementary\ntechnologies, which in turn has amplified the intricacy of RAG systems.\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\nwith many methods struggling to be unified under the process of\n\"retrieve-then-generate\". In this context, this paper examines the limitations\nof the existing RAG paradigm and introduces the modular RAG framework. By\ndecomposing complex RAG systems into independent modules and specialized\noperators, it facilitates a highly reconfigurable framework. Modular RAG\ntranscends the traditional linear architecture, embracing a more advanced\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\nextensive research, this paper further identifies prevalent RAG\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\nanalysis of their respective implementation nuances. Modular RAG presents\ninnovative opportunities for the conceptualization and deployment of RAG\nsystems. Finally, the paper explores the potential emergence of new operators\nand paradigms, establishing a solid theoretical foundation and a practical\nroadmap for the continued evolution and practical deployment of RAG\ntechnologies.", "label": "(\u0027Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable\\n  Frameworks\u0027, \u0027Yunfan Gao, Yun Xiong, Meng Wang and Haofen Wang\u0027):   Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\nincreasing demands of application scenarios have driven the evolution of RAG,\nleading to the integration of advanced retrievers, LLMs and other complementary\ntechnologies, which in turn has amplified the intricacy of RAG systems.\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\nwith many methods struggling to be unified under the process of\n\"retrieve-then-generate\". In this context, this paper examines the limitations\nof the existing RAG paradigm and introduces the modular RAG framework. By\ndecomposing complex RAG systems into independent modules and specialized\noperators, it facilitates a highly reconfigurable framework. Modular RAG\ntranscends the traditional linear architecture, embracing a more advanced\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\nextensive research, this paper further identifies prevalent RAG\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\nanalysis of their respective implementation nuances. Modular RAG presents\ninnovative opportunities for the conceptualization and deployment of RAG\nsystems. Finally, the paper explores the potential emergence of new operators\nand paradigms, establishing a solid theoretical foundation and a practical\nroadmap for the continued evolution and practical deployment of RAG\ntechnologies.", "shape": "dot", "title": "Node: (\u0027Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable\\n  Frameworks\u0027, \u0027Yunfan Gao, Yun Xiong, Meng Wang and Haofen Wang\u0027):   Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\nincreasing demands of application scenarios have driven the evolution of RAG,\nleading to the integration of advanced retrievers, LLMs and other complementary\ntechnologies, which in turn has amplified the intricacy of RAG systems.\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\nwith many methods struggling to be unified under the process of\n\"retrieve-then-generate\". In this context, this paper examines the limitations\nof the existing RAG paradigm and introduces the modular RAG framework. By\ndecomposing complex RAG systems into independent modules and specialized\noperators, it facilitates a highly reconfigurable framework. Modular RAG\ntranscends the traditional linear architecture, embracing a more advanced\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\nextensive research, this paper further identifies prevalent RAG\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\nanalysis of their respective implementation nuances. Modular RAG presents\ninnovative opportunities for the conceptualization and deployment of RAG\nsystems. Finally, the paper explores the potential emergence of new operators\nand paradigms, establishing a solid theoretical foundation and a practical\nroadmap for the continued evolution and practical deployment of RAG\ntechnologies.\nPaper ID: 2407.21059\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework\u0027, \u0027Kunlun Zhu, Yifan Luo, Dingling Xu, Ruobing Wang, Shi Yu, Shuo Wang,\\n  Yukun Yan, Zhenghao Liu, Xu Han, Zhiyuan Liu, Maosong Sun\u0027):   Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics Completeness,\nHallucination, and Irrelevance to rigorously evaluate LLM-generated responses.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications.", "label": "(\u0027RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework\u0027, \u0027Kunlun Zhu, Yifan Luo, Dingling Xu, Ruobing Wang, Shi Yu, Shuo Wang,\\n  Yukun Yan, Zhenghao Liu, Xu Han, Zhiyuan Liu, Maosong Sun\u0027):   Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics Completeness,\nHallucination, and Irrelevance to rigorously evaluate LLM-generated responses.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications.", "shape": "dot", "title": "Node: (\u0027RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework\u0027, \u0027Kunlun Zhu, Yifan Luo, Dingling Xu, Ruobing Wang, Shi Yu, Shuo Wang,\\n  Yukun Yan, Zhenghao Liu, Xu Han, Zhiyuan Liu, Maosong Sun\u0027):   Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics Completeness,\nHallucination, and Irrelevance to rigorously evaluate LLM-generated responses.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications.\nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented\\n  Generation\u0027, \u0027Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak\u0027):   Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.", "label": "(\u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented\\n  Generation\u0027, \u0027Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak\u0027):   Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.", "shape": "dot", "title": "Node: (\u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented\\n  Generation\u0027, \u0027Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak\u0027):   Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.\nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027, \u0027Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu,\\n  Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang\u0027):   Retrieval-augmented generation (RAG) methods encounter difficulties when\naddressing complex questions like multi-hop queries. While iterative retrieval\nmethods improve performance by gathering additional information, current\napproaches often rely on multiple calls of large language models (LLMs). In\nthis paper, we introduce EfficientRAG, an efficient retriever for multi-hop\nquestion answering. EfficientRAG iteratively generates new queries without the\nneed for LLM calls at each iteration and filters out irrelevant information.\nExperimental results demonstrate that EfficientRAG surpasses existing RAG\nmethods on three open-domain multi-hop question-answering datasets.", "label": "(\u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027, \u0027Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu,\\n  Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang\u0027):   Retrieval-augmented generation (RAG) methods encounter difficulties when\naddressing complex questions like multi-hop queries. While iterative retrieval\nmethods improve performance by gathering additional information, current\napproaches often rely on multiple calls of large language models (LLMs). In\nthis paper, we introduce EfficientRAG, an efficient retriever for multi-hop\nquestion answering. EfficientRAG iteratively generates new queries without the\nneed for LLM calls at each iteration and filters out irrelevant information.\nExperimental results demonstrate that EfficientRAG surpasses existing RAG\nmethods on three open-domain multi-hop question-answering datasets.", "shape": "dot", "title": "Node: (\u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027, \u0027Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu,\\n  Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang\u0027):   Retrieval-augmented generation (RAG) methods encounter difficulties when\naddressing complex questions like multi-hop queries. While iterative retrieval\nmethods improve performance by gathering additional information, current\napproaches often rely on multiple calls of large language models (LLMs). In\nthis paper, we introduce EfficientRAG, an efficient retriever for multi-hop\nquestion answering. EfficientRAG iteratively generates new queries without the\nneed for LLM calls at each iteration and filters out irrelevant information.\nExperimental results demonstrate that EfficientRAG surpasses existing RAG\nmethods on three open-domain multi-hop question-answering datasets.\nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning\u0027, \u0027Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang\u0027):   Retrieval-augmented generation (RAG) is a framework enabling large language\nmodels (LLMs) to enhance their accuracy and reduce hallucinations by\nintegrating external knowledge bases. In this paper, we introduce a hybrid RAG\nsystem enhanced through a comprehensive suite of optimizations that\nsignificantly improve retrieval quality, augment reasoning capabilities, and\nrefine numerical computation ability. We refined the text chunks and tables in\nweb pages, added attribute predictors to reduce hallucinations, conducted LLM\nKnowledge Extractor and Knowledge Graph Extractor, and finally built a\nreasoning strategy with all the references. We evaluated our system on the CRAG\ndataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and\nonline evaluations demonstrate that our system significantly enhances complex\nreasoning capabilities. In local evaluations, we have significantly improved\naccuracy and reduced error rates compared to the baseline model, achieving a\nnotable increase in scores. In the meanwhile, we have attained outstanding\nresults in online assessments, demonstrating the performance and generalization\ncapabilities of the proposed system. The source code for our system is released\nin \\url{https://gitlab.aicrowd.com/shizueyy/crag-new}.", "label": "(\u0027A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning\u0027, \u0027Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang\u0027):   Retrieval-augmented generation (RAG) is a framework enabling large language\nmodels (LLMs) to enhance their accuracy and reduce hallucinations by\nintegrating external knowledge bases. In this paper, we introduce a hybrid RAG\nsystem enhanced through a comprehensive suite of optimizations that\nsignificantly improve retrieval quality, augment reasoning capabilities, and\nrefine numerical computation ability. We refined the text chunks and tables in\nweb pages, added attribute predictors to reduce hallucinations, conducted LLM\nKnowledge Extractor and Knowledge Graph Extractor, and finally built a\nreasoning strategy with all the references. We evaluated our system on the CRAG\ndataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and\nonline evaluations demonstrate that our system significantly enhances complex\nreasoning capabilities. In local evaluations, we have significantly improved\naccuracy and reduced error rates compared to the baseline model, achieving a\nnotable increase in scores. In the meanwhile, we have attained outstanding\nresults in online assessments, demonstrating the performance and generalization\ncapabilities of the proposed system. The source code for our system is released\nin \\url{https://gitlab.aicrowd.com/shizueyy/crag-new}.", "shape": "dot", "title": "Node: (\u0027A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning\u0027, \u0027Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang\u0027):   Retrieval-augmented generation (RAG) is a framework enabling large language\nmodels (LLMs) to enhance their accuracy and reduce hallucinations by\nintegrating external knowledge bases. In this paper, we introduce a hybrid RAG\nsystem enhanced through a comprehensive suite of optimizations that\nsignificantly improve retrieval quality, augment reasoning capabilities, and\nrefine numerical computation ability. We refined the text chunks and tables in\nweb pages, added attribute predictors to reduce hallucinations, conducted LLM\nKnowledge Extractor and Knowledge Graph Extractor, and finally built a\nreasoning strategy with all the references. We evaluated our system on the CRAG\ndataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and\nonline evaluations demonstrate that our system significantly enhances complex\nreasoning capabilities. In local evaluations, we have significantly improved\naccuracy and reduced error rates compared to the baseline model, achieving a\nnotable increase in scores. In the meanwhile, we have attained outstanding\nresults in online assessments, demonstrating the performance and generalization\ncapabilities of the proposed system. The source code for our system is released\nin \\url{https://gitlab.aicrowd.com/shizueyy/crag-new}.\nPaper ID: 2408.05141\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Exploring Retrieval Augmented Generation in Arabic\u0027, \u0027Samhaa R. El-Beltagy and Mohamed A. Abdallah\u0027):   Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful\ntechnique in natural language processing, combining the strengths of\nretrieval-based and generation-based models to enhance text generation tasks.\nHowever, the application of RAG in Arabic, a language with unique\ncharacteristics and resource constraints, remains underexplored. This paper\npresents a comprehensive case study on the implementation and evaluation of RAG\nfor Arabic text. The work focuses on exploring various semantic embedding\nmodels in the retrieval stage and several LLMs in the generation stage, in\norder to investigate what works and what doesn\u0027t in the context of Arabic. The\nwork also touches upon the issue of variations between document dialect and\nquery dialect in the retrieval stage. Results show that existing semantic\nembedding models and LLMs can be effectively employed to build Arabic RAG\npipelines.", "label": "(\u0027Exploring Retrieval Augmented Generation in Arabic\u0027, \u0027Samhaa R. El-Beltagy and Mohamed A. Abdallah\u0027):   Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful\ntechnique in natural language processing, combining the strengths of\nretrieval-based and generation-based models to enhance text generation tasks.\nHowever, the application of RAG in Arabic, a language with unique\ncharacteristics and resource constraints, remains underexplored. This paper\npresents a comprehensive case study on the implementation and evaluation of RAG\nfor Arabic text. The work focuses on exploring various semantic embedding\nmodels in the retrieval stage and several LLMs in the generation stage, in\norder to investigate what works and what doesn\u0027t in the context of Arabic. The\nwork also touches upon the issue of variations between document dialect and\nquery dialect in the retrieval stage. Results show that existing semantic\nembedding models and LLMs can be effectively employed to build Arabic RAG\npipelines.", "shape": "dot", "title": "Node: (\u0027Exploring Retrieval Augmented Generation in Arabic\u0027, \u0027Samhaa R. El-Beltagy and Mohamed A. Abdallah\u0027):   Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful\ntechnique in natural language processing, combining the strengths of\nretrieval-based and generation-based models to enhance text generation tasks.\nHowever, the application of RAG in Arabic, a language with unique\ncharacteristics and resource constraints, remains underexplored. This paper\npresents a comprehensive case study on the implementation and evaluation of RAG\nfor Arabic text. The work focuses on exploring various semantic embedding\nmodels in the retrieval stage and several LLMs in the generation stage, in\norder to investigate what works and what doesn\u0027t in the context of Arabic. The\nwork also touches upon the issue of variations between document dialect and\nquery dialect in the retrieval stage. Results show that existing semantic\nembedding models and LLMs can be effectively employed to build Arabic RAG\npipelines.\nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented\\n  Generation\u0027, \u0027Dongyu Ru, Lin Qiu, Xiangkun Hu, Tianhang Zhang, Peng Shi, Shuaichen\\n  Chang, Cheng Jiayang, Cunxiang Wang, Shichao Sun, Huanyu Li, Zizhao Zhang,\\n  Binjie Wang, Jiarong Jiang, Tong He, Zhiguo Wang, Pengfei Liu, Yue Zhang,\\n  Zheng Zhang\u0027):   Despite Retrieval-Augmented Generation (RAG) showing promising capability in\nleveraging external knowledge, a comprehensive evaluation of RAG systems is\nstill challenging due to the modular nature of RAG, evaluation of long-form\nresponses and reliability of measurements. In this paper, we propose a\nfine-grained evaluation framework, RAGChecker, that incorporates a suite of\ndiagnostic metrics for both the retrieval and generation modules. Meta\nevaluation verifies that RAGChecker has significantly better correlations with\nhuman judgments than other evaluation metrics. Using RAGChecker, we evaluate 8\nRAG systems and conduct an in-depth analysis of their performance, revealing\ninsightful patterns and trade-offs in the design choices of RAG architectures.\nThe metrics of RAGChecker can guide researchers and practitioners in developing\nmore effective RAG systems. This work has been open sourced at\nhttps://github.com/amazon-science/RAGChecker.", "label": "(\u0027RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented\\n  Generation\u0027, \u0027Dongyu Ru, Lin Qiu, Xiangkun Hu, Tianhang Zhang, Peng Shi, Shuaichen\\n  Chang, Cheng Jiayang, Cunxiang Wang, Shichao Sun, Huanyu Li, Zizhao Zhang,\\n  Binjie Wang, Jiarong Jiang, Tong He, Zhiguo Wang, Pengfei Liu, Yue Zhang,\\n  Zheng Zhang\u0027):   Despite Retrieval-Augmented Generation (RAG) showing promising capability in\nleveraging external knowledge, a comprehensive evaluation of RAG systems is\nstill challenging due to the modular nature of RAG, evaluation of long-form\nresponses and reliability of measurements. In this paper, we propose a\nfine-grained evaluation framework, RAGChecker, that incorporates a suite of\ndiagnostic metrics for both the retrieval and generation modules. Meta\nevaluation verifies that RAGChecker has significantly better correlations with\nhuman judgments than other evaluation metrics. Using RAGChecker, we evaluate 8\nRAG systems and conduct an in-depth analysis of their performance, revealing\ninsightful patterns and trade-offs in the design choices of RAG architectures.\nThe metrics of RAGChecker can guide researchers and practitioners in developing\nmore effective RAG systems. This work has been open sourced at\nhttps://github.com/amazon-science/RAGChecker.", "shape": "dot", "title": "Node: (\u0027RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented\\n  Generation\u0027, \u0027Dongyu Ru, Lin Qiu, Xiangkun Hu, Tianhang Zhang, Peng Shi, Shuaichen\\n  Chang, Cheng Jiayang, Cunxiang Wang, Shichao Sun, Huanyu Li, Zizhao Zhang,\\n  Binjie Wang, Jiarong Jiang, Tong He, Zhiguo Wang, Pengfei Liu, Yue Zhang,\\n  Zheng Zhang\u0027):   Despite Retrieval-Augmented Generation (RAG) showing promising capability in\nleveraging external knowledge, a comprehensive evaluation of RAG systems is\nstill challenging due to the modular nature of RAG, evaluation of long-form\nresponses and reliability of measurements. In this paper, we propose a\nfine-grained evaluation framework, RAGChecker, that incorporates a suite of\ndiagnostic metrics for both the retrieval and generation modules. Meta\nevaluation verifies that RAGChecker has significantly better correlations with\nhuman judgments than other evaluation metrics. Using RAGChecker, we evaluate 8\nRAG systems and conduct an in-depth analysis of their performance, revealing\ninsightful patterns and trade-offs in the design choices of RAG architectures.\nThe metrics of RAGChecker can guide researchers and practitioners in developing\nmore effective RAG systems. This work has been open sourced at\nhttps://github.com/amazon-science/RAGChecker.\nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Graph Retrieval-Augmented Generation: A Survey\u0027, \u0027Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao\\n  Hong, Yan Zhang, Siliang Tang\u0027):   Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable\nsuccess in addressing the challenges of Large Language Models (LLMs) without\nnecessitating retraining. By referencing an external knowledge base, RAG\nrefines LLM outputs, effectively mitigating issues such as ``hallucination\u0027\u0027,\nlack of domain-specific knowledge, and outdated information. However, the\ncomplex structure of relationships among different entities in databases\npresents challenges for RAG systems. In response, GraphRAG leverages structural\ninformation across entities to enable more precise and comprehensive retrieval,\ncapturing relational knowledge and facilitating more accurate, context-aware\nresponses. Given the novelty and potential of GraphRAG, a systematic review of\ncurrent technologies is imperative. This paper provides the first comprehensive\noverview of GraphRAG methodologies. We formalize the GraphRAG workflow,\nencompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced\nGeneration. We then outline the core technologies and training methods at each\nstage. Additionally, we examine downstream tasks, application domains,\nevaluation methodologies, and industrial use cases of GraphRAG. Finally, we\nexplore future research directions to inspire further inquiries and advance\nprogress in the field. In order to track recent progress in this field, we set\nup a repository at \\url{https://github.com/pengboci/GraphRAG-Survey}.", "label": "(\u0027Graph Retrieval-Augmented Generation: A Survey\u0027, \u0027Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao\\n  Hong, Yan Zhang, Siliang Tang\u0027):   Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable\nsuccess in addressing the challenges of Large Language Models (LLMs) without\nnecessitating retraining. By referencing an external knowledge base, RAG\nrefines LLM outputs, effectively mitigating issues such as ``hallucination\u0027\u0027,\nlack of domain-specific knowledge, and outdated information. However, the\ncomplex structure of relationships among different entities in databases\npresents challenges for RAG systems. In response, GraphRAG leverages structural\ninformation across entities to enable more precise and comprehensive retrieval,\ncapturing relational knowledge and facilitating more accurate, context-aware\nresponses. Given the novelty and potential of GraphRAG, a systematic review of\ncurrent technologies is imperative. This paper provides the first comprehensive\noverview of GraphRAG methodologies. We formalize the GraphRAG workflow,\nencompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced\nGeneration. We then outline the core technologies and training methods at each\nstage. Additionally, we examine downstream tasks, application domains,\nevaluation methodologies, and industrial use cases of GraphRAG. Finally, we\nexplore future research directions to inspire further inquiries and advance\nprogress in the field. In order to track recent progress in this field, we set\nup a repository at \\url{https://github.com/pengboci/GraphRAG-Survey}.", "shape": "dot", "title": "Node: (\u0027Graph Retrieval-Augmented Generation: A Survey\u0027, \u0027Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao\\n  Hong, Yan Zhang, Siliang Tang\u0027):   Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable\nsuccess in addressing the challenges of Large Language Models (LLMs) without\nnecessitating retraining. By referencing an external knowledge base, RAG\nrefines LLM outputs, effectively mitigating issues such as ``hallucination\u0027\u0027,\nlack of domain-specific knowledge, and outdated information. However, the\ncomplex structure of relationships among different entities in databases\npresents challenges for RAG systems. In response, GraphRAG leverages structural\ninformation across entities to enable more precise and comprehensive retrieval,\ncapturing relational knowledge and facilitating more accurate, context-aware\nresponses. Given the novelty and potential of GraphRAG, a systematic review of\ncurrent technologies is imperative. This paper provides the first comprehensive\noverview of GraphRAG methodologies. We formalize the GraphRAG workflow,\nencompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced\nGeneration. We then outline the core technologies and training methods at each\nstage. Additionally, we examine downstream tasks, application domains,\nevaluation methodologies, and industrial use cases of GraphRAG. Finally, we\nexplore future research directions to inspire further inquiries and advance\nprogress in the field. In order to track recent progress in this field, we set\nup a repository at \\url{https://github.com/pengboci/GraphRAG-Survey}.\nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "(\"Pandora\u0027s Box or Aladdin\u0027s Lamp: A Comprehensive Analysis Revealing the\\n  Role of RAG Noise in Large Language Models\", \u0027Jinyang Wu and Feihu Che and Chuyuan Zhang and Jianhua Tao and Shuai\\n  Zhang and Pengpeng Shao\u0027):   Retrieval-Augmented Generation (RAG) has emerged as a crucial method for\naddressing hallucinations in large language models (LLMs). While recent\nresearch has extended RAG models to complex noisy scenarios, these explorations\noften confine themselves to limited noise types and presuppose that noise is\ninherently detrimental to LLMs, potentially deviating from real-world retrieval\nenvironments and restricting practical applicability. In this paper, we define\nseven distinct noise types from a linguistic perspective and establish a Noise\nRAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing\nmultiple datasets and reasoning tasks. Through empirical evaluation of eight\nrepresentative LLMs with diverse architectures and scales, we reveal that these\nnoises can be further categorized into two practical groups: noise that is\nbeneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs\n(aka harmful noise). While harmful noise generally impairs performance,\nbeneficial noise may enhance several aspects of model capabilities and overall\nperformance. Our analysis offers insights for developing more robust, adaptable\nRAG solutions and mitigating hallucinations across diverse retrieval scenarios.", "label": "(\"Pandora\u0027s Box or Aladdin\u0027s Lamp: A Comprehensive Analysis Revealing the\\n  Role of RAG Noise in Large Language Models\", \u0027Jinyang Wu and Feihu Che and Chuyuan Zhang and Jianhua Tao and Shuai\\n  Zhang and Pengpeng Shao\u0027):   Retrieval-Augmented Generation (RAG) has emerged as a crucial method for\naddressing hallucinations in large language models (LLMs). While recent\nresearch has extended RAG models to complex noisy scenarios, these explorations\noften confine themselves to limited noise types and presuppose that noise is\ninherently detrimental to LLMs, potentially deviating from real-world retrieval\nenvironments and restricting practical applicability. In this paper, we define\nseven distinct noise types from a linguistic perspective and establish a Noise\nRAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing\nmultiple datasets and reasoning tasks. Through empirical evaluation of eight\nrepresentative LLMs with diverse architectures and scales, we reveal that these\nnoises can be further categorized into two practical groups: noise that is\nbeneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs\n(aka harmful noise). While harmful noise generally impairs performance,\nbeneficial noise may enhance several aspects of model capabilities and overall\nperformance. Our analysis offers insights for developing more robust, adaptable\nRAG solutions and mitigating hallucinations across diverse retrieval scenarios.", "shape": "dot", "title": "Node: (\"Pandora\u0027s Box or Aladdin\u0027s Lamp: A Comprehensive Analysis Revealing the\\n  Role of RAG Noise in Large Language Models\", \u0027Jinyang Wu and Feihu Che and Chuyuan Zhang and Jianhua Tao and Shuai\\n  Zhang and Pengpeng Shao\u0027):   Retrieval-Augmented Generation (RAG) has emerged as a crucial method for\naddressing hallucinations in large language models (LLMs). While recent\nresearch has extended RAG models to complex noisy scenarios, these explorations\noften confine themselves to limited noise types and presuppose that noise is\ninherently detrimental to LLMs, potentially deviating from real-world retrieval\nenvironments and restricting practical applicability. In this paper, we define\nseven distinct noise types from a linguistic perspective and establish a Noise\nRAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing\nmultiple datasets and reasoning tasks. Through empirical evaluation of eight\nrepresentative LLMs with diverse architectures and scales, we reveal that these\nnoises can be further categorized into two practical groups: noise that is\nbeneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs\n(aka harmful noise). While harmful noise generally impairs performance,\nbeneficial noise may enhance several aspects of model capabilities and overall\nperformance. Our analysis offers insights for developing more robust, adaptable\nRAG solutions and mitigating hallucinations across diverse retrieval scenarios.\nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027In Defense of RAG in the Era of Long-Context Language Models\u0027, \u0027Tan Yu, Anbang Xu, Rama Akkiraju\u0027):   Overcoming the limited context limitations in early-generation LLMs,\nretrieval-augmented generation (RAG) has been a reliable solution for\ncontext-based answer generation in the past. Recently, the emergence of\nlong-context LLMs allows the models to incorporate much longer text sequences,\nmaking RAG less attractive. Recent studies show that long-context LLMs\nsignificantly outperform RAG in long-context applications. Unlike the existing\nworks favoring the long-context LLM over RAG, we argue that the extremely long\ncontext in LLMs suffers from a diminished focus on relevant information and\nleads to potential degradation in answer quality. This paper revisits the RAG\nin long-context answer generation. We propose an order-preserve\nretrieval-augmented generation (OP-RAG) mechanism, which significantly improves\nthe performance of RAG for long-context question-answer applications. With\nOP-RAG, as the number of retrieved chunks increases, the answer quality\ninitially rises, and then declines, forming an inverted U-shaped curve. There\nexist sweet points where OP-RAG could achieve higher answer quality with much\nless tokens than long-context LLM taking the whole context as input. Extensive\nexperiments on public benchmark demonstrate the superiority of our OP-RAG.", "label": "(\u0027In Defense of RAG in the Era of Long-Context Language Models\u0027, \u0027Tan Yu, Anbang Xu, Rama Akkiraju\u0027):   Overcoming the limited context limitations in early-generation LLMs,\nretrieval-augmented generation (RAG) has been a reliable solution for\ncontext-based answer generation in the past. Recently, the emergence of\nlong-context LLMs allows the models to incorporate much longer text sequences,\nmaking RAG less attractive. Recent studies show that long-context LLMs\nsignificantly outperform RAG in long-context applications. Unlike the existing\nworks favoring the long-context LLM over RAG, we argue that the extremely long\ncontext in LLMs suffers from a diminished focus on relevant information and\nleads to potential degradation in answer quality. This paper revisits the RAG\nin long-context answer generation. We propose an order-preserve\nretrieval-augmented generation (OP-RAG) mechanism, which significantly improves\nthe performance of RAG for long-context question-answer applications. With\nOP-RAG, as the number of retrieved chunks increases, the answer quality\ninitially rises, and then declines, forming an inverted U-shaped curve. There\nexist sweet points where OP-RAG could achieve higher answer quality with much\nless tokens than long-context LLM taking the whole context as input. Extensive\nexperiments on public benchmark demonstrate the superiority of our OP-RAG.", "shape": "dot", "title": "Node: (\u0027In Defense of RAG in the Era of Long-Context Language Models\u0027, \u0027Tan Yu, Anbang Xu, Rama Akkiraju\u0027):   Overcoming the limited context limitations in early-generation LLMs,\nretrieval-augmented generation (RAG) has been a reliable solution for\ncontext-based answer generation in the past. Recently, the emergence of\nlong-context LLMs allows the models to incorporate much longer text sequences,\nmaking RAG less attractive. Recent studies show that long-context LLMs\nsignificantly outperform RAG in long-context applications. Unlike the existing\nworks favoring the long-context LLM over RAG, we argue that the extremely long\ncontext in LLMs suffers from a diminished focus on relevant information and\nleads to potential degradation in answer quality. This paper revisits the RAG\nin long-context answer generation. We propose an order-preserve\nretrieval-augmented generation (OP-RAG) mechanism, which significantly improves\nthe performance of RAG for long-context question-answer applications. With\nOP-RAG, as the number of retrieved chunks increases, the answer quality\ninitially rises, and then declines, forming an inverted U-shaped curve. There\nexist sweet points where OP-RAG could achieve higher answer quality with much\nless tokens than long-context LLM taking the whole context as input. Extensive\nexperiments on public benchmark demonstrate the superiority of our OP-RAG.\nPaper ID: 2409.01666\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented\\n  Generation Question Answering\u0027, \u0027Mitchell DeHaven\u0027):   In this paper we present a multi-adapter retrieval augmented generation\nsystem (MARAGS) for Meta\u0027s Comprehensive RAG (CRAG) competition for KDD CUP\n2024. CRAG is a question answering dataset contains 3 different subtasks aimed\nat realistic question and answering RAG related tasks, with a diverse set of\nquestion topics, question types, time dynamic answers, and questions featuring\nentities of varying popularity.\n  Our system follows a standard setup for web based RAG, which uses processed\nweb pages to provide context for an LLM to produce generations, while also\nquerying API endpoints for additional information. MARAGS also utilizes\nmultiple different adapters to solve the various requirements for these tasks\nwith a standard cross-encoder model for ranking candidate passages relevant for\nanswering the question. Our system achieved 2nd place for Task 1 as well as 3rd\nplace on Task 2.", "label": "(\u0027MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented\\n  Generation Question Answering\u0027, \u0027Mitchell DeHaven\u0027):   In this paper we present a multi-adapter retrieval augmented generation\nsystem (MARAGS) for Meta\u0027s Comprehensive RAG (CRAG) competition for KDD CUP\n2024. CRAG is a question answering dataset contains 3 different subtasks aimed\nat realistic question and answering RAG related tasks, with a diverse set of\nquestion topics, question types, time dynamic answers, and questions featuring\nentities of varying popularity.\n  Our system follows a standard setup for web based RAG, which uses processed\nweb pages to provide context for an LLM to produce generations, while also\nquerying API endpoints for additional information. MARAGS also utilizes\nmultiple different adapters to solve the various requirements for these tasks\nwith a standard cross-encoder model for ranking candidate passages relevant for\nanswering the question. Our system achieved 2nd place for Task 1 as well as 3rd\nplace on Task 2.", "shape": "dot", "title": "Node: (\u0027MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented\\n  Generation Question Answering\u0027, \u0027Mitchell DeHaven\u0027):   In this paper we present a multi-adapter retrieval augmented generation\nsystem (MARAGS) for Meta\u0027s Comprehensive RAG (CRAG) competition for KDD CUP\n2024. CRAG is a question answering dataset contains 3 different subtasks aimed\nat realistic question and answering RAG related tasks, with a diverse set of\nquestion topics, question types, time dynamic answers, and questions featuring\nentities of varying popularity.\n  Our system follows a standard setup for web based RAG, which uses processed\nweb pages to provide context for an LLM to produce generations, while also\nquerying API endpoints for additional information. MARAGS also utilizes\nmultiple different adapters to solve the various requirements for these tasks\nwith a standard cross-encoder model for ranking candidate passages relevant for\nanswering the question. Our system achieved 2nd place for Task 1 as well as 3rd\nplace on Task 2.\nPaper ID: 2409.03171\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs\u0027, \u0027Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang,\\n  Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang\u0027):   Despite the recent advancements in Large Language Models (LLMs), which have\nsignificantly enhanced the generative capabilities for various NLP tasks, LLMs\nstill face limitations in directly handling retrieval tasks. However, many\npractical applications demand the seamless integration of both retrieval and\ngeneration. This paper introduces a novel and efficient One-pass Generation and\nretrieval framework (OneGen), designed to improve LLMs\u0027 performance on tasks\nthat require both generation and retrieval. The proposed framework bridges the\ntraditionally separate training approaches for generation and retrieval by\nincorporating retrieval tokens generated autoregressively. This enables a\nsingle LLM to handle both tasks simultaneously in a unified forward pass. We\nconduct experiments on two distinct types of composite tasks, RAG and Entity\nLinking, to validate the pluggability, effectiveness, and efficiency of OneGen\nin training and inference. Furthermore, our results show that integrating\ngeneration and retrieval within the same context preserves the generative\ncapabilities of LLMs while improving retrieval performance. To the best of our\nknowledge, OneGen is the first to enable LLMs to conduct vector retrieval\nduring the generation.", "label": "(\u0027OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs\u0027, \u0027Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang,\\n  Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang\u0027):   Despite the recent advancements in Large Language Models (LLMs), which have\nsignificantly enhanced the generative capabilities for various NLP tasks, LLMs\nstill face limitations in directly handling retrieval tasks. However, many\npractical applications demand the seamless integration of both retrieval and\ngeneration. This paper introduces a novel and efficient One-pass Generation and\nretrieval framework (OneGen), designed to improve LLMs\u0027 performance on tasks\nthat require both generation and retrieval. The proposed framework bridges the\ntraditionally separate training approaches for generation and retrieval by\nincorporating retrieval tokens generated autoregressively. This enables a\nsingle LLM to handle both tasks simultaneously in a unified forward pass. We\nconduct experiments on two distinct types of composite tasks, RAG and Entity\nLinking, to validate the pluggability, effectiveness, and efficiency of OneGen\nin training and inference. Furthermore, our results show that integrating\ngeneration and retrieval within the same context preserves the generative\ncapabilities of LLMs while improving retrieval performance. To the best of our\nknowledge, OneGen is the first to enable LLMs to conduct vector retrieval\nduring the generation.", "shape": "dot", "title": "Node: (\u0027OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs\u0027, \u0027Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang,\\n  Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang\u0027):   Despite the recent advancements in Large Language Models (LLMs), which have\nsignificantly enhanced the generative capabilities for various NLP tasks, LLMs\nstill face limitations in directly handling retrieval tasks. However, many\npractical applications demand the seamless integration of both retrieval and\ngeneration. This paper introduces a novel and efficient One-pass Generation and\nretrieval framework (OneGen), designed to improve LLMs\u0027 performance on tasks\nthat require both generation and retrieval. The proposed framework bridges the\ntraditionally separate training approaches for generation and retrieval by\nincorporating retrieval tokens generated autoregressively. This enables a\nsingle LLM to handle both tasks simultaneously in a unified forward pass. We\nconduct experiments on two distinct types of composite tasks, RAG and Entity\nLinking, to validate the pluggability, effectiveness, and efficiency of OneGen\nin training and inference. Furthermore, our results show that integrating\ngeneration and retrieval within the same context preserves the generative\ncapabilities of LLMs while improving retrieval performance. To the best of our\nknowledge, OneGen is the first to enable LLMs to conduct vector retrieval\nduring the generation.\nPaper ID: 2409.05152\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge\\n  Discovery\u0027, \u0027Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao and Zhicheng Dou\u0027):   Retrieval-Augmented Generation (RAG) leverages retrieval tools to access\nexternal databases, thereby enhancing the generation quality of large language\nmodels (LLMs) through optimized context. However, the existing retrieval\nmethods are constrained inherently, as they can only perform relevance matching\nbetween explicitly stated queries and well-formed knowledge, but unable to\nhandle tasks involving ambiguous information needs or unstructured knowledge.\nConsequently, existing RAG systems are primarily effective for straightforward\nquestion-answering tasks. In this work, we propose MemoRAG, a novel\nretrieval-augmented generation paradigm empowered by long-term memory. MemoRAG\nadopts a dual-system architecture. On the one hand, it employs a light but\nlong-range LLM to form the global memory of database. Once a task is presented,\nit generates draft answers, cluing the retrieval tools to locate useful\ninformation within the database. On the other hand, it leverages an expensive\nbut expressive LLM, which generates the ultimate answer based on the retrieved\ninformation. Building on this general framework, we further optimize MemoRAG\u0027s\nperformance by enhancing its cluing mechanism and memorization capacity. In our\nexperiment, MemoRAG achieves superior performance across a variety of\nevaluation tasks, including both complex ones where conventional RAG fails and\nstraightforward ones where RAG is commonly applied.", "label": "(\u0027MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge\\n  Discovery\u0027, \u0027Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao and Zhicheng Dou\u0027):   Retrieval-Augmented Generation (RAG) leverages retrieval tools to access\nexternal databases, thereby enhancing the generation quality of large language\nmodels (LLMs) through optimized context. However, the existing retrieval\nmethods are constrained inherently, as they can only perform relevance matching\nbetween explicitly stated queries and well-formed knowledge, but unable to\nhandle tasks involving ambiguous information needs or unstructured knowledge.\nConsequently, existing RAG systems are primarily effective for straightforward\nquestion-answering tasks. In this work, we propose MemoRAG, a novel\nretrieval-augmented generation paradigm empowered by long-term memory. MemoRAG\nadopts a dual-system architecture. On the one hand, it employs a light but\nlong-range LLM to form the global memory of database. Once a task is presented,\nit generates draft answers, cluing the retrieval tools to locate useful\ninformation within the database. On the other hand, it leverages an expensive\nbut expressive LLM, which generates the ultimate answer based on the retrieved\ninformation. Building on this general framework, we further optimize MemoRAG\u0027s\nperformance by enhancing its cluing mechanism and memorization capacity. In our\nexperiment, MemoRAG achieves superior performance across a variety of\nevaluation tasks, including both complex ones where conventional RAG fails and\nstraightforward ones where RAG is commonly applied.", "shape": "dot", "title": "Node: (\u0027MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge\\n  Discovery\u0027, \u0027Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao and Zhicheng Dou\u0027):   Retrieval-Augmented Generation (RAG) leverages retrieval tools to access\nexternal databases, thereby enhancing the generation quality of large language\nmodels (LLMs) through optimized context. However, the existing retrieval\nmethods are constrained inherently, as they can only perform relevance matching\nbetween explicitly stated queries and well-formed knowledge, but unable to\nhandle tasks involving ambiguous information needs or unstructured knowledge.\nConsequently, existing RAG systems are primarily effective for straightforward\nquestion-answering tasks. In this work, we propose MemoRAG, a novel\nretrieval-augmented generation paradigm empowered by long-term memory. MemoRAG\nadopts a dual-system architecture. On the one hand, it employs a light but\nlong-range LLM to form the global memory of database. Once a task is presented,\nit generates draft answers, cluing the retrieval tools to locate useful\ninformation within the database. On the other hand, it leverages an expensive\nbut expressive LLM, which generates the ultimate answer based on the retrieved\ninformation. Building on this general framework, we further optimize MemoRAG\u0027s\nperformance by enhancing its cluing mechanism and memorization capacity. In our\nexperiment, MemoRAG achieves superior performance across a variety of\nevaluation tasks, including both complex ones where conventional RAG fails and\nstraightforward ones where RAG is commonly applied.\nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027, \u0027Xuan-Phi Nguyen, Shrey Pandit, Senthil Purushwalkam, Austin Xu, Hailin\\n  Chen, Yifei Ming, Zixuan Ke, Silvio Savarese, Caiming Xong, Shafiq Joty\u0027):   Retrieval Augmented Generation (RAG), a paradigm that integrates external\ncontextual information with large language models (LLMs) to enhance factual\naccuracy and relevance, has emerged as a pivotal area in generative AI. The\nLLMs used in RAG applications are required to faithfully and completely\ncomprehend the provided context and users\u0027 questions, avoid hallucination,\nhandle unanswerable, counterfactual or otherwise low-quality and irrelevant\ncontexts, perform complex multi-hop reasoning and produce reliable citations.\nIn this paper, we introduce SFR-RAG, a small LLM that is instruction-tuned with\nan emphasis on context-grounded generation and hallucination minimization. We\nalso present ContextualBench, a new evaluation framework compiling multiple\npopular and diverse RAG benchmarks, such as HotpotQA and TriviaQA, with\nconsistent RAG settings to ensure reproducibility and consistency in model\nassessments. Experimental results demonstrate that our SFR-RAG-9B model\noutperforms leading baselines such as Command-R+ (104B) and GPT-4o, achieving\nstate-of-the-art results in 3 out of 7 benchmarks in ContextualBench with\nsignificantly fewer parameters. The model is also shown to be resilient to\nalteration in the contextual information and behave appropriately when relevant\ncontext is removed. Additionally, the SFR-RAG model maintains competitive\nperformance in general instruction-following tasks and function-calling\ncapabilities.", "label": "(\u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027, \u0027Xuan-Phi Nguyen, Shrey Pandit, Senthil Purushwalkam, Austin Xu, Hailin\\n  Chen, Yifei Ming, Zixuan Ke, Silvio Savarese, Caiming Xong, Shafiq Joty\u0027):   Retrieval Augmented Generation (RAG), a paradigm that integrates external\ncontextual information with large language models (LLMs) to enhance factual\naccuracy and relevance, has emerged as a pivotal area in generative AI. The\nLLMs used in RAG applications are required to faithfully and completely\ncomprehend the provided context and users\u0027 questions, avoid hallucination,\nhandle unanswerable, counterfactual or otherwise low-quality and irrelevant\ncontexts, perform complex multi-hop reasoning and produce reliable citations.\nIn this paper, we introduce SFR-RAG, a small LLM that is instruction-tuned with\nan emphasis on context-grounded generation and hallucination minimization. We\nalso present ContextualBench, a new evaluation framework compiling multiple\npopular and diverse RAG benchmarks, such as HotpotQA and TriviaQA, with\nconsistent RAG settings to ensure reproducibility and consistency in model\nassessments. Experimental results demonstrate that our SFR-RAG-9B model\noutperforms leading baselines such as Command-R+ (104B) and GPT-4o, achieving\nstate-of-the-art results in 3 out of 7 benchmarks in ContextualBench with\nsignificantly fewer parameters. The model is also shown to be resilient to\nalteration in the contextual information and behave appropriately when relevant\ncontext is removed. Additionally, the SFR-RAG model maintains competitive\nperformance in general instruction-following tasks and function-calling\ncapabilities.", "shape": "dot", "title": "Node: (\u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027, \u0027Xuan-Phi Nguyen, Shrey Pandit, Senthil Purushwalkam, Austin Xu, Hailin\\n  Chen, Yifei Ming, Zixuan Ke, Silvio Savarese, Caiming Xong, Shafiq Joty\u0027):   Retrieval Augmented Generation (RAG), a paradigm that integrates external\ncontextual information with large language models (LLMs) to enhance factual\naccuracy and relevance, has emerged as a pivotal area in generative AI. The\nLLMs used in RAG applications are required to faithfully and completely\ncomprehend the provided context and users\u0027 questions, avoid hallucination,\nhandle unanswerable, counterfactual or otherwise low-quality and irrelevant\ncontexts, perform complex multi-hop reasoning and produce reliable citations.\nIn this paper, we introduce SFR-RAG, a small LLM that is instruction-tuned with\nan emphasis on context-grounded generation and hallucination minimization. We\nalso present ContextualBench, a new evaluation framework compiling multiple\npopular and diverse RAG benchmarks, such as HotpotQA and TriviaQA, with\nconsistent RAG settings to ensure reproducibility and consistency in model\nassessments. Experimental results demonstrate that our SFR-RAG-9B model\noutperforms leading baselines such as Command-R+ (104B) and GPT-4o, achieving\nstate-of-the-art results in 3 out of 7 benchmarks in ContextualBench with\nsignificantly fewer parameters. The model is also shown to be resilient to\nalteration in the contextual information and behave appropriately when relevant\ncontext is removed. Additionally, the SFR-RAG model maintains competitive\nperformance in general instruction-following tasks and function-calling\ncapabilities.\nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027P-RAG: Progressive Retrieval Augmented Generation For Planning on\\n  Embodied Everyday Task\u0027, \u0027Weiye Xu, Min Wang, Wengang Zhou, and Houqiang Li\u0027):   Embodied Everyday Task is a popular task in the embodied AI community,\nrequiring agents to make a sequence of actions based on natural language\ninstructions and visual observations. Traditional learning-based approaches\nface two challenges. Firstly, natural language instructions often lack explicit\ntask planning. Secondly, extensive training is required to equip models with\nknowledge of the task environment. Previous works based on Large Language Model\n(LLM) either suffer from poor performance due to the lack of task-specific\nknowledge or rely on ground truth as few-shot samples. To address the above\nlimitations, we propose a novel approach called Progressive Retrieval Augmented\nGeneration (P-RAG), which not only effectively leverages the powerful language\nprocessing capabilities of LLMs but also progressively accumulates\ntask-specific knowledge without ground-truth. Compared to the conventional RAG\nmethods, which retrieve relevant information from the database in a one-shot\nmanner to assist generation, P-RAG introduces an iterative approach to\nprogressively update the database. In each iteration, P-RAG retrieves the\nlatest database and obtains historical information from the previous\ninteraction as experiential references for the current interaction. Moreover,\nwe also introduce a more granular retrieval scheme that not only retrieves\nsimilar tasks but also incorporates retrieval of similar situations to provide\nmore valuable reference experiences. Extensive experiments reveal that P-RAG\nachieves competitive results without utilizing ground truth and can even\nfurther improve performance through self-iterations.", "label": "(\u0027P-RAG: Progressive Retrieval Augmented Generation For Planning on\\n  Embodied Everyday Task\u0027, \u0027Weiye Xu, Min Wang, Wengang Zhou, and Houqiang Li\u0027):   Embodied Everyday Task is a popular task in the embodied AI community,\nrequiring agents to make a sequence of actions based on natural language\ninstructions and visual observations. Traditional learning-based approaches\nface two challenges. Firstly, natural language instructions often lack explicit\ntask planning. Secondly, extensive training is required to equip models with\nknowledge of the task environment. Previous works based on Large Language Model\n(LLM) either suffer from poor performance due to the lack of task-specific\nknowledge or rely on ground truth as few-shot samples. To address the above\nlimitations, we propose a novel approach called Progressive Retrieval Augmented\nGeneration (P-RAG), which not only effectively leverages the powerful language\nprocessing capabilities of LLMs but also progressively accumulates\ntask-specific knowledge without ground-truth. Compared to the conventional RAG\nmethods, which retrieve relevant information from the database in a one-shot\nmanner to assist generation, P-RAG introduces an iterative approach to\nprogressively update the database. In each iteration, P-RAG retrieves the\nlatest database and obtains historical information from the previous\ninteraction as experiential references for the current interaction. Moreover,\nwe also introduce a more granular retrieval scheme that not only retrieves\nsimilar tasks but also incorporates retrieval of similar situations to provide\nmore valuable reference experiences. Extensive experiments reveal that P-RAG\nachieves competitive results without utilizing ground truth and can even\nfurther improve performance through self-iterations.", "shape": "dot", "title": "Node: (\u0027P-RAG: Progressive Retrieval Augmented Generation For Planning on\\n  Embodied Everyday Task\u0027, \u0027Weiye Xu, Min Wang, Wengang Zhou, and Houqiang Li\u0027):   Embodied Everyday Task is a popular task in the embodied AI community,\nrequiring agents to make a sequence of actions based on natural language\ninstructions and visual observations. Traditional learning-based approaches\nface two challenges. Firstly, natural language instructions often lack explicit\ntask planning. Secondly, extensive training is required to equip models with\nknowledge of the task environment. Previous works based on Large Language Model\n(LLM) either suffer from poor performance due to the lack of task-specific\nknowledge or rely on ground truth as few-shot samples. To address the above\nlimitations, we propose a novel approach called Progressive Retrieval Augmented\nGeneration (P-RAG), which not only effectively leverages the powerful language\nprocessing capabilities of LLMs but also progressively accumulates\ntask-specific knowledge without ground-truth. Compared to the conventional RAG\nmethods, which retrieve relevant information from the database in a one-shot\nmanner to assist generation, P-RAG introduces an iterative approach to\nprogressively update the database. In each iteration, P-RAG retrieves the\nlatest database and obtains historical information from the previous\ninteraction as experiential references for the current interaction. Moreover,\nwe also introduce a more granular retrieval scheme that not only retrieves\nsimilar tasks but also incorporates retrieval of similar situations to provide\nmore valuable reference experiences. Extensive experiments reveal that P-RAG\nachieves competitive results without utilizing ground truth and can even\nfurther improve performance through self-iterations.\nPaper ID: 2409.11279\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Contextual Compression in Retrieval-Augmented Generation for Large\\n  Language Models: A Survey\u0027, \u0027Sourav Verma\u0027):   Large Language Models (LLMs) showcase remarkable abilities, yet they struggle\nwith limitations such as hallucinations, outdated knowledge, opacity, and\ninexplicable reasoning. To address these challenges, Retrieval-Augmented\nGeneration (RAG) has proven to be a viable solution, leveraging external\ndatabases to improve the consistency and coherence of generated content,\nespecially valuable for complex, knowledge-rich tasks, and facilitates\ncontinuous improvement by leveraging domain-specific insights. By combining the\nintrinsic knowledge of LLMs with the vast, dynamic repositories of external\ndatabases, RAG achieves a synergistic effect. However, RAG is not without its\nlimitations, including a limited context window, irrelevant information, and\nthe high processing overhead for extensive contextual data. In this\ncomprehensive work, we explore the evolution of Contextual Compression\nparadigms, providing an in-depth examination of the field. Finally, we outline\nthe current challenges and suggest potential research and development\ndirections, paving the way for future advancements in this area.", "label": "(\u0027Contextual Compression in Retrieval-Augmented Generation for Large\\n  Language Models: A Survey\u0027, \u0027Sourav Verma\u0027):   Large Language Models (LLMs) showcase remarkable abilities, yet they struggle\nwith limitations such as hallucinations, outdated knowledge, opacity, and\ninexplicable reasoning. To address these challenges, Retrieval-Augmented\nGeneration (RAG) has proven to be a viable solution, leveraging external\ndatabases to improve the consistency and coherence of generated content,\nespecially valuable for complex, knowledge-rich tasks, and facilitates\ncontinuous improvement by leveraging domain-specific insights. By combining the\nintrinsic knowledge of LLMs with the vast, dynamic repositories of external\ndatabases, RAG achieves a synergistic effect. However, RAG is not without its\nlimitations, including a limited context window, irrelevant information, and\nthe high processing overhead for extensive contextual data. In this\ncomprehensive work, we explore the evolution of Contextual Compression\nparadigms, providing an in-depth examination of the field. Finally, we outline\nthe current challenges and suggest potential research and development\ndirections, paving the way for future advancements in this area.", "shape": "dot", "title": "Node: (\u0027Contextual Compression in Retrieval-Augmented Generation for Large\\n  Language Models: A Survey\u0027, \u0027Sourav Verma\u0027):   Large Language Models (LLMs) showcase remarkable abilities, yet they struggle\nwith limitations such as hallucinations, outdated knowledge, opacity, and\ninexplicable reasoning. To address these challenges, Retrieval-Augmented\nGeneration (RAG) has proven to be a viable solution, leveraging external\ndatabases to improve the consistency and coherence of generated content,\nespecially valuable for complex, knowledge-rich tasks, and facilitates\ncontinuous improvement by leveraging domain-specific insights. By combining the\nintrinsic knowledge of LLMs with the vast, dynamic repositories of external\ndatabases, RAG achieves a synergistic effect. However, RAG is not without its\nlimitations, including a limited context window, irrelevant information, and\nthe high processing overhead for extensive contextual data. In this\ncomprehensive work, we explore the evolution of Contextual Compression\nparadigms, providing an in-depth examination of the field. Finally, we outline\nthe current challenges and suggest potential research and development\ndirections, paving the way for future advancements in this area.\nPaper ID: 2409.13385\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Knowledge-Centric Benchmarking Framework and Empirical Study for\\n  Retrieval-Augmented Generation\u0027, \u0027Shuo Yu (1 and 2), Mingyue Cheng (1 and 2), Jiqian Yang (1 and 2), Jie\\n  Ouyang (1 and 2) ((1) Anhui Province Key Laboratory of Big Data Analysis and\\n  Application, University of Science and Technology of China (2) State Key\\n  Laboratory of Cognitive Intelligence)\u0027):   Retrieval-Augmented Generation (RAG) enhances generative models by\nintegrating retrieval mechanisms, which allow these models to access and\nutilize external knowledge sources. Despite its advantages, RAG encounters\nsignificant challenges, particularly in effectively handling real-world queries\nand mitigating hallucinations. The KDD Cup 2024 CRAG competition brings these\nissues to the forefront by incorporating both web pages and a mock API as\nknowledge sources, adding the complexity of parsing HTML before large language\nmodels (LLMs) can process the information. In this paper, we propose a novel\nRAG benchmark designed to address these challenges. Our work provides a\ncomprehensive set of experimental results, offering valuable insights for the\nstudy of RAG. We thoroughly examine the entire RAG process, including knowledge\nsource selection, retrieval, organization, and reasoning. Key findings from our\nstudy include the impact of automated knowledge source selection using agents\nand the influence of noise chunks on RAG reasoning. Additionally, we conduct\ndetailed experiments to analyze the effects of various hyperparameters on RAG\nperformance. To support further research, we have made our results, the\nassociated code, and a parsed version of the CRAG dataset publicly\navailable\\footnote{https://github.com/USTCAGI/RAG-X}, contributing to the\nadvancement of RAG methodologies and establishing a solid foundation for future\nwork in this domain.", "label": "(\u0027A Knowledge-Centric Benchmarking Framework and Empirical Study for\\n  Retrieval-Augmented Generation\u0027, \u0027Shuo Yu (1 and 2), Mingyue Cheng (1 and 2), Jiqian Yang (1 and 2), Jie\\n  Ouyang (1 and 2) ((1) Anhui Province Key Laboratory of Big Data Analysis and\\n  Application, University of Science and Technology of China (2) State Key\\n  Laboratory of Cognitive Intelligence)\u0027):   Retrieval-Augmented Generation (RAG) enhances generative models by\nintegrating retrieval mechanisms, which allow these models to access and\nutilize external knowledge sources. Despite its advantages, RAG encounters\nsignificant challenges, particularly in effectively handling real-world queries\nand mitigating hallucinations. The KDD Cup 2024 CRAG competition brings these\nissues to the forefront by incorporating both web pages and a mock API as\nknowledge sources, adding the complexity of parsing HTML before large language\nmodels (LLMs) can process the information. In this paper, we propose a novel\nRAG benchmark designed to address these challenges. Our work provides a\ncomprehensive set of experimental results, offering valuable insights for the\nstudy of RAG. We thoroughly examine the entire RAG process, including knowledge\nsource selection, retrieval, organization, and reasoning. Key findings from our\nstudy include the impact of automated knowledge source selection using agents\nand the influence of noise chunks on RAG reasoning. Additionally, we conduct\ndetailed experiments to analyze the effects of various hyperparameters on RAG\nperformance. To support further research, we have made our results, the\nassociated code, and a parsed version of the CRAG dataset publicly\navailable\\footnote{https://github.com/USTCAGI/RAG-X}, contributing to the\nadvancement of RAG methodologies and establishing a solid foundation for future\nwork in this domain.", "shape": "dot", "title": "Node: (\u0027A Knowledge-Centric Benchmarking Framework and Empirical Study for\\n  Retrieval-Augmented Generation\u0027, \u0027Shuo Yu (1 and 2), Mingyue Cheng (1 and 2), Jiqian Yang (1 and 2), Jie\\n  Ouyang (1 and 2) ((1) Anhui Province Key Laboratory of Big Data Analysis and\\n  Application, University of Science and Technology of China (2) State Key\\n  Laboratory of Cognitive Intelligence)\u0027):   Retrieval-Augmented Generation (RAG) enhances generative models by\nintegrating retrieval mechanisms, which allow these models to access and\nutilize external knowledge sources. Despite its advantages, RAG encounters\nsignificant challenges, particularly in effectively handling real-world queries\nand mitigating hallucinations. The KDD Cup 2024 CRAG competition brings these\nissues to the forefront by incorporating both web pages and a mock API as\nknowledge sources, adding the complexity of parsing HTML before large language\nmodels (LLMs) can process the information. In this paper, we propose a novel\nRAG benchmark designed to address these challenges. Our work provides a\ncomprehensive set of experimental results, offering valuable insights for the\nstudy of RAG. We thoroughly examine the entire RAG process, including knowledge\nsource selection, retrieval, organization, and reasoning. Key findings from our\nstudy include the impact of automated knowledge source selection using agents\nand the influence of noise chunks on RAG reasoning. Additionally, we conduct\ndetailed experiments to analyze the effects of various hyperparameters on RAG\nperformance. To support further research, we have made our results, the\nassociated code, and a parsed version of the CRAG dataset publicly\navailable\\footnote{https://github.com/USTCAGI/RAG-X}, contributing to the\nadvancement of RAG methodologies and establishing a solid foundation for future\nwork in this domain.\nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Revisiting the Solution of Meta KDD Cup 2024: CRAG\u0027, \u0027Jie Ouyang, Yucong Luo, Mingyue Cheng, Daoyu Wang, Shuo Yu, Qi Liu,\\n  Enhong Chen\u0027):   This paper presents the solution of our team APEX in the Meta KDD CUP 2024:\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\nmore comprehensive assessment of RAG performance and contributes to advancing\nresearch in this field. We propose a routing-based domain and dynamic adaptive\nRAG pipeline, which performs specific processing for the diverse and dynamic\nnature of the question in all three stages: retrieval, augmentation, and\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\nTask 2\u00263 on the final competition leaderboard. Our implementation is available\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.", "label": "(\u0027Revisiting the Solution of Meta KDD Cup 2024: CRAG\u0027, \u0027Jie Ouyang, Yucong Luo, Mingyue Cheng, Daoyu Wang, Shuo Yu, Qi Liu,\\n  Enhong Chen\u0027):   This paper presents the solution of our team APEX in the Meta KDD CUP 2024:\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\nmore comprehensive assessment of RAG performance and contributes to advancing\nresearch in this field. We propose a routing-based domain and dynamic adaptive\nRAG pipeline, which performs specific processing for the diverse and dynamic\nnature of the question in all three stages: retrieval, augmentation, and\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\nTask 2\u00263 on the final competition leaderboard. Our implementation is available\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.", "shape": "dot", "title": "Node: (\u0027Revisiting the Solution of Meta KDD Cup 2024: CRAG\u0027, \u0027Jie Ouyang, Yucong Luo, Mingyue Cheng, Daoyu Wang, Shuo Yu, Qi Liu,\\n  Enhong Chen\u0027):   This paper presents the solution of our team APEX in the Meta KDD CUP 2024:\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\nmore comprehensive assessment of RAG performance and contributes to advancing\nresearch in this field. We propose a routing-based domain and dynamic adaptive\nRAG pipeline, which performs specific processing for the diverse and dynamic\nnature of the question in all three stages: retrieval, augmentation, and\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\nTask 2\u00263 on the final competition leaderboard. Our implementation is available\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.\nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027, \u0027Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes\u0027):   The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility\u0027\u0027 questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI\u0027s text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.", "label": "(\u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027, \u0027Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes\u0027):   The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility\u0027\u0027 questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI\u0027s text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.", "shape": "dot", "title": "Node: (\u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027, \u0027Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes\u0027):   The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility\u0027\u0027 questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI\u0027s text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.\nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Lighter And Better: Towards Flexible Context Adaptation For Retrieval\\n  Augmented Generation\u0027, \u0027Zheng Liu, Chenyuan Wu, Ninglu Shao, Shitao Xiao, Chaozhuo Li, Defu\\n  Lian\u0027):   The existing Retrieval-Augmented Generation (RAG) systems face significant\nchallenges in terms of cost and effectiveness. On one hand, they need to encode\nthe lengthy retrieved contexts before responding to the input tasks, which\nimposes substantial computational overhead. On the other hand, directly using\ngeneric Large Language Models (LLMs) often leads to sub-optimal answers, while\ntask-specific fine-tuning may compromise the LLMs\u0027 general capabilities. To\naddress these challenges, we introduce a novel approach called FlexRAG\n(Flexible Context Adaptation for RAG). In this approach, the retrieved contexts\nare compressed into compact embeddings before being encoded by the LLMs.\nSimultaneously, these compressed embeddings are optimized to enhance downstream\nRAG performance. A key feature of FlexRAG is its flexibility, which enables\neffective support for diverse compression ratios and selective preservation of\nimportant contexts. Thanks to these technical designs, FlexRAG achieves\nsuperior generation quality while significantly reducing running costs.\nComprehensive experiments on various question-answering datasets validate our\napproach as a cost-effective and flexible solution for RAG systems.", "label": "(\u0027Lighter And Better: Towards Flexible Context Adaptation For Retrieval\\n  Augmented Generation\u0027, \u0027Zheng Liu, Chenyuan Wu, Ninglu Shao, Shitao Xiao, Chaozhuo Li, Defu\\n  Lian\u0027):   The existing Retrieval-Augmented Generation (RAG) systems face significant\nchallenges in terms of cost and effectiveness. On one hand, they need to encode\nthe lengthy retrieved contexts before responding to the input tasks, which\nimposes substantial computational overhead. On the other hand, directly using\ngeneric Large Language Models (LLMs) often leads to sub-optimal answers, while\ntask-specific fine-tuning may compromise the LLMs\u0027 general capabilities. To\naddress these challenges, we introduce a novel approach called FlexRAG\n(Flexible Context Adaptation for RAG). In this approach, the retrieved contexts\nare compressed into compact embeddings before being encoded by the LLMs.\nSimultaneously, these compressed embeddings are optimized to enhance downstream\nRAG performance. A key feature of FlexRAG is its flexibility, which enables\neffective support for diverse compression ratios and selective preservation of\nimportant contexts. Thanks to these technical designs, FlexRAG achieves\nsuperior generation quality while significantly reducing running costs.\nComprehensive experiments on various question-answering datasets validate our\napproach as a cost-effective and flexible solution for RAG systems.", "shape": "dot", "title": "Node: (\u0027Lighter And Better: Towards Flexible Context Adaptation For Retrieval\\n  Augmented Generation\u0027, \u0027Zheng Liu, Chenyuan Wu, Ninglu Shao, Shitao Xiao, Chaozhuo Li, Defu\\n  Lian\u0027):   The existing Retrieval-Augmented Generation (RAG) systems face significant\nchallenges in terms of cost and effectiveness. On one hand, they need to encode\nthe lengthy retrieved contexts before responding to the input tasks, which\nimposes substantial computational overhead. On the other hand, directly using\ngeneric Large Language Models (LLMs) often leads to sub-optimal answers, while\ntask-specific fine-tuning may compromise the LLMs\u0027 general capabilities. To\naddress these challenges, we introduce a novel approach called FlexRAG\n(Flexible Context Adaptation for RAG). In this approach, the retrieved contexts\nare compressed into compact embeddings before being encoded by the LLMs.\nSimultaneously, these compressed embeddings are optimized to enhance downstream\nRAG performance. A key feature of FlexRAG is its flexibility, which enables\neffective support for diverse compression ratios and selective preservation of\nimportant contexts. Thanks to these technical designs, FlexRAG achieves\nsuperior generation quality while significantly reducing running costs.\nComprehensive experiments on various question-answering datasets validate our\napproach as a cost-effective and flexible solution for RAG systems.\nPaper ID: 2409.15699\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Efficient In-Domain Question Answering for Resource-Constrained\\n  Environments\u0027, \u0027Isaac Chung, Phat Vo, Arman C. Kizilkale, Aaron Reite\u0027):   Retrieval Augmented Generation (RAG) is a common method for integrating\nexternal knowledge into pretrained Large Language Models (LLMs) to enhance\naccuracy and relevancy in question answering (QA) tasks. However, prompt\nengineering and resource efficiency remain significant bottlenecks in\ndeveloping optimal and robust RAG solutions for real-world QA applications.\nRecent studies have shown success in using fine tuning to address these\nproblems; in particular, Retrieval Augmented Fine Tuning (RAFT) applied to\nsmaller 7B models has demonstrated superior performance compared to RAG setups\nwith much larger models such as GPT-3.5. The combination of RAFT with\nparameter-efficient fine tuning (PEFT) techniques, such as Low-Rank Adaptation\n(LoRA), promises an even more efficient solution, yet remains an unexplored\narea. In this work, we combine RAFT with LoRA to reduce fine tuning and storage\nrequirements and gain faster inference times while maintaining comparable RAG\nperformance. This results in a more compute-efficient RAFT, or CRAFT, which is\nparticularly useful for knowledge-intensive QA tasks in resource-constrained\nenvironments where internet access may be restricted and hardware resources\nlimited.", "label": "(\u0027Efficient In-Domain Question Answering for Resource-Constrained\\n  Environments\u0027, \u0027Isaac Chung, Phat Vo, Arman C. Kizilkale, Aaron Reite\u0027):   Retrieval Augmented Generation (RAG) is a common method for integrating\nexternal knowledge into pretrained Large Language Models (LLMs) to enhance\naccuracy and relevancy in question answering (QA) tasks. However, prompt\nengineering and resource efficiency remain significant bottlenecks in\ndeveloping optimal and robust RAG solutions for real-world QA applications.\nRecent studies have shown success in using fine tuning to address these\nproblems; in particular, Retrieval Augmented Fine Tuning (RAFT) applied to\nsmaller 7B models has demonstrated superior performance compared to RAG setups\nwith much larger models such as GPT-3.5. The combination of RAFT with\nparameter-efficient fine tuning (PEFT) techniques, such as Low-Rank Adaptation\n(LoRA), promises an even more efficient solution, yet remains an unexplored\narea. In this work, we combine RAFT with LoRA to reduce fine tuning and storage\nrequirements and gain faster inference times while maintaining comparable RAG\nperformance. This results in a more compute-efficient RAFT, or CRAFT, which is\nparticularly useful for knowledge-intensive QA tasks in resource-constrained\nenvironments where internet access may be restricted and hardware resources\nlimited.", "shape": "dot", "title": "Node: (\u0027Efficient In-Domain Question Answering for Resource-Constrained\\n  Environments\u0027, \u0027Isaac Chung, Phat Vo, Arman C. Kizilkale, Aaron Reite\u0027):   Retrieval Augmented Generation (RAG) is a common method for integrating\nexternal knowledge into pretrained Large Language Models (LLMs) to enhance\naccuracy and relevancy in question answering (QA) tasks. However, prompt\nengineering and resource efficiency remain significant bottlenecks in\ndeveloping optimal and robust RAG solutions for real-world QA applications.\nRecent studies have shown success in using fine tuning to address these\nproblems; in particular, Retrieval Augmented Fine Tuning (RAFT) applied to\nsmaller 7B models has demonstrated superior performance compared to RAG setups\nwith much larger models such as GPT-3.5. The combination of RAFT with\nparameter-efficient fine tuning (PEFT) techniques, such as Low-Rank Adaptation\n(LoRA), promises an even more efficient solution, yet remains an unexplored\narea. In this work, we combine RAFT with LoRA to reduce fine tuning and storage\nrequirements and gain faster inference times while maintaining comparable RAG\nperformance. This results in a more compute-efficient RAFT, or CRAFT, which is\nparticularly useful for knowledge-intensive QA tasks in resource-constrained\nenvironments where internet access may be restricted and hardware resources\nlimited.\nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the\\n  E-commerce Domain\u0027, \u0027Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang and Ruihua Song\u0027):   Retrieval Augmented Generation (RAG) system is important in domains such as\ne-commerce, which has many long-tail entities and frequently updated\ninformation. Most existing works adopt separate modules for retrieval and\ngeneration, which may be suboptimal since the retrieval task and the generation\ntask cannot benefit from each other to improve performance. We propose a novel\nBackbone Shared RAG framework (BSharedRAG). It first uses a domain-specific\ncorpus to continually pre-train a base model as a domain-specific backbone\nmodel and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules\nbased on the shared backbone to minimize retrieval and generation losses\nrespectively. Experimental results indicate that our proposed BSharedRAG\noutperforms baseline models by 5% and 13% in Hit@3 upon two datasets in\nretrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.\nOur codes, models, and dataset are available at https://bsharedrag.github.io.", "label": "(\u0027BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the\\n  E-commerce Domain\u0027, \u0027Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang and Ruihua Song\u0027):   Retrieval Augmented Generation (RAG) system is important in domains such as\ne-commerce, which has many long-tail entities and frequently updated\ninformation. Most existing works adopt separate modules for retrieval and\ngeneration, which may be suboptimal since the retrieval task and the generation\ntask cannot benefit from each other to improve performance. We propose a novel\nBackbone Shared RAG framework (BSharedRAG). It first uses a domain-specific\ncorpus to continually pre-train a base model as a domain-specific backbone\nmodel and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules\nbased on the shared backbone to minimize retrieval and generation losses\nrespectively. Experimental results indicate that our proposed BSharedRAG\noutperforms baseline models by 5% and 13% in Hit@3 upon two datasets in\nretrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.\nOur codes, models, and dataset are available at https://bsharedrag.github.io.", "shape": "dot", "title": "Node: (\u0027BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the\\n  E-commerce Domain\u0027, \u0027Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang and Ruihua Song\u0027):   Retrieval Augmented Generation (RAG) system is important in domains such as\ne-commerce, which has many long-tail entities and frequently updated\ninformation. Most existing works adopt separate modules for retrieval and\ngeneration, which may be suboptimal since the retrieval task and the generation\ntask cannot benefit from each other to improve performance. We propose a novel\nBackbone Shared RAG framework (BSharedRAG). It first uses a domain-specific\ncorpus to continually pre-train a base model as a domain-specific backbone\nmodel and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules\nbased on the shared backbone to minimize retrieval and generation losses\nrespectively. Experimental results indicate that our proposed BSharedRAG\noutperforms baseline models by 5% and 13% in Hit@3 upon two datasets in\nretrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.\nOur codes, models, and dataset are available at https://bsharedrag.github.io.\nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Retro-li: Small-Scale Retrieval Augmented Generation Supporting Noisy\\n  Similarity Searches and Domain Shift Generalization\u0027, \u0027Gentiana Rashiti, Geethan Karunaratne, Mrinmaya Sachan, Abu Sebastian,\\n  Abbas Rahimi\u0027):   The retrieval augmented generation (RAG) system such as Retro has been shown\nto improve language modeling capabilities and reduce toxicity and\nhallucinations by retrieving from a database of non-parametric memory\ncontaining trillions of entries. We introduce Retro-li that shows retrieval can\nalso help using a small-scale database, but it demands more accurate and better\nneighbors when searching in a smaller hence sparser non-parametric memory. This\ncan be met by using a proper semantic similarity search. We further propose\nadding a regularization to the non-parametric memory for the first time: it\nsignificantly reduces perplexity when the neighbor search operations are noisy\nduring inference, and it improves generalization when a domain shift occurs. We\nalso show that Retro-li\u0027s non-parametric memory can potentially be implemented\non analog in-memory computing hardware, exhibiting O(1) search time while\ncausing noise in retrieving neighbors, with minimal (\u003c1%) performance loss. Our\ncode is available at:\nhttps://github.com/IBM/Retrieval-Enhanced-Transformer-Little.", "label": "(\u0027Retro-li: Small-Scale Retrieval Augmented Generation Supporting Noisy\\n  Similarity Searches and Domain Shift Generalization\u0027, \u0027Gentiana Rashiti, Geethan Karunaratne, Mrinmaya Sachan, Abu Sebastian,\\n  Abbas Rahimi\u0027):   The retrieval augmented generation (RAG) system such as Retro has been shown\nto improve language modeling capabilities and reduce toxicity and\nhallucinations by retrieving from a database of non-parametric memory\ncontaining trillions of entries. We introduce Retro-li that shows retrieval can\nalso help using a small-scale database, but it demands more accurate and better\nneighbors when searching in a smaller hence sparser non-parametric memory. This\ncan be met by using a proper semantic similarity search. We further propose\nadding a regularization to the non-parametric memory for the first time: it\nsignificantly reduces perplexity when the neighbor search operations are noisy\nduring inference, and it improves generalization when a domain shift occurs. We\nalso show that Retro-li\u0027s non-parametric memory can potentially be implemented\non analog in-memory computing hardware, exhibiting O(1) search time while\ncausing noise in retrieving neighbors, with minimal (\u003c1%) performance loss. Our\ncode is available at:\nhttps://github.com/IBM/Retrieval-Enhanced-Transformer-Little.", "shape": "dot", "title": "Node: (\u0027Retro-li: Small-Scale Retrieval Augmented Generation Supporting Noisy\\n  Similarity Searches and Domain Shift Generalization\u0027, \u0027Gentiana Rashiti, Geethan Karunaratne, Mrinmaya Sachan, Abu Sebastian,\\n  Abbas Rahimi\u0027):   The retrieval augmented generation (RAG) system such as Retro has been shown\nto improve language modeling capabilities and reduce toxicity and\nhallucinations by retrieving from a database of non-parametric memory\ncontaining trillions of entries. We introduce Retro-li that shows retrieval can\nalso help using a small-scale database, but it demands more accurate and better\nneighbors when searching in a smaller hence sparser non-parametric memory. This\ncan be met by using a proper semantic similarity search. We further propose\nadding a regularization to the non-parametric memory for the first time: it\nsignificantly reduces perplexity when the neighbor search operations are noisy\nduring inference, and it improves generalization when a domain shift occurs. We\nalso show that Retro-li\u0027s non-parametric memory can potentially be implemented\non analog in-memory computing hardware, exhibiting O(1) search time while\ncausing noise in retrieving neighbors, with minimal (\u003c1%) performance loss. Our\ncode is available at:\nhttps://github.com/IBM/Retrieval-Enhanced-Transformer-Little.\nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027How Much Can RAG Help the Reasoning of LLM?\u0027, \u0027Jingyu Liu, Jiaen Lin, Yong Liu\u0027):   Retrieval-Augmented Generation (RAG) has gained significant popularity in\nmodern Large Language Models (LLMs) due to its effectiveness in introducing new\nknowledge and reducing hallucinations. However, the deep understanding of RAG\nremains limited, how does RAG help the reasoning process and can RAG help\nimprove the reasoning capability remains question. While external documents are\ntypically considered as a method to incorporate domain-specific information,\nthey also contain intermediate reasoning results related to the query, this\nsuggests that documents could enhance the reasoning capability of LLMs, which\nhas not been previously explored. In this paper, we investigate this issue in\ndepth and find that while RAG can assist with reasoning, the help is limited.\nIf we conceptualize the reasoning process as a tree with fixed depth, then RAG\nstruggles to assist LLMs in performing deeper reasoning. Additionally, the\ninformation in the documents requires preprocessing to filter out noise. We\ndemonstrate that this preprocessing is difficult to achieve simply fine-tuning\nof the LLM, it often necessitates numerous additional transformer layers to\nsolve the problem. To simplify the problem, we propose DPrompt tuning, which\neffectively resolves the issue within just limited transformer layers, leading\nto improved performance.", "label": "(\u0027How Much Can RAG Help the Reasoning of LLM?\u0027, \u0027Jingyu Liu, Jiaen Lin, Yong Liu\u0027):   Retrieval-Augmented Generation (RAG) has gained significant popularity in\nmodern Large Language Models (LLMs) due to its effectiveness in introducing new\nknowledge and reducing hallucinations. However, the deep understanding of RAG\nremains limited, how does RAG help the reasoning process and can RAG help\nimprove the reasoning capability remains question. While external documents are\ntypically considered as a method to incorporate domain-specific information,\nthey also contain intermediate reasoning results related to the query, this\nsuggests that documents could enhance the reasoning capability of LLMs, which\nhas not been previously explored. In this paper, we investigate this issue in\ndepth and find that while RAG can assist with reasoning, the help is limited.\nIf we conceptualize the reasoning process as a tree with fixed depth, then RAG\nstruggles to assist LLMs in performing deeper reasoning. Additionally, the\ninformation in the documents requires preprocessing to filter out noise. We\ndemonstrate that this preprocessing is difficult to achieve simply fine-tuning\nof the LLM, it often necessitates numerous additional transformer layers to\nsolve the problem. To simplify the problem, we propose DPrompt tuning, which\neffectively resolves the issue within just limited transformer layers, leading\nto improved performance.", "shape": "dot", "title": "Node: (\u0027How Much Can RAG Help the Reasoning of LLM?\u0027, \u0027Jingyu Liu, Jiaen Lin, Yong Liu\u0027):   Retrieval-Augmented Generation (RAG) has gained significant popularity in\nmodern Large Language Models (LLMs) due to its effectiveness in introducing new\nknowledge and reducing hallucinations. However, the deep understanding of RAG\nremains limited, how does RAG help the reasoning process and can RAG help\nimprove the reasoning capability remains question. While external documents are\ntypically considered as a method to incorporate domain-specific information,\nthey also contain intermediate reasoning results related to the query, this\nsuggests that documents could enhance the reasoning capability of LLMs, which\nhas not been previously explored. In this paper, we investigate this issue in\ndepth and find that while RAG can assist with reasoning, the help is limited.\nIf we conceptualize the reasoning process as a tree with fixed depth, then RAG\nstruggles to assist LLMs in performing deeper reasoning. Additionally, the\ninformation in the documents requires preprocessing to filter out noise. We\ndemonstrate that this preprocessing is difficult to achieve simply fine-tuning\nof the LLM, it often necessitates numerous additional transformer layers to\nsolve the problem. To simplify the problem, we propose DPrompt tuning, which\neffectively resolves the issue within just limited transformer layers, leading\nto improved performance.\nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Enhancing Retrieval in QA Systems with Derived Feature Association\u0027, \u0027Keyush Shah and Abhishek Goyal and Isaac Wasserman\u0027):   Retrieval augmented generation (RAG) has become the standard in long context\nquestion answering (QA) systems. However, typical implementations of RAG rely\non a rather naive retrieval mechanism, in which texts whose embeddings are most\nsimilar to that of the query are deemed most relevant. This has consequences in\nsubjective QA tasks, where the most relevant text may not directly contain the\nanswer. In this work, we propose a novel extension to RAG systems, which we\ncall Retrieval from AI Derived Documents (RAIDD). RAIDD leverages the full\npower of the LLM in the retrieval process by deriving inferred features, such\nas summaries and example questions, from the documents at ingest. We\ndemonstrate that this approach significantly improves the performance of RAG\nsystems on long-context QA tasks.", "label": "(\u0027Enhancing Retrieval in QA Systems with Derived Feature Association\u0027, \u0027Keyush Shah and Abhishek Goyal and Isaac Wasserman\u0027):   Retrieval augmented generation (RAG) has become the standard in long context\nquestion answering (QA) systems. However, typical implementations of RAG rely\non a rather naive retrieval mechanism, in which texts whose embeddings are most\nsimilar to that of the query are deemed most relevant. This has consequences in\nsubjective QA tasks, where the most relevant text may not directly contain the\nanswer. In this work, we propose a novel extension to RAG systems, which we\ncall Retrieval from AI Derived Documents (RAIDD). RAIDD leverages the full\npower of the LLM in the retrieval process by deriving inferred features, such\nas summaries and example questions, from the documents at ingest. We\ndemonstrate that this approach significantly improves the performance of RAG\nsystems on long-context QA tasks.", "shape": "dot", "title": "Node: (\u0027Enhancing Retrieval in QA Systems with Derived Feature Association\u0027, \u0027Keyush Shah and Abhishek Goyal and Isaac Wasserman\u0027):   Retrieval augmented generation (RAG) has become the standard in long context\nquestion answering (QA) systems. However, typical implementations of RAG rely\non a rather naive retrieval mechanism, in which texts whose embeddings are most\nsimilar to that of the query are deemed most relevant. This has consequences in\nsubjective QA tasks, where the most relevant text may not directly contain the\nanswer. In this work, we propose a novel extension to RAG systems, which we\ncall Retrieval from AI Derived Documents (RAIDD). RAIDD leverages the full\npower of the LLM in the retrieval process by deriving inferred features, such\nas summaries and example questions, from the documents at ingest. We\ndemonstrate that this approach significantly improves the performance of RAG\nsystems on long-context QA tasks.\nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via\\n  Inference-time Hybrid Information Structurization\u0027, \u0027Zhuoqun Li, Xuanang Chen, Haiyang Yu, Hongyu Lin, Yaojie Lu, Qiaoyu\\n  Tang, Fei Huang, Xianpei Han, Le Sun, Yongbin Li\u0027):   Retrieval-augmented generation (RAG) is a key means to effectively enhance\nlarge language models (LLMs) in many knowledge-based tasks. However, existing\nRAG methods struggle with knowledge-intensive reasoning tasks, because useful\ninformation required to these tasks are badly scattered. This characteristic\nmakes it difficult for existing RAG methods to accurately identify key\ninformation and perform global reasoning with such noisy augmentation. In this\npaper, motivated by the cognitive theories that humans convert raw information\ninto various structured knowledge when tackling knowledge-intensive reasoning,\nwe proposes a new framework, StructRAG, which can identify the optimal\nstructure type for the task at hand, reconstruct original documents into this\nstructured format, and infer answers based on the resulting structure.\nExtensive experiments across various knowledge-intensive tasks show that\nStructRAG achieves state-of-the-art performance, particularly excelling in\nchallenging scenarios, demonstrating its potential as an effective solution for\nenhancing LLMs in complex real-world applications.", "label": "(\u0027StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via\\n  Inference-time Hybrid Information Structurization\u0027, \u0027Zhuoqun Li, Xuanang Chen, Haiyang Yu, Hongyu Lin, Yaojie Lu, Qiaoyu\\n  Tang, Fei Huang, Xianpei Han, Le Sun, Yongbin Li\u0027):   Retrieval-augmented generation (RAG) is a key means to effectively enhance\nlarge language models (LLMs) in many knowledge-based tasks. However, existing\nRAG methods struggle with knowledge-intensive reasoning tasks, because useful\ninformation required to these tasks are badly scattered. This characteristic\nmakes it difficult for existing RAG methods to accurately identify key\ninformation and perform global reasoning with such noisy augmentation. In this\npaper, motivated by the cognitive theories that humans convert raw information\ninto various structured knowledge when tackling knowledge-intensive reasoning,\nwe proposes a new framework, StructRAG, which can identify the optimal\nstructure type for the task at hand, reconstruct original documents into this\nstructured format, and infer answers based on the resulting structure.\nExtensive experiments across various knowledge-intensive tasks show that\nStructRAG achieves state-of-the-art performance, particularly excelling in\nchallenging scenarios, demonstrating its potential as an effective solution for\nenhancing LLMs in complex real-world applications.", "shape": "dot", "title": "Node: (\u0027StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via\\n  Inference-time Hybrid Information Structurization\u0027, \u0027Zhuoqun Li, Xuanang Chen, Haiyang Yu, Hongyu Lin, Yaojie Lu, Qiaoyu\\n  Tang, Fei Huang, Xianpei Han, Le Sun, Yongbin Li\u0027):   Retrieval-augmented generation (RAG) is a key means to effectively enhance\nlarge language models (LLMs) in many knowledge-based tasks. However, existing\nRAG methods struggle with knowledge-intensive reasoning tasks, because useful\ninformation required to these tasks are badly scattered. This characteristic\nmakes it difficult for existing RAG methods to accurately identify key\ninformation and perform global reasoning with such noisy augmentation. In this\npaper, motivated by the cognitive theories that humans convert raw information\ninto various structured knowledge when tackling knowledge-intensive reasoning,\nwe proposes a new framework, StructRAG, which can identify the optimal\nstructure type for the task at hand, reconstruct original documents into this\nstructured format, and infer answers based on the resulting structure.\nExtensive experiments across various knowledge-intensive tasks show that\nStructRAG achieves state-of-the-art performance, particularly excelling in\nchallenging scenarios, demonstrating its potential as an effective solution for\nenhancing LLMs in complex real-world applications.\nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Learning to Rank for Multiple Retrieval-Augmented Models through\\n  Iterative Utility Maximization\u0027, \u0027Alireza Salemi, Hamed Zamani\u0027):   This paper investigates the design of a unified search engine to serve\nmultiple retrieval-augmented generation (RAG) agents, each with a distinct\ntask, backbone large language model (LLM), and retrieval-augmentation strategy.\nWe introduce an iterative approach where the search engine generates retrieval\nresults for these RAG agents and gathers feedback on the quality of the\nretrieved documents during an offline phase. This feedback is then used to\niteratively optimize the search engine using a novel expectation-maximization\nalgorithm, with the goal of maximizing each agent\u0027s utility function.\nAdditionally, we adapt this approach to an online setting, allowing the search\nengine to refine its behavior based on real-time individual agents feedback to\nbetter serve the results for each of them. Experiments on diverse datasets from\nthe Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our\napproach significantly on average outperforms competitive baselines across 18\nRAG models. We also demonstrate that our method effectively ``personalizes\u0027\u0027\nthe retrieval process for each RAG agent based on the collected feedback.\nFinally, we provide a comprehensive ablation study to explore various aspects\nof our method.", "label": "(\u0027Learning to Rank for Multiple Retrieval-Augmented Models through\\n  Iterative Utility Maximization\u0027, \u0027Alireza Salemi, Hamed Zamani\u0027):   This paper investigates the design of a unified search engine to serve\nmultiple retrieval-augmented generation (RAG) agents, each with a distinct\ntask, backbone large language model (LLM), and retrieval-augmentation strategy.\nWe introduce an iterative approach where the search engine generates retrieval\nresults for these RAG agents and gathers feedback on the quality of the\nretrieved documents during an offline phase. This feedback is then used to\niteratively optimize the search engine using a novel expectation-maximization\nalgorithm, with the goal of maximizing each agent\u0027s utility function.\nAdditionally, we adapt this approach to an online setting, allowing the search\nengine to refine its behavior based on real-time individual agents feedback to\nbetter serve the results for each of them. Experiments on diverse datasets from\nthe Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our\napproach significantly on average outperforms competitive baselines across 18\nRAG models. We also demonstrate that our method effectively ``personalizes\u0027\u0027\nthe retrieval process for each RAG agent based on the collected feedback.\nFinally, we provide a comprehensive ablation study to explore various aspects\nof our method.", "shape": "dot", "title": "Node: (\u0027Learning to Rank for Multiple Retrieval-Augmented Models through\\n  Iterative Utility Maximization\u0027, \u0027Alireza Salemi, Hamed Zamani\u0027):   This paper investigates the design of a unified search engine to serve\nmultiple retrieval-augmented generation (RAG) agents, each with a distinct\ntask, backbone large language model (LLM), and retrieval-augmentation strategy.\nWe introduce an iterative approach where the search engine generates retrieval\nresults for these RAG agents and gathers feedback on the quality of the\nretrieved documents during an offline phase. This feedback is then used to\niteratively optimize the search engine using a novel expectation-maximization\nalgorithm, with the goal of maximizing each agent\u0027s utility function.\nAdditionally, we adapt this approach to an online setting, allowing the search\nengine to refine its behavior based on real-time individual agents feedback to\nbetter serve the results for each of them. Experiments on diverse datasets from\nthe Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our\napproach significantly on average outperforms competitive baselines across 18\nRAG models. We also demonstrate that our method effectively ``personalizes\u0027\u0027\nthe retrieval process for each RAG agent based on the collected feedback.\nFinally, we provide a comprehensive ablation study to explore various aspects\nof our method.\nPaper ID: 2410.09942\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG\u0027, \u0027Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang\\n  Li, Baotian Hu, Min Zhang\u0027):   Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It\nmainly consists of retrieval and generation. The retrieval modules (a.k.a.\nretrievers) aim to find useful information used to facilitate generation\nmodules (a.k.a. generators). As such, generators\u0027 performance largely depends\non the effectiveness and efficiency of retrievers. However, the retrieval\nparadigm that we design and use remains flat, which treats the retrieval\nprocedures as a one-off deal with constant granularity. Despite effectiveness,\nwe argue that they suffer from two limitations: (1) flat retrieval exerts a\nsignificant burden on one retriever; (2) constant granularity limits the\nceiling of retrieval performance. In this work, we propose a progressive\nretrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,\nso as to balance effectiveness and efficiency. Specifically, FunnelRAG\nestablishes a progressive retrieval pipeline by collaborating coarse-to-fine\ngranularity, large-to-small quantity, and low-to-high capacity, which can\nrelieve the burden on one retriever and also promote the ceiling of retrieval\nperformance. Extensive experiments manifest that FunnelRAG achieves comparable\nretrieval performance while the time overhead is reduced by nearly 40 percent.", "label": "(\u0027FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG\u0027, \u0027Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang\\n  Li, Baotian Hu, Min Zhang\u0027):   Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It\nmainly consists of retrieval and generation. The retrieval modules (a.k.a.\nretrievers) aim to find useful information used to facilitate generation\nmodules (a.k.a. generators). As such, generators\u0027 performance largely depends\non the effectiveness and efficiency of retrievers. However, the retrieval\nparadigm that we design and use remains flat, which treats the retrieval\nprocedures as a one-off deal with constant granularity. Despite effectiveness,\nwe argue that they suffer from two limitations: (1) flat retrieval exerts a\nsignificant burden on one retriever; (2) constant granularity limits the\nceiling of retrieval performance. In this work, we propose a progressive\nretrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,\nso as to balance effectiveness and efficiency. Specifically, FunnelRAG\nestablishes a progressive retrieval pipeline by collaborating coarse-to-fine\ngranularity, large-to-small quantity, and low-to-high capacity, which can\nrelieve the burden on one retriever and also promote the ceiling of retrieval\nperformance. Extensive experiments manifest that FunnelRAG achieves comparable\nretrieval performance while the time overhead is reduced by nearly 40 percent.", "shape": "dot", "title": "Node: (\u0027FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG\u0027, \u0027Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang\\n  Li, Baotian Hu, Min Zhang\u0027):   Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It\nmainly consists of retrieval and generation. The retrieval modules (a.k.a.\nretrievers) aim to find useful information used to facilitate generation\nmodules (a.k.a. generators). As such, generators\u0027 performance largely depends\non the effectiveness and efficiency of retrievers. However, the retrieval\nparadigm that we design and use remains flat, which treats the retrieval\nprocedures as a one-off deal with constant granularity. Despite effectiveness,\nwe argue that they suffer from two limitations: (1) flat retrieval exerts a\nsignificant burden on one retriever; (2) constant granularity limits the\nceiling of retrieval performance. In this work, we propose a progressive\nretrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,\nso as to balance effectiveness and efficiency. Specifically, FunnelRAG\nestablishes a progressive retrieval pipeline by collaborating coarse-to-fine\ngranularity, large-to-small quantity, and low-to-high capacity, which can\nrelieve the burden on one retriever and also promote the ceiling of retrieval\nperformance. Extensive experiments manifest that FunnelRAG achieves comparable\nretrieval performance while the time overhead is reduced by nearly 40 percent.\nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Self-adaptive Multimodal Retrieval-Augmented Generation\u0027, \u0027Wenjia Zhai\u0027):   Traditional Retrieval-Augmented Generation (RAG) methods are limited by their\nreliance on a fixed number of retrieved documents, often resulting in\nincomplete or noisy information that undermines task performance. Although\nrecent adaptive approaches alleviated these problems, their application in\nintricate and real-world multimodal tasks remains limited. To address these, we\npropose a new approach called Self-adaptive Multimodal Retrieval-Augmented\nGeneration (SAM-RAG), tailored specifically for multimodal contexts. SAM-RAG\nnot only dynamically filters relevant documents based on the input query,\nincluding image captions when needed, but also verifies the quality of both the\nretrieved documents and the output. Extensive experimental results show that\nSAM-RAG surpasses existing state-of-the-art methods in both retrieval accuracy\nand response generation. By further ablation experiments and effectiveness\nanalysis, SAM-RAG maintains high recall quality while improving overall task\nperformance in multimodal RAG task. Our codes are available at\nhttps://github.com/SAM-RAG/SAM_RAG.", "label": "(\u0027Self-adaptive Multimodal Retrieval-Augmented Generation\u0027, \u0027Wenjia Zhai\u0027):   Traditional Retrieval-Augmented Generation (RAG) methods are limited by their\nreliance on a fixed number of retrieved documents, often resulting in\nincomplete or noisy information that undermines task performance. Although\nrecent adaptive approaches alleviated these problems, their application in\nintricate and real-world multimodal tasks remains limited. To address these, we\npropose a new approach called Self-adaptive Multimodal Retrieval-Augmented\nGeneration (SAM-RAG), tailored specifically for multimodal contexts. SAM-RAG\nnot only dynamically filters relevant documents based on the input query,\nincluding image captions when needed, but also verifies the quality of both the\nretrieved documents and the output. Extensive experimental results show that\nSAM-RAG surpasses existing state-of-the-art methods in both retrieval accuracy\nand response generation. By further ablation experiments and effectiveness\nanalysis, SAM-RAG maintains high recall quality while improving overall task\nperformance in multimodal RAG task. Our codes are available at\nhttps://github.com/SAM-RAG/SAM_RAG.", "shape": "dot", "title": "Node: (\u0027Self-adaptive Multimodal Retrieval-Augmented Generation\u0027, \u0027Wenjia Zhai\u0027):   Traditional Retrieval-Augmented Generation (RAG) methods are limited by their\nreliance on a fixed number of retrieved documents, often resulting in\nincomplete or noisy information that undermines task performance. Although\nrecent adaptive approaches alleviated these problems, their application in\nintricate and real-world multimodal tasks remains limited. To address these, we\npropose a new approach called Self-adaptive Multimodal Retrieval-Augmented\nGeneration (SAM-RAG), tailored specifically for multimodal contexts. SAM-RAG\nnot only dynamically filters relevant documents based on the input query,\nincluding image captions when needed, but also verifies the quality of both the\nretrieved documents and the output. Extensive experimental results show that\nSAM-RAG surpasses existing state-of-the-art methods in both retrieval accuracy\nand response generation. By further ablation experiments and effectiveness\nanalysis, SAM-RAG maintains high recall quality while improving overall task\nperformance in multimodal RAG task. Our codes are available at\nhttps://github.com/SAM-RAG/SAM_RAG.\nPaper ID: 2410.11321\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for\\n  Retrieval-Augmented Generation with Enhanced Data Diversity\u0027, \u0027Jintao Liu, Ruixue Ding, Linhao Zhang, Pengjun Xie, Fie Huang\u0027):   Retrieval-Augmented Generation (RAG) aims to enhance large language models\n(LLMs) to generate more accurate and reliable answers with the help of the\nretrieved context from external knowledge sources, thereby reducing the\nincidence of hallucinations. Despite the advancements, evaluating these systems\nremains a crucial research area due to the following issues: (1) Limited data\ndiversity: The insufficient diversity of knowledge sources and query types\nconstrains the applicability of RAG systems; (2) Obscure problems location:\nExisting evaluation methods have difficulty in locating the stage of the RAG\npipeline where problems occur; (3) Unstable retrieval evaluation: These methods\noften fail to effectively assess retrieval performance, particularly when the\nchunking strategy changes. To tackle these challenges, we propose a\nComprehensive Full-chain Evaluation (CoFE-RAG) framework to facilitate thorough\nevaluation across the entire RAG pipeline, including chunking, retrieval,\nreranking, and generation. To effectively evaluate the first three phases, we\nintroduce multi-granularity keywords, including coarse-grained and fine-grained\nkeywords, to assess the retrieved context instead of relying on the annotation\nof golden chunks. Moreover, we release a holistic benchmark dataset tailored\nfor diverse data scenarios covering a wide range of document formats and query\ntypes. We demonstrate the utility of the CoFE-RAG framework by conducting\nexperiments to evaluate each stage of RAG systems. Our evaluation method\nprovides unique insights into the effectiveness of RAG systems in handling\ndiverse data scenarios, offering a more nuanced understanding of their\ncapabilities and limitations.", "label": "(\u0027CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for\\n  Retrieval-Augmented Generation with Enhanced Data Diversity\u0027, \u0027Jintao Liu, Ruixue Ding, Linhao Zhang, Pengjun Xie, Fie Huang\u0027):   Retrieval-Augmented Generation (RAG) aims to enhance large language models\n(LLMs) to generate more accurate and reliable answers with the help of the\nretrieved context from external knowledge sources, thereby reducing the\nincidence of hallucinations. Despite the advancements, evaluating these systems\nremains a crucial research area due to the following issues: (1) Limited data\ndiversity: The insufficient diversity of knowledge sources and query types\nconstrains the applicability of RAG systems; (2) Obscure problems location:\nExisting evaluation methods have difficulty in locating the stage of the RAG\npipeline where problems occur; (3) Unstable retrieval evaluation: These methods\noften fail to effectively assess retrieval performance, particularly when the\nchunking strategy changes. To tackle these challenges, we propose a\nComprehensive Full-chain Evaluation (CoFE-RAG) framework to facilitate thorough\nevaluation across the entire RAG pipeline, including chunking, retrieval,\nreranking, and generation. To effectively evaluate the first three phases, we\nintroduce multi-granularity keywords, including coarse-grained and fine-grained\nkeywords, to assess the retrieved context instead of relying on the annotation\nof golden chunks. Moreover, we release a holistic benchmark dataset tailored\nfor diverse data scenarios covering a wide range of document formats and query\ntypes. We demonstrate the utility of the CoFE-RAG framework by conducting\nexperiments to evaluate each stage of RAG systems. Our evaluation method\nprovides unique insights into the effectiveness of RAG systems in handling\ndiverse data scenarios, offering a more nuanced understanding of their\ncapabilities and limitations.", "shape": "dot", "title": "Node: (\u0027CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for\\n  Retrieval-Augmented Generation with Enhanced Data Diversity\u0027, \u0027Jintao Liu, Ruixue Ding, Linhao Zhang, Pengjun Xie, Fie Huang\u0027):   Retrieval-Augmented Generation (RAG) aims to enhance large language models\n(LLMs) to generate more accurate and reliable answers with the help of the\nretrieved context from external knowledge sources, thereby reducing the\nincidence of hallucinations. Despite the advancements, evaluating these systems\nremains a crucial research area due to the following issues: (1) Limited data\ndiversity: The insufficient diversity of knowledge sources and query types\nconstrains the applicability of RAG systems; (2) Obscure problems location:\nExisting evaluation methods have difficulty in locating the stage of the RAG\npipeline where problems occur; (3) Unstable retrieval evaluation: These methods\noften fail to effectively assess retrieval performance, particularly when the\nchunking strategy changes. To tackle these challenges, we propose a\nComprehensive Full-chain Evaluation (CoFE-RAG) framework to facilitate thorough\nevaluation across the entire RAG pipeline, including chunking, retrieval,\nreranking, and generation. To effectively evaluate the first three phases, we\nintroduce multi-granularity keywords, including coarse-grained and fine-grained\nkeywords, to assess the retrieved context instead of relying on the annotation\nof golden chunks. Moreover, we release a holistic benchmark dataset tailored\nfor diverse data scenarios covering a wide range of document formats and query\ntypes. We demonstrate the utility of the CoFE-RAG framework by conducting\nexperiments to evaluate each stage of RAG systems. Our evaluation method\nprovides unique insights into the effectiveness of RAG systems in handling\ndiverse data scenarios, offering a more nuanced understanding of their\ncapabilities and limitations.\nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Comprehensive Survey of Retrieval-Augmented Generation (RAG):\\n  Evolution, Current Landscape and Future Directions\u0027, \u0027Shailja Gupta, Rajesh Ranjan, Surya Narayan Singh\u0027):   This paper presents a comprehensive study of Retrieval-Augmented Generation\n(RAG), tracing its evolution from foundational concepts to the current state of\nthe art. RAG combines retrieval mechanisms with generative language models to\nenhance the accuracy of outputs, addressing key limitations of LLMs. The study\nexplores the basic architecture of RAG, focusing on how retrieval and\ngeneration are integrated to handle knowledge-intensive tasks. A detailed\nreview of the significant technological advancements in RAG is provided,\nincluding key innovations in retrieval-augmented language models and\napplications across various domains such as question-answering, summarization,\nand knowledge-based tasks. Recent research breakthroughs are discussed,\nhighlighting novel methods for improving retrieval efficiency. Furthermore, the\npaper examines ongoing challenges such as scalability, bias, and ethical\nconcerns in deployment. Future research directions are proposed, focusing on\nimproving the robustness of RAG models, expanding the scope of application of\nRAG models, and addressing societal implications. This survey aims to serve as\na foundational resource for researchers and practitioners in understanding the\npotential of RAG and its trajectory in natural language processing.", "label": "(\u0027A Comprehensive Survey of Retrieval-Augmented Generation (RAG):\\n  Evolution, Current Landscape and Future Directions\u0027, \u0027Shailja Gupta, Rajesh Ranjan, Surya Narayan Singh\u0027):   This paper presents a comprehensive study of Retrieval-Augmented Generation\n(RAG), tracing its evolution from foundational concepts to the current state of\nthe art. RAG combines retrieval mechanisms with generative language models to\nenhance the accuracy of outputs, addressing key limitations of LLMs. The study\nexplores the basic architecture of RAG, focusing on how retrieval and\ngeneration are integrated to handle knowledge-intensive tasks. A detailed\nreview of the significant technological advancements in RAG is provided,\nincluding key innovations in retrieval-augmented language models and\napplications across various domains such as question-answering, summarization,\nand knowledge-based tasks. Recent research breakthroughs are discussed,\nhighlighting novel methods for improving retrieval efficiency. Furthermore, the\npaper examines ongoing challenges such as scalability, bias, and ethical\nconcerns in deployment. Future research directions are proposed, focusing on\nimproving the robustness of RAG models, expanding the scope of application of\nRAG models, and addressing societal implications. This survey aims to serve as\na foundational resource for researchers and practitioners in understanding the\npotential of RAG and its trajectory in natural language processing.", "shape": "dot", "title": "Node: (\u0027A Comprehensive Survey of Retrieval-Augmented Generation (RAG):\\n  Evolution, Current Landscape and Future Directions\u0027, \u0027Shailja Gupta, Rajesh Ranjan, Surya Narayan Singh\u0027):   This paper presents a comprehensive study of Retrieval-Augmented Generation\n(RAG), tracing its evolution from foundational concepts to the current state of\nthe art. RAG combines retrieval mechanisms with generative language models to\nenhance the accuracy of outputs, addressing key limitations of LLMs. The study\nexplores the basic architecture of RAG, focusing on how retrieval and\ngeneration are integrated to handle knowledge-intensive tasks. A detailed\nreview of the significant technological advancements in RAG is provided,\nincluding key innovations in retrieval-augmented language models and\napplications across various domains such as question-answering, summarization,\nand knowledge-based tasks. Recent research breakthroughs are discussed,\nhighlighting novel methods for improving retrieval efficiency. Furthermore, the\npaper examines ongoing challenges such as scalability, bias, and ethical\nconcerns in deployment. Future research directions are proposed, focusing on\nimproving the robustness of RAG models, expanding the scope of application of\nRAG models, and addressing societal implications. This survey aims to serve as\na foundational resource for researchers and practitioners in understanding the\npotential of RAG and its trajectory in natural language processing.\nPaper ID: 2410.12837\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027A Systematic Investigation of Knowledge Retrieval and Selection for\\n  Retrieval Augmented Generation\u0027, \u0027Xiangci Li and Jessica Ouyang\u0027):   Retrieval-augmented generation (RAG) has emerged as a powerful method for\nenhancing natural language generation by integrating external knowledge into a\nmodel\u0027s output. While prior work has demonstrated the importance of improving\nknowledge retrieval for boosting generation quality, the role of knowledge\nselection remains less clear. In this paper, we perform a comprehensive\nanalysis of how knowledge retrieval and selection influence downstream\ngeneration performance in RAG systems. By simulating different retrieval and\nselection conditions through a controlled mixture of gold and distractor\nknowledge, we assess the impact of these factors on generation outcomes. Our\nfindings indicate that the downstream generator model\u0027s capability, as well as\nthe complexity of the task and dataset, significantly influence the impact of\nknowledge retrieval and selection on the overall RAG system performance. In\ntypical scenarios, improving the knowledge recall score is key to enhancing\ngeneration outcomes, with the knowledge selector providing a limited additional\nbenefit when a strong generator model is used on clear, well-defined tasks. For\nweaker generator models or more ambiguous tasks and datasets, the knowledge F1\nscore becomes a critical factor, and the knowledge selector plays a more\nprominent role in improving overall performance.", "label": "(\u0027A Systematic Investigation of Knowledge Retrieval and Selection for\\n  Retrieval Augmented Generation\u0027, \u0027Xiangci Li and Jessica Ouyang\u0027):   Retrieval-augmented generation (RAG) has emerged as a powerful method for\nenhancing natural language generation by integrating external knowledge into a\nmodel\u0027s output. While prior work has demonstrated the importance of improving\nknowledge retrieval for boosting generation quality, the role of knowledge\nselection remains less clear. In this paper, we perform a comprehensive\nanalysis of how knowledge retrieval and selection influence downstream\ngeneration performance in RAG systems. By simulating different retrieval and\nselection conditions through a controlled mixture of gold and distractor\nknowledge, we assess the impact of these factors on generation outcomes. Our\nfindings indicate that the downstream generator model\u0027s capability, as well as\nthe complexity of the task and dataset, significantly influence the impact of\nknowledge retrieval and selection on the overall RAG system performance. In\ntypical scenarios, improving the knowledge recall score is key to enhancing\ngeneration outcomes, with the knowledge selector providing a limited additional\nbenefit when a strong generator model is used on clear, well-defined tasks. For\nweaker generator models or more ambiguous tasks and datasets, the knowledge F1\nscore becomes a critical factor, and the knowledge selector plays a more\nprominent role in improving overall performance.", "shape": "dot", "title": "Node: (\u0027A Systematic Investigation of Knowledge Retrieval and Selection for\\n  Retrieval Augmented Generation\u0027, \u0027Xiangci Li and Jessica Ouyang\u0027):   Retrieval-augmented generation (RAG) has emerged as a powerful method for\nenhancing natural language generation by integrating external knowledge into a\nmodel\u0027s output. While prior work has demonstrated the importance of improving\nknowledge retrieval for boosting generation quality, the role of knowledge\nselection remains less clear. In this paper, we perform a comprehensive\nanalysis of how knowledge retrieval and selection influence downstream\ngeneration performance in RAG systems. By simulating different retrieval and\nselection conditions through a controlled mixture of gold and distractor\nknowledge, we assess the impact of these factors on generation outcomes. Our\nfindings indicate that the downstream generator model\u0027s capability, as well as\nthe complexity of the task and dataset, significantly influence the impact of\nknowledge retrieval and selection on the overall RAG system performance. In\ntypical scenarios, improving the knowledge recall score is key to enhancing\ngeneration outcomes, with the knowledge selector providing a limited additional\nbenefit when a strong generator model is used on clear, well-defined tasks. For\nweaker generator models or more ambiguous tasks and datasets, the knowledge F1\nscore becomes a critical factor, and the knowledge selector plays a more\nprominent role in improving overall performance.\nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027Probing-RAG: Self-Probing to Guide Language Models in Selective Document\\n  Retrieval\u0027, \u0027Ingeol Baek, Hwan Chang, Byeongjeong Kim, Jimin Lee, Hwanhee Lee\u0027):   Retrieval-Augmented Generation (RAG) enhances language models by retrieving\nand incorporating relevant external knowledge. However, traditional\nretrieve-and-generate processes may not be optimized for real-world scenarios,\nwhere queries might require multiple retrieval steps or none at all. In this\npaper, we propose a Probing-RAG, which utilizes the hidden state\nrepresentations from the intermediate layers of language models to adaptively\ndetermine the necessity of additional retrievals for a given query. By\nemploying a pre-trained prober, Probing-RAG effectively captures the model\u0027s\ninternal cognition, enabling reliable decision-making about retrieving external\ndocuments. Experimental results across five open-domain QA datasets demonstrate\nthat Probing-RAG outperforms previous methods while reducing the number of\nredundant retrieval steps.", "label": "(\u0027Probing-RAG: Self-Probing to Guide Language Models in Selective Document\\n  Retrieval\u0027, \u0027Ingeol Baek, Hwan Chang, Byeongjeong Kim, Jimin Lee, Hwanhee Lee\u0027):   Retrieval-Augmented Generation (RAG) enhances language models by retrieving\nand incorporating relevant external knowledge. However, traditional\nretrieve-and-generate processes may not be optimized for real-world scenarios,\nwhere queries might require multiple retrieval steps or none at all. In this\npaper, we propose a Probing-RAG, which utilizes the hidden state\nrepresentations from the intermediate layers of language models to adaptively\ndetermine the necessity of additional retrievals for a given query. By\nemploying a pre-trained prober, Probing-RAG effectively captures the model\u0027s\ninternal cognition, enabling reliable decision-making about retrieving external\ndocuments. Experimental results across five open-domain QA datasets demonstrate\nthat Probing-RAG outperforms previous methods while reducing the number of\nredundant retrieval steps.", "shape": "dot", "title": "Node: (\u0027Probing-RAG: Self-Probing to Guide Language Models in Selective Document\\n  Retrieval\u0027, \u0027Ingeol Baek, Hwan Chang, Byeongjeong Kim, Jimin Lee, Hwanhee Lee\u0027):   Retrieval-Augmented Generation (RAG) enhances language models by retrieving\nand incorporating relevant external knowledge. However, traditional\nretrieve-and-generate processes may not be optimized for real-world scenarios,\nwhere queries might require multiple retrieval steps or none at all. In this\npaper, we propose a Probing-RAG, which utilizes the hidden state\nrepresentations from the intermediate layers of language models to adaptively\ndetermine the necessity of additional retrievals for a given query. By\nemploying a pre-trained prober, Probing-RAG effectively captures the model\u0027s\ninternal cognition, enabling reliable decision-making about retrieving external\ndocuments. Experimental results across five open-domain QA datasets demonstrate\nthat Probing-RAG outperforms previous methods while reducing the number of\nredundant retrieval steps.\nPaper ID: 2410.13339\nCommunity:-1"}, {"color": "##28282B", "id": "(\u0027AutoRAG: Automated Framework for optimization of Retrieval Augmented\\n  Generation Pipeline\u0027, \u0027Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\\\\v{s} Eibich\u0027):   Using LLMs (Large Language Models) in conjunction with external documents has\nmade RAG (Retrieval-Augmented Generation) an essential technology. Numerous\ntechniques and modules for RAG are being researched, but their performance can\nvary across different datasets. Finding RAG modules that perform well on\nspecific datasets is challenging. In this paper, we propose the AutoRAG\nframework, which automatically identifies suitable RAG modules for a given\ndataset. AutoRAG explores and approximates the optimal combination of RAG\nmodules for the dataset. Additionally, we share the results of optimizing a\ndataset using AutoRAG. All experimental results and data are publicly available\nand can be accessed through our GitHub repository\nhttps://github.com/Marker-Inc-Korea/AutoRAG_ARAGOG_Paper .", "label": "(\u0027AutoRAG: Automated Framework for optimization of Retrieval Augmented\\n  Generation Pipeline\u0027, \u0027Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\\\\v{s} Eibich\u0027):   Using LLMs (Large Language Models) in conjunction with external documents has\nmade RAG (Retrieval-Augmented Generation) an essential technology. Numerous\ntechniques and modules for RAG are being researched, but their performance can\nvary across different datasets. Finding RAG modules that perform well on\nspecific datasets is challenging. In this paper, we propose the AutoRAG\nframework, which automatically identifies suitable RAG modules for a given\ndataset. AutoRAG explores and approximates the optimal combination of RAG\nmodules for the dataset. Additionally, we share the results of optimizing a\ndataset using AutoRAG. All experimental results and data are publicly available\nand can be accessed through our GitHub repository\nhttps://github.com/Marker-Inc-Korea/AutoRAG_ARAGOG_Paper .", "shape": "dot", "title": "Node: (\u0027AutoRAG: Automated Framework for optimization of Retrieval Augmented\\n  Generation Pipeline\u0027, \u0027Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\\\\v{s} Eibich\u0027):   Using LLMs (Large Language Models) in conjunction with external documents has\nmade RAG (Retrieval-Augmented Generation) an essential technology. Numerous\ntechniques and modules for RAG are being researched, but their performance can\nvary across different datasets. Finding RAG modules that perform well on\nspecific datasets is challenging. In this paper, we propose the AutoRAG\nframework, which automatically identifies suitable RAG modules for a given\ndataset. AutoRAG explores and approximates the optimal combination of RAG\nmodules for the dataset. Additionally, we share the results of optimizing a\ndataset using AutoRAG. All experimental results and data are publicly available\nand can be accessed through our GitHub repository\nhttps://github.com/Marker-Inc-Korea/AutoRAG_ARAGOG_Paper .\nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Fine-tune the Entire RAG Architecture ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "Fine-tune the Entire RAG Architecture ", "shape": "dot", "title": "Node: Fine-tune the Entire RAG Architecture \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "RAG Architecture ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027relationship_description\u0027: \u0027The DPR retriever is a component of the RAG architecture.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "RAG Architecture ", "shape": "dot", "title": "Node: RAG Architecture \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "DPR Retriever ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027relationship_description\u0027: \u0027The fine-tuning technique is applied to the RAG architecture.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "DPR Retriever ", "shape": "dot", "title": "Node: DPR Retriever \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "HuggingFace Transformers library ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027entity_description\u0027: \u0027A library for natural language processing tasks, including question answering.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "HuggingFace Transformers library ", "shape": "dot", "title": "Node: HuggingFace Transformers library \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "Shamane Siriwardhana ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027relationship_description\u0027: \u0027The DPR retriever is a component of the RAG architecture.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "Shamane Siriwardhana ", "shape": "dot", "title": "Node: Shamane Siriwardhana \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "Rivindu Weerasekera ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of the RAG architecture.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "Rivindu Weerasekera ", "shape": "dot", "title": "Node: Rivindu Weerasekera \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "Elliott Wen ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of the RAG architecture.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "Elliott Wen ", "shape": "dot", "title": "Node: Elliott Wen \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "Suranga Nanayakkara ({\u0027paper_id\u0027: \u00272106.11517\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of the RAG architecture.\u0027, \u0027triplet_source_id\u0027: \u002722918700-0a1a-4852-92ff-475107fdf6af\u0027})", "label": "Suranga Nanayakkara ", "shape": "dot", "title": "Node: Suranga Nanayakkara \nPaper ID: 2106.11517\nCommunity:-1"}, {"color": "##28282B", "id": "Large Language Models ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027relationship_description\u0027: \u0027CoFE-RAG is a framework that evaluates Retrieval-Augmented Generation\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "Large Language Models ", "shape": "dot", "title": "Node: Large Language Models \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval Augmented Generation ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation is used in Long Context Question Answering systems.\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "Retrieval Augmented Generation ", "shape": "dot", "title": "Node: Retrieval Augmented Generation \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "Medical Education ({\u0027paper_id\u0027: \u00272308.00479\u0027, \u0027relationship_description\u0027: \u0027Large Language Models use Retrieval Augmented Generation to produce high-quality text\u0027, \u0027triplet_source_id\u0027: \u0027a3a4267b-f67d-404b-b9c0-96105e224f72\u0027})", "label": "Medical Education ", "shape": "dot", "title": "Node: Medical Education \nPaper ID: 2308.00479\nCommunity:-1"}, {"color": "##28282B", "id": "S. S. Manathunga ({\u0027paper_id\u0027: \u00272308.00479\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027a3a4267b-f67d-404b-b9c0-96105e224f72\u0027})", "label": "S. S. Manathunga ", "shape": "dot", "title": "Node: S. S. Manathunga \nPaper ID: 2308.00479\nCommunity:-1"}, {"color": "##28282B", "id": "Y. A. Illangasekara ({\u0027paper_id\u0027: \u00272308.00479\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027a3a4267b-f67d-404b-b9c0-96105e224f72\u0027})", "label": "Y. A. Illangasekara ", "shape": "dot", "title": "Node: Y. A. Illangasekara \nPaper ID: 2308.00479\nCommunity:-1"}, {"color": "##28282B", "id": "Cheonsu Jeong ({\u0027paper_id\u0027: \u00272309.01105\u0027, \u0027triplet_source_id\u0027: \u0027f4a30610-abd5-4b41-9500-ff21652349cd\u0027})", "label": "Cheonsu Jeong ", "shape": "dot", "title": "Node: Cheonsu Jeong \nPaper ID: 2309.01105\nCommunity:-1"}, {"color": "##28282B", "id": "Large Language Models (LLM) ({\u0027paper_id\u0027: \u00272309.01105\u0027, \u0027relationship_description\u0027: \u0027The author uses Large Language Models (LLM) in their study on implementing generative AI services.\u0027, \u0027triplet_source_id\u0027: \u0027f4a30610-abd5-4b41-9500-ff21652349cd\u0027})", "label": "Large Language Models (LLM) ", "shape": "dot", "title": "Node: Large Language Models (LLM) \nPaper ID: 2309.01105\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Generation (RAG) model ({\u0027paper_id\u0027: \u00272309.01105\u0027, \u0027relationship_description\u0027: \u0027The Retrieval-Augmented Generation (RAG) model is designed to utilize the capabilities of Large Language Models (LLM) for improved content generation.\u0027, \u0027triplet_source_id\u0027: \u0027f4a30610-abd5-4b41-9500-ff21652349cd\u0027})", "label": "Retrieval-Augmented Generation (RAG) model ", "shape": "dot", "title": "Node: Retrieval-Augmented Generation (RAG) model \nPaper ID: 2309.01105\nCommunity:-1"}, {"color": "##28282B", "id": "Generative AI services ({\u0027paper_id\u0027: \u00272309.01105\u0027, \u0027relationship_description\u0027: \u0027The Retrieval-Augmented Generation (RAG) model is designed to utilize the capabilities of Large Language Models (LLM) for improved content generation.\u0027, \u0027triplet_source_id\u0027: \u0027f4a30610-abd5-4b41-9500-ff21652349cd\u0027})", "label": "Generative AI services ", "shape": "dot", "title": "Node: Generative AI services \nPaper ID: 2309.01105\nCommunity:-1"}, {"color": "##28282B", "id": "Enterprise Data-Based LLM Application Architecture ({\u0027paper_id\u0027: \u00272309.01105\u0027, \u0027entity_description\u0027: \u0027A framework for implementing generative AI services using large language models and enterprise data.\u0027, \u0027triplet_source_id\u0027: \u0027f4a30610-abd5-4b41-9500-ff21652349cd\u0027})", "label": "Enterprise Data-Based LLM Application Architecture ", "shape": "dot", "title": "Node: Enterprise Data-Based LLM Application Architecture \nPaper ID: 2309.01105\nCommunity:-1"}, {"color": "##28282B", "id": "Jiawei Chen ({\u0027paper_id\u0027: \u00272309.01431\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Benchmarking Large Language Models in Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027c76bb137-5574-4c6f-8390-7099a4817240\u0027})", "label": "Jiawei Chen ", "shape": "dot", "title": "Node: Jiawei Chen \nPaper ID: 2309.01431\nCommunity:-1"}, {"color": "##28282B", "id": "Hongyu Lin ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Hongyu Lin ", "shape": "dot", "title": "Node: Hongyu Lin \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Xianpei Han ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Xianpei Han ", "shape": "dot", "title": "Node: Xianpei Han \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Le Sun ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Le Sun ", "shape": "dot", "title": "Node: Le Sun \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Generation ({\u0027paper_id\u0027: \u00272410.13258\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation uses Knowledge Retrieval to retrieve external knowledge.\u0027, \u0027triplet_source_id\u0027: \u00275c41d11a-7a50-4de7-ba89-18ba3e8aa9dc\u0027})", "label": "Retrieval-Augmented Generation ", "shape": "dot", "title": "Node: Retrieval-Augmented Generation \nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Generation Benchmark ({\u0027paper_id\u0027: \u00272309.01431\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation is a promising approach for mitigating the hallucination of large language models\u0027, \u0027triplet_source_id\u0027: \u0027c76bb137-5574-4c6f-8390-7099a4817240\u0027})", "label": "Retrieval-Augmented Generation Benchmark ", "shape": "dot", "title": "Node: Retrieval-Augmented Generation Benchmark \nPaper ID: 2309.01431\nCommunity:-1"}, {"color": "##28282B", "id": "RAGAS ({\u0027paper_id\u0027: \u00272309.15217\u0027, \u0027relationship_description\u0027: \u0027RAGAS uses LLMs to provide knowledge from a reference textual database.\u0027, \u0027triplet_source_id\u0027: \u0027548a9450-a1d9-427e-96d6-2be8333ba383\u0027})", "label": "RAGAS ", "shape": "dot", "title": "Node: RAGAS \nPaper ID: 2309.15217\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval Augmented Generation (RAG) ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027relationship_description\u0027: \u0027BSharedRAG is a system designed for the e-commerce domain\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Retrieval Augmented Generation (RAG) ", "shape": "dot", "title": "Node: Retrieval Augmented Generation (RAG) \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "LLMs ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "LLMs ", "shape": "dot", "title": "Node: LLMs \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Shahul Es ({\u0027paper_id\u0027: \u00272309.15217\u0027, \u0027relationship_description\u0027: \u0027RAGAS uses LLMs to provide knowledge from a reference textual database.\u0027, \u0027triplet_source_id\u0027: \u0027548a9450-a1d9-427e-96d6-2be8333ba383\u0027})", "label": "Shahul Es ", "shape": "dot", "title": "Node: Shahul Es \nPaper ID: 2309.15217\nCommunity:-1"}, {"color": "##28282B", "id": "Jithin James ({\u0027paper_id\u0027: \u00272309.15217\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u0027548a9450-a1d9-427e-96d6-2be8333ba383\u0027})", "label": "Jithin James ", "shape": "dot", "title": "Node: Jithin James \nPaper ID: 2309.15217\nCommunity:-1"}, {"color": "##28282B", "id": "Luis Espinosa-Anke ({\u0027paper_id\u0027: \u00272309.15217\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u0027548a9450-a1d9-427e-96d6-2be8333ba383\u0027})", "label": "Luis Espinosa-Anke ", "shape": "dot", "title": "Node: Luis Espinosa-Anke \nPaper ID: 2309.15217\nCommunity:-1"}, {"color": "##28282B", "id": "Steven Schockaert ({\u0027paper_id\u0027: \u00272309.15217\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u0027548a9450-a1d9-427e-96d6-2be8333ba383\u0027})", "label": "Steven Schockaert ", "shape": "dot", "title": "Node: Steven Schockaert \nPaper ID: 2309.15217\nCommunity:-1"}, {"color": "##28282B", "id": "Yunfan Gao ({\u0027paper_id\u0027: \u00272407.21059\u0027, \u0027relationship_description\u0027: \u0027Modular RAG integrates advanced retrievers, LLMs, and other complementary technologies\u0027, \u0027triplet_source_id\u0027: \u0027d0700d0c-57e0-4925-96bc-e36e42ce72f0\u0027})", "label": "Yunfan Gao ", "shape": "dot", "title": "Node: Yunfan Gao \nPaper ID: 2407.21059\nCommunity:-1"}, {"color": "##28282B", "id": "Yun Xiong ({\u0027paper_id\u0027: \u00272407.21059\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d0700d0c-57e0-4925-96bc-e36e42ce72f0\u0027})", "label": "Yun Xiong ", "shape": "dot", "title": "Node: Yun Xiong \nPaper ID: 2407.21059\nCommunity:-1"}, {"color": "##28282B", "id": "Xinyu Gao ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Xinyu Gao ", "shape": "dot", "title": "Node: Xinyu Gao \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Kangxiang Jia ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Kangxiang Jia ", "shape": "dot", "title": "Node: Kangxiang Jia \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Jinliu Pan ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Jinliu Pan ", "shape": "dot", "title": "Node: Jinliu Pan \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Yuxi Bi ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Yuxi Bi ", "shape": "dot", "title": "Node: Yuxi Bi \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Yi Dai ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Yi Dai ", "shape": "dot", "title": "Node: Yi Dai \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Jiawei Sun ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027Retrieval-Augmented Generation for Large Language Models: A Survey\u0027.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Jiawei Sun ", "shape": "dot", "title": "Node: Jiawei Sun \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Meng Wang ({\u0027paper_id\u0027: \u00272407.21059\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d0700d0c-57e0-4925-96bc-e36e42ce72f0\u0027})", "label": "Meng Wang ", "shape": "dot", "title": "Node: Meng Wang \nPaper ID: 2407.21059\nCommunity:-1"}, {"color": "##28282B", "id": "Haofen Wang ({\u0027paper_id\u0027: \u00272407.21059\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d0700d0c-57e0-4925-96bc-e36e42ce72f0\u0027})", "label": "Haofen Wang ", "shape": "dot", "title": "Node: Haofen Wang \nPaper ID: 2407.21059\nCommunity:-1"}, {"color": "##28282B", "id": "Naive RAG ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027relationship_description\u0027: \"Retrieval-Augmented Generation incorporates knowledge from external databases to enhance the accuracy and credibility of Large Language Models\u0027 generation.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Naive RAG ", "shape": "dot", "title": "Node: Naive RAG \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Advanced RAG ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027relationship_description\u0027: \"Retrieval-Augmented Generation incorporates knowledge from external databases to enhance the accuracy and credibility of Large Language Models\u0027 generation.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "Advanced RAG ", "shape": "dot", "title": "Node: Advanced RAG \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Modular RAG ({\u0027paper_id\u0027: \u00272407.21059\u0027, \u0027relationship_description\u0027: \u0027Modular RAG integrates advanced retrievers, LLMs, and other complementary technologies\u0027, \u0027triplet_source_id\u0027: \u0027d0700d0c-57e0-4925-96bc-e36e42ce72f0\u0027})", "label": "Modular RAG ", "shape": "dot", "title": "Node: Modular RAG \nPaper ID: 2407.21059\nCommunity:-1"}, {"color": "##28282B", "id": "External Databases ({\u0027paper_id\u0027: \u00272312.10997\u0027, \u0027relationship_description\u0027: \"Retrieval-Augmented Generation enhances the accuracy and credibility of Large Language Models\u0027 generation.\", \u0027triplet_source_id\u0027: \u002747ec9cf6-3173-43e3-b170-a1a53cf03848\u0027})", "label": "External Databases ", "shape": "dot", "title": "Node: External Databases \nPaper ID: 2312.10997\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-augmented Generation ({\u0027paper_id\u0027: \u00272407.03955\u0027, \u0027triplet_source_id\u0027: \u002727d5254a-6f38-4049-bae7-ddc596d6f95a\u0027})", "label": "Retrieval-augmented Generation ", "shape": "dot", "title": "Node: Retrieval-augmented Generation \nPaper ID: 2407.03955\nCommunity:-1"}, {"color": "##28282B", "id": "Zixuan Ke ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Zixuan Ke ", "shape": "dot", "title": "Node: Zixuan Ke \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Weize Kong ({\u0027paper_id\u0027: \u00272401.06954\u0027, \u0027entity_description\u0027: \"Weize Kong is one of the authors of the paper \u0027Bridging the Preference Gap between Retrievers and LLMs\u0027.\", \u0027triplet_source_id\u0027: \u0027ba69b032-a812-41c1-b462-08444957cf39\u0027})", "label": "Weize Kong ", "shape": "dot", "title": "Node: Weize Kong \nPaper ID: 2401.06954\nCommunity:-1"}, {"color": "##28282B", "id": "Cheng Li ({\u0027paper_id\u0027: \u00272401.06954\u0027, \u0027entity_description\u0027: \"Cheng Li is one of the authors of the paper \u0027Bridging the Preference Gap between Retrievers and LLMs\u0027.\", \u0027triplet_source_id\u0027: \u0027ba69b032-a812-41c1-b462-08444957cf39\u0027})", "label": "Cheng Li ", "shape": "dot", "title": "Node: Cheng Li \nPaper ID: 2401.06954\nCommunity:-1"}, {"color": "##28282B", "id": "Mingyang Zhang ({\u0027paper_id\u0027: \u00272401.06954\u0027, \u0027entity_description\u0027: \"Mingyang Zhang is one of the authors of the paper \u0027Bridging the Preference Gap between Retrievers and LLMs\u0027.\", \u0027triplet_source_id\u0027: \u0027ba69b032-a812-41c1-b462-08444957cf39\u0027})", "label": "Mingyang Zhang ", "shape": "dot", "title": "Node: Mingyang Zhang \nPaper ID: 2401.06954\nCommunity:-1"}, {"color": "##28282B", "id": "Qiaozhu Mei ({\u0027paper_id\u0027: \u00272401.06954\u0027, \u0027entity_description\u0027: \"Qiaozhu Mei is one of the authors of the paper \u0027Bridging the Preference Gap between Retrievers and LLMs\u0027.\", \u0027triplet_source_id\u0027: \u0027ba69b032-a812-41c1-b462-08444957cf39\u0027})", "label": "Qiaozhu Mei ", "shape": "dot", "title": "Node: Qiaozhu Mei \nPaper ID: 2401.06954\nCommunity:-1"}, {"color": "##28282B", "id": "Michael Bendersky ({\u0027paper_id\u0027: \u00272401.06954\u0027, \u0027entity_description\u0027: \"Michael Bendersky is one of the authors of the paper \u0027Bridging the Preference Gap between Retrievers and LLMs\u0027.\", \u0027triplet_source_id\u0027: \u0027ba69b032-a812-41c1-b462-08444957cf39\u0027})", "label": "Michael Bendersky ", "shape": "dot", "title": "Node: Michael Bendersky \nPaper ID: 2401.06954\nCommunity:-1"}, {"color": "##28282B", "id": "Retrievers ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \u0027Components of Retrieval-Augmented Generation approaches that retrieve relevant information\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Retrievers ", "shape": "dot", "title": "Node: Retrievers \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "The Chronicles of RAG ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "The Chronicles of RAG ", "shape": "dot", "title": "Node: The Chronicles of RAG \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Paulo Finardi ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027relationship_description\u0027: \u0027Paulo Finardi is the author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Paulo Finardi ", "shape": "dot", "title": "Node: Paulo Finardi \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Leonardo Avila ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Leonardo Avila ", "shape": "dot", "title": "Node: Leonardo Avila \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Rodrigo Castaldoni ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Rodrigo Castaldoni ", "shape": "dot", "title": "Node: Rodrigo Castaldoni \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Pedro Gengo ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Pedro Gengo ", "shape": "dot", "title": "Node: Pedro Gengo \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Celio Larcher ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Celio Larcher ", "shape": "dot", "title": "Node: Celio Larcher \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Marcos Piau ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Marcos Piau ", "shape": "dot", "title": "Node: Marcos Piau \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Pablo Costa ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Pablo Costa ", "shape": "dot", "title": "Node: Pablo Costa \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Vinicius Carid\u0027a ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Vinicius Carid\u0027a ", "shape": "dot", "title": "Node: Vinicius Carid\u0027a \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "OpenAI ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027relationship_description\u0027: \u0027GEM-RAG uses SBERT as a text encoder.\u0027, \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "OpenAI ", "shape": "dot", "title": "Node: OpenAI \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "Google ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027relationship_description\u0027: \u0027OpenAI provides the gpt-4 model\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Google ", "shape": "dot", "title": "Node: Google \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Harry Potter ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027relationship_description\u0027: \u0027RAG enables LLMs to access external data\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Harry Potter ", "shape": "dot", "title": "Node: Harry Potter \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "RAG ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027relationship_description\u0027: \u0027AutoRAG uses LLMs in conjunction with external documents\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "RAG ", "shape": "dot", "title": "Node: RAG \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "gpt-4 ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027relationship_description\u0027: \u0027Paulo Finardi is a developer of the RAG technique\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "gpt-4 ", "shape": "dot", "title": "Node: gpt-4 \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Gemini Pro ({\u0027paper_id\u0027: \u00272401.07883\u0027, \u0027relationship_description\u0027: \u0027OpenAI provides the gpt-4 model\u0027, \u0027triplet_source_id\u0027: \u002748c84b8e-7496-426d-bdc3-ebaa9e2a58ff\u0027})", "label": "Gemini Pro ", "shape": "dot", "title": "Node: Gemini Pro \nPaper ID: 2401.07883\nCommunity:-1"}, {"color": "##28282B", "id": "Information Retrieval ({\u0027paper_id\u0027: \u00272401.14887\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation extends beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval system.\u0027, \u0027triplet_source_id\u0027: \u0027cd306930-9756-4c04-9523-f6300301830e\u0027})", "label": "Information Retrieval ", "shape": "dot", "title": "Node: Information Retrieval \nPaper ID: 2401.14887\nCommunity:-1"}, {"color": "##28282B", "id": "Generative AI ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027relationship_description\u0027: \u0027Patrice B\u00e8chard and Orlando Marquez Ayala are authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Generative AI ", "shape": "dot", "title": "Node: Generative AI \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Florin Cuconasu ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Florin Cuconasu ", "shape": "dot", "title": "Node: Florin Cuconasu \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Giovanni Trappolini ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \u0027Florin Cuconasu is the author of the paper discussing RAG systems\u0027, \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Giovanni Trappolini ", "shape": "dot", "title": "Node: Giovanni Trappolini \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Federico Siciliano ({\u0027paper_id\u0027: \u00272401.14887\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027.\", \u0027triplet_source_id\u0027: \u0027cd306930-9756-4c04-9523-f6300301830e\u0027})", "label": "Federico Siciliano ", "shape": "dot", "title": "Node: Federico Siciliano \nPaper ID: 2401.14887\nCommunity:-1"}, {"color": "##28282B", "id": "Simone Filice ({\u0027paper_id\u0027: \u00272401.14887\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027.\", \u0027triplet_source_id\u0027: \u0027cd306930-9756-4c04-9523-f6300301830e\u0027})", "label": "Simone Filice ", "shape": "dot", "title": "Node: Simone Filice \nPaper ID: 2401.14887\nCommunity:-1"}, {"color": "##28282B", "id": "Cesare Campagnano ({\u0027paper_id\u0027: \u00272401.14887\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027.\", \u0027triplet_source_id\u0027: \u0027cd306930-9756-4c04-9523-f6300301830e\u0027})", "label": "Cesare Campagnano ", "shape": "dot", "title": "Node: Cesare Campagnano \nPaper ID: 2401.14887\nCommunity:-1"}, {"color": "##28282B", "id": "Yoelle Maarek ({\u0027paper_id\u0027: \u00272401.14887\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027The Power of Noise: Redefining Retrieval for RAG Systems\u0027.\", \u0027triplet_source_id\u0027: \u0027cd306930-9756-4c04-9523-f6300301830e\u0027})", "label": "Yoelle Maarek ", "shape": "dot", "title": "Node: Yoelle Maarek \nPaper ID: 2401.14887\nCommunity:-1"}, {"color": "##28282B", "id": "Nicola Tonellotto ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \u0027Giovanni Trappolini is the author of the paper discussing RAG systems\u0027, \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Nicola Tonellotto ", "shape": "dot", "title": "Node: Nicola Tonellotto \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Fabrizio Silvestri ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \u0027Nicola Tonellotto is the author of the paper discussing RAG systems\u0027, \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Fabrizio Silvestri ", "shape": "dot", "title": "Node: Fabrizio Silvestri \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Corrective Retrieval Augmented Generation ({\u0027paper_id\u0027: \u00272401.15884\u0027, \u0027entity_description\u0027: \u0027A method to improve the robustness of generation by incorporating a lightweight retrieval evaluator and a decompose-then-recompose algorithm.\u0027, \u0027triplet_source_id\u0027: \u0027563224b7-ba07-4b9e-936d-003157ae5981\u0027})", "label": "Corrective Retrieval Augmented Generation ", "shape": "dot", "title": "Node: Corrective Retrieval Augmented Generation \nPaper ID: 2401.15884\nCommunity:-1"}, {"color": "##28282B", "id": "Large Language Models (LLMs) ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027relationship_description\u0027: \u0027StructRAG is a framework that enhances LLMs in knowledge-intensive reasoning tasks\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Large Language Models (LLMs) ", "shape": "dot", "title": "Node: Large Language Models (LLMs) \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Generation (RAG) ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Retrieval-Augmented Generation (RAG) ", "shape": "dot", "title": "Node: Retrieval-Augmented Generation (RAG) \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Shi-Qi Yan ({\u0027paper_id\u0027: \u00272401.15884\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027563224b7-ba07-4b9e-936d-003157ae5981\u0027})", "label": "Shi-Qi Yan ", "shape": "dot", "title": "Node: Shi-Qi Yan \nPaper ID: 2401.15884\nCommunity:-1"}, {"color": "##28282B", "id": "Jia-Chen Gu ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Jia-Chen Gu ", "shape": "dot", "title": "Node: Jia-Chen Gu \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Yun Zhu ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Yun Zhu ", "shape": "dot", "title": "Node: Yun Zhu \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Zhen-Hua Ling ({\u0027paper_id\u0027: \u00272401.15884\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027563224b7-ba07-4b9e-936d-003157ae5981\u0027})", "label": "Zhen-Hua Ling ", "shape": "dot", "title": "Node: Zhen-Hua Ling \nPaper ID: 2401.15884\nCommunity:-1"}, {"color": "##28282B", "id": "Corrective Retrieval Augmented Generation (CRAG) ({\u0027paper_id\u0027: \u00272401.15884\u0027, \u0027relationship_description\u0027: \u0027LLMs can be complemented by RAG to improve the accuracy of generated text.\u0027, \u0027triplet_source_id\u0027: \u0027563224b7-ba07-4b9e-936d-003157ae5981\u0027})", "label": "Corrective Retrieval Augmented Generation (CRAG) ", "shape": "dot", "title": "Node: Corrective Retrieval Augmented Generation (CRAG) \nPaper ID: 2401.15884\nCommunity:-1"}, {"color": "##28282B", "id": "CRUD-RAG ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027relationship_description\u0027: \u0027CRUD-RAG requires the generation of original, varied content for Create applications.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "CRUD-RAG ", "shape": "dot", "title": "Node: CRUD-RAG \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Yuanjie Lyu ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Yuanjie Lyu ", "shape": "dot", "title": "Node: Yuanjie Lyu \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Zhiyu Li ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Zhiyu Li ", "shape": "dot", "title": "Node: Zhiyu Li \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Simin Niu ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Simin Niu ", "shape": "dot", "title": "Node: Simin Niu \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Feiyu Xiong ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Feiyu Xiong ", "shape": "dot", "title": "Node: Feiyu Xiong \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Bo Tang ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Bo Tang ", "shape": "dot", "title": "Node: Bo Tang \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Wenjin Wang ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Wenjin Wang ", "shape": "dot", "title": "Node: Wenjin Wang \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Hao Wu ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Hao Wu ", "shape": "dot", "title": "Node: Hao Wu \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Huanyong Liu ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Huanyong Liu ", "shape": "dot", "title": "Node: Huanyong Liu \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Tong Xu ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models\u0027.\", \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Tong Xu ", "shape": "dot", "title": "Node: Tong Xu \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Enhong Chen ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Enhong Chen ", "shape": "dot", "title": "Node: Enhong Chen \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge Sources ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027relationship_description\u0027: \u0027CRUD-RAG enhances the capabilities of large language models by incorporating external knowledge sources.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Knowledge Sources ", "shape": "dot", "title": "Node: Knowledge Sources \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "CRUD ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027relationship_description\u0027: \u0027CRUD-RAG uses external knowledge sources to enhance the capabilities of large language models.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "CRUD ", "shape": "dot", "title": "Node: CRUD \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Create ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027relationship_description\u0027: \u0027CRUD-RAG applies to various CRUD applications, including Create, Read, Update, and Delete.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Create ", "shape": "dot", "title": "Node: Create \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Read ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027relationship_description\u0027: \u0027CRUD-RAG requires the generation of original, varied content for Create applications.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Read ", "shape": "dot", "title": "Node: Read \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Update ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \u0027A type of CRUD application that focuses on revising and rectifying inaccuracies or inconsistencies in pre-existing texts.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Update ", "shape": "dot", "title": "Node: Update \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "Delete ({\u0027paper_id\u0027: \u00272401.17043\u0027, \u0027entity_description\u0027: \u0027A type of CRUD application that pertains to the task of summarizing extensive texts into more concise forms.\u0027, \u0027triplet_source_id\u0027: \u0027d6c04d53-58b0-409a-8432-d9ffd21a6c4d\u0027})", "label": "Delete ", "shape": "dot", "title": "Node: Delete \nPaper ID: 2401.17043\nCommunity:-1"}, {"color": "##28282B", "id": "HiQA ({\u0027paper_id\u0027: \u00272402.01767\u0027, \u0027relationship_description\u0027: \u0027HiQA uses RAG as a method for integrating external documents during the response generation phase\u0027, \u0027triplet_source_id\u0027: \u002762930548-6bc2-4f91-9c39-20cb1b76b63d\u0027})", "label": "HiQA ", "shape": "dot", "title": "Node: HiQA \nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "MasQA ({\u0027paper_id\u0027: \u00272402.01767\u0027, \u0027relationship_description\u0027: \u0027HiQA uses RAG as a method for integrating external documents during the response generation phase\u0027, \u0027triplet_source_id\u0027: \u002762930548-6bc2-4f91-9c39-20cb1b76b63d\u0027})", "label": "MasQA ", "shape": "dot", "title": "Node: MasQA \nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "Xinyue Chen ({\u0027paper_id\u0027: \u00272402.01767\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027\", \u0027triplet_source_id\u0027: \u002762930548-6bc2-4f91-9c39-20cb1b76b63d\u0027})", "label": "Xinyue Chen ", "shape": "dot", "title": "Node: Xinyue Chen \nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "Pengyu Gao ({\u0027paper_id\u0027: \u00272402.01767\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027\", \u0027triplet_source_id\u0027: \u002762930548-6bc2-4f91-9c39-20cb1b76b63d\u0027})", "label": "Pengyu Gao ", "shape": "dot", "title": "Node: Pengyu Gao \nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "Jiangjiang Song ({\u0027paper_id\u0027: \u00272402.01767\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027\", \u0027triplet_source_id\u0027: \u002762930548-6bc2-4f91-9c39-20cb1b76b63d\u0027})", "label": "Jiangjiang Song ", "shape": "dot", "title": "Node: Jiangjiang Song \nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "Xiaoyang Tan ({\u0027paper_id\u0027: \u00272402.01767\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA\u0027\", \u0027triplet_source_id\u0027: \u002762930548-6bc2-4f91-9c39-20cb1b76b63d\u0027})", "label": "Xiaoyang Tan ", "shape": "dot", "title": "Node: Xiaoyang Tan \nPaper ID: 2402.01767\nCommunity:-1"}, {"color": "##28282B", "id": "Julien Pierre Edmond Ghali ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027Both authors contributed to the research paper\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Julien Pierre Edmond Ghali ", "shape": "dot", "title": "Node: Julien Pierre Edmond Ghali \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Kosuke Shima ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Kosuke Shima ", "shape": "dot", "title": "Node: Kosuke Shima \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Koichi Moriyama ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027Both authors contributed to the research paper\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Koichi Moriyama ", "shape": "dot", "title": "Node: Koichi Moriyama \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Atsuko Mutoh ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027Both authors contributed to the research paper\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Atsuko Mutoh ", "shape": "dot", "title": "Node: Atsuko Mutoh \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Nobuhiro Inuzuka ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027Both authors contributed to the research paper\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Nobuhiro Inuzuka ", "shape": "dot", "title": "Node: Nobuhiro Inuzuka \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "BERT ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027Orca2 is used as a language model in the RAG technique\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "BERT ", "shape": "dot", "title": "Node: BERT \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Orca2 ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027BERT is used as a language model in the RAG technique\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Orca2 ", "shape": "dot", "title": "Node: Orca2 \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "UMAP ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027relationship_description\u0027: \u0027Orca2 is used as a language model in the RAG technique\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "UMAP ", "shape": "dot", "title": "Node: UMAP \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Smart Technology ({\u0027paper_id\u0027: \u00272402.16874\u0027, \u0027entity_description\u0027: \u0027Field of study and application\u0027, \u0027triplet_source_id\u0027: \u0027b055650b-8466-420b-b556-925f19688ed1\u0027})", "label": "Smart Technology ", "shape": "dot", "title": "Node: Smart Technology \nPaper ID: 2402.16874\nCommunity:-1"}, {"color": "##28282B", "id": "Penghao Zhao ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027relationship_description\u0027: \u0027Penghao Zhao is the author of the paper on RAG\u0027, \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Penghao Zhao ", "shape": "dot", "title": "Node: Penghao Zhao \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Hailin Zhang ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Hailin Zhang ", "shape": "dot", "title": "Node: Hailin Zhang \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Qinhan Yu ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Qinhan Yu ", "shape": "dot", "title": "Node: Qinhan Yu \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Zhengren Wang ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Zhengren Wang ", "shape": "dot", "title": "Node: Zhengren Wang \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Yunteng Geng ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Yunteng Geng ", "shape": "dot", "title": "Node: Yunteng Geng \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Fangcheng Fu ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Fangcheng Fu ", "shape": "dot", "title": "Node: Fangcheng Fu \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Ling Yang ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Ling Yang ", "shape": "dot", "title": "Node: Ling Yang \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Wentao Zhang ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Wentao Zhang ", "shape": "dot", "title": "Node: Wentao Zhang \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Jie Jiang ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Jie Jiang ", "shape": "dot", "title": "Node: Jie Jiang \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Bin Cui ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval-Augmented Generation for AI-Generated Content: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Bin Cui ", "shape": "dot", "title": "Node: Bin Cui \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Artificial Intelligence Generated Content (AIGC) ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027relationship_description\u0027: \u0027Penghao Zhao is researching AIGC\u0027, \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Artificial Intelligence Generated Content (AIGC) ", "shape": "dot", "title": "Node: Artificial Intelligence Generated Content (AIGC) \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Github ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027entity_description\u0027: \u0027Platform for hosting the RAG-Survey repository\u0027, \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "Github ", "shape": "dot", "title": "Node: Github \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "PKU-DAIR ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027relationship_description\u0027: \u0027RAG is a solution to address challenges in AIGC\u0027, \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "PKU-DAIR ", "shape": "dot", "title": "Node: PKU-DAIR \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "RAG-Survey ({\u0027paper_id\u0027: \u00272402.19473\u0027, \u0027relationship_description\u0027: \u0027RAG is a solution to address challenges in AIGC\u0027, \u0027triplet_source_id\u0027: \u0027e3fea7c7-40f0-4c8a-90cf-36baf3ad4e5a\u0027})", "label": "RAG-Survey ", "shape": "dot", "title": "Node: RAG-Survey \nPaper ID: 2402.19473\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval Augmented Generation Systems ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation Systems query the Vector Database for additional information.\u0027, \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Retrieval Augmented Generation Systems ", "shape": "dot", "title": "Node: Retrieval Augmented Generation Systems \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "Large-Language Model (LLM) ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Large-Language Model (LLM) ", "shape": "dot", "title": "Node: Large-Language Model (LLM) \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "Tristan Kenneweg ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup\u0027.\", \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Tristan Kenneweg ", "shape": "dot", "title": "Node: Tristan Kenneweg \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "Philip Kenneweg ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup\u0027.\", \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Philip Kenneweg ", "shape": "dot", "title": "Node: Philip Kenneweg \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "Barbara Hammer ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup\u0027.\", \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Barbara Hammer ", "shape": "dot", "title": "Node: Barbara Hammer \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "Boolean Agent ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation Systems query the Vector Database for additional information.\u0027, \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Boolean Agent ", "shape": "dot", "title": "Node: Boolean Agent \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "Vector Database ({\u0027paper_id\u0027: \u00272403.0082\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation Systems augment Large-Language Model (LLM) outputs with domain specific and time sensitive data.\u0027, \u0027triplet_source_id\u0027: \u0027cec988f0-8f28-4836-8559-b9323c6a0b92\u0027})", "label": "Vector Database ", "shape": "dot", "title": "Node: Vector Database \nPaper ID: 2403.0082\nCommunity:-1"}, {"color": "##28282B", "id": "PipeRAG ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027relationship_description\u0027: \u0027PipeRAG improves the generation quality of large language models.\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "PipeRAG ", "shape": "dot", "title": "Node: PipeRAG \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "Wenqi Jiang ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "Wenqi Jiang ", "shape": "dot", "title": "Node: Wenqi Jiang \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "Shuai Zhang ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Shuai Zhang ", "shape": "dot", "title": "Node: Shuai Zhang \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Boran Han ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "Boran Han ", "shape": "dot", "title": "Node: Boran Han \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "Jie Wang ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "Jie Wang ", "shape": "dot", "title": "Node: Jie Wang \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "Bernie Wang ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "Bernie Wang ", "shape": "dot", "title": "Node: Bernie Wang \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "Tim Kraska ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "Tim Kraska ", "shape": "dot", "title": "Node: Tim Kraska \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "Algorithm-System Co-design ({\u0027paper_id\u0027: \u00272403.05676\u0027, \u0027relationship_description\u0027: \u0027PipeRAG improves the generation quality of large language models.\u0027, \u0027triplet_source_id\u0027: \u0027c2a76353-eefd-4cc6-acd4-6e4b469dd4f2\u0027})", "label": "Algorithm-System Co-design ", "shape": "dot", "title": "Node: Algorithm-System Co-design \nPaper ID: 2403.05676\nCommunity:-1"}, {"color": "##28282B", "id": "RAGGED ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027relationship_description\u0027: \u0027RAG can significantly improve the performance of language models\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "RAGGED ", "shape": "dot", "title": "Node: RAGGED \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "Language Models (LMs) ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027relationship_description\u0027: \u0027RAGGED is a framework for analyzing RAG configurations\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "Language Models (LMs) ", "shape": "dot", "title": "Node: Language Models (LMs) \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "Document-Based Question Answering (DBQA) ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027relationship_description\u0027: \u0027RAG can significantly improve the performance of language models\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "Document-Based Question Answering (DBQA) ", "shape": "dot", "title": "Node: Document-Based Question Answering (DBQA) \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "Jennifer Hsia ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "Jennifer Hsia ", "shape": "dot", "title": "Node: Jennifer Hsia \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "Afreen Shaikh ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "Afreen Shaikh ", "shape": "dot", "title": "Node: Afreen Shaikh \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "Zhiruo Wang ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "Zhiruo Wang ", "shape": "dot", "title": "Node: Zhiruo Wang \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "Graham Neubig ({\u0027paper_id\u0027: \u00272403.0904\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00272dea0aa2-93b3-43d5-9e44-c5b096869fb1\u0027})", "label": "Graham Neubig ", "shape": "dot", "title": "Node: Graham Neubig \nPaper ID: 2403.0904\nCommunity:-1"}, {"color": "##28282B", "id": "DRAGIN ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027relationship_description\u0027: \u0027The authors of the paper developed the DRAGIN framework\u0027, \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "DRAGIN ", "shape": "dot", "title": "Node: DRAGIN \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "Weihang Su ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models\u0027\", \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "Weihang Su ", "shape": "dot", "title": "Node: Weihang Su \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "Yichen Tang ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models\u0027\", \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "Yichen Tang ", "shape": "dot", "title": "Node: Yichen Tang \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "Qingyao Ai ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models\u0027\", \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "Qingyao Ai ", "shape": "dot", "title": "Node: Qingyao Ai \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "Zhijing Wu ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models\u0027\", \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "Zhijing Wu ", "shape": "dot", "title": "Node: Zhijing Wu \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "Yiqun Liu ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models\u0027\", \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "Yiqun Liu ", "shape": "dot", "title": "Node: Yiqun Liu \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "GitHub ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027relationship_description\u0027: \u0027The authors of the paper propose the AutoRAG framework\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "GitHub ", "shape": "dot", "title": "Node: GitHub \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu ({\u0027paper_id\u0027: \u00272403.10081\u0027, \u0027relationship_description\u0027: \u0027DRAGIN is based on the real-time information needs of Large Language Models\u0027, \u0027triplet_source_id\u0027: \u0027291776f8-d592-47f1-bada-9105f1b0b237\u0027})", "label": "Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu ", "shape": "dot", "title": "Node: Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu \nPaper ID: 2403.10081\nCommunity:-1"}, {"color": "##28282B", "id": "Anuja Tayal ({\u0027paper_id\u0027: \u00272403.11413\u0027, \u0027triplet_source_id\u0027: \u00278da1df28-7a11-42a3-b1cb-6a65657e1724\u0027})", "label": "Anuja Tayal ", "shape": "dot", "title": "Node: Anuja Tayal \nPaper ID: 2403.11413\nCommunity:-1"}, {"color": "##28282B", "id": "Aman Tyagi ({\u0027paper_id\u0027: \u00272403.11413\u0027, \u0027triplet_source_id\u0027: \u00278da1df28-7a11-42a3-b1cb-6a65657e1724\u0027})", "label": "Aman Tyagi ", "shape": "dot", "title": "Node: Aman Tyagi \nPaper ID: 2403.11413\nCommunity:-1"}, {"color": "##28282B", "id": "Conversational Systems ({\u0027paper_id\u0027: \u00272403.11413\u0027, \u0027relationship_description\u0027: \"Anuja Tayal and Aman Tyagi co-authored the paper \u0027Dynamic Contexts for Generating Suggestion Questions in RAG Based Conversational Systems\u0027\", \u0027triplet_source_id\u0027: \u00278da1df28-7a11-42a3-b1cb-6a65657e1724\u0027})", "label": "Conversational Systems ", "shape": "dot", "title": "Node: Conversational Systems \nPaper ID: 2403.11413\nCommunity:-1"}, {"color": "##28282B", "id": "Suggestion Questions ({\u0027paper_id\u0027: \u00272403.11413\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation (RAG) technology is used in Conversational Systems\u0027, \u0027triplet_source_id\u0027: \u00278da1df28-7a11-42a3-b1cb-6a65657e1724\u0027})", "label": "Suggestion Questions ", "shape": "dot", "title": "Node: Suggestion Questions \nPaper ID: 2403.11413\nCommunity:-1"}, {"color": "##28282B", "id": "Dynamic Contexts ({\u0027paper_id\u0027: \u00272403.11413\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation (RAG) technology is used in Conversational Systems\u0027, \u0027triplet_source_id\u0027: \u00278da1df28-7a11-42a3-b1cb-6a65657e1724\u0027})", "label": "Dynamic Contexts ", "shape": "dot", "title": "Node: Dynamic Contexts \nPaper ID: 2403.11413\nCommunity:-1"}, {"color": "##28282B", "id": "Loops On Retrieval Augmented Generation (LoRAG) ({\u0027paper_id\u0027: \u00272403.1545\u0027, \u0027relationship_description\u0027: \u0027LoRAG is evaluated on benchmark datasets\u0027, \u0027triplet_source_id\u0027: \u00271bd4a61b-cc95-41c1-9b36-d67bed777d64\u0027})", "label": "Loops On Retrieval Augmented Generation (LoRAG) ", "shape": "dot", "title": "Node: Loops On Retrieval Augmented Generation (LoRAG) \nPaper ID: 2403.1545\nCommunity:-1"}, {"color": "##28282B", "id": "Ayush Thakur ({\u0027paper_id\u0027: \u00272403.1545\u0027, \u0027triplet_source_id\u0027: \u00271bd4a61b-cc95-41c1-9b36-d67bed777d64\u0027})", "label": "Ayush Thakur ", "shape": "dot", "title": "Node: Ayush Thakur \nPaper ID: 2403.1545\nCommunity:-1"}, {"color": "##28282B", "id": "Rashmi Vashisth ({\u0027paper_id\u0027: \u00272403.1545\u0027, \u0027relationship_description\u0027: \u0027Ayush Thakur is one of the authors of LoRAG\u0027, \u0027triplet_source_id\u0027: \u00271bd4a61b-cc95-41c1-9b36-d67bed777d64\u0027})", "label": "Rashmi Vashisth ", "shape": "dot", "title": "Node: Rashmi Vashisth \nPaper ID: 2403.1545\nCommunity:-1"}, {"color": "##28282B", "id": "Benchmark datasets ({\u0027paper_id\u0027: \u00272403.1545\u0027, \u0027relationship_description\u0027: \u0027Rashmi Vashisth is one of the authors of LoRAG\u0027, \u0027triplet_source_id\u0027: \u00271bd4a61b-cc95-41c1-9b36-d67bed777d64\u0027})", "label": "Benchmark datasets ", "shape": "dot", "title": "Node: Benchmark datasets \nPaper ID: 2403.1545\nCommunity:-1"}, {"color": "##28282B", "id": "State-of-the-art models ({\u0027paper_id\u0027: \u00272403.1545\u0027, \u0027relationship_description\u0027: \u0027LoRAG is evaluated on benchmark datasets\u0027, \u0027triplet_source_id\u0027: \u00271bd4a61b-cc95-41c1-9b36-d67bed777d64\u0027})", "label": "State-of-the-art models ", "shape": "dot", "title": "Node: State-of-the-art models \nPaper ID: 2403.1545\nCommunity:-1"}, {"color": "##28282B", "id": "Karthik Suresh ({\u0027paper_id\u0027: \u00272403.15729\u0027, \u0027triplet_source_id\u0027: \u0027b893f0ce-7932-43de-a0d8-ef99a5e946e0\u0027})", "label": "Karthik Suresh ", "shape": "dot", "title": "Node: Karthik Suresh \nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "Neeltje Kackar ({\u0027paper_id\u0027: \u00272403.15729\u0027, \u0027relationship_description\u0027: \"Karthik Suresh is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\", \u0027triplet_source_id\u0027: \u0027b893f0ce-7932-43de-a0d8-ef99a5e946e0\u0027})", "label": "Neeltje Kackar ", "shape": "dot", "title": "Node: Neeltje Kackar \nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "Luke Schleck ({\u0027paper_id\u0027: \u00272403.15729\u0027, \u0027relationship_description\u0027: \"Neeltje Kackar is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\", \u0027triplet_source_id\u0027: \u0027b893f0ce-7932-43de-a0d8-ef99a5e946e0\u0027})", "label": "Luke Schleck ", "shape": "dot", "title": "Node: Luke Schleck \nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "Cristiano Fanelli ({\u0027paper_id\u0027: \u00272403.15729\u0027, \u0027relationship_description\u0027: \"Luke Schleck is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\", \u0027triplet_source_id\u0027: \u0027b893f0ce-7932-43de-a0d8-ef99a5e946e0\u0027})", "label": "Cristiano Fanelli ", "shape": "dot", "title": "Node: Cristiano Fanelli \nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "Electron-Ion Collider (EIC) ({\u0027paper_id\u0027: \u00272403.15729\u0027, \u0027relationship_description\u0027: \"Cristiano Fanelli is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\", \u0027triplet_source_id\u0027: \u0027b893f0ce-7932-43de-a0d8-ef99a5e946e0\u0027})", "label": "Electron-Ion Collider (EIC) ", "shape": "dot", "title": "Node: Electron-Ion Collider (EIC) \nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "RAGS4EIC ({\u0027paper_id\u0027: \u00272403.15729\u0027, \u0027relationship_description\u0027: \u0027The Large Language Model (LLM) is used by RAGS4EIC to generate concise summaries\u0027, \u0027triplet_source_id\u0027: \u0027b893f0ce-7932-43de-a0d8-ef99a5e946e0\u0027})", "label": "RAGS4EIC ", "shape": "dot", "title": "Node: RAGS4EIC \nPaper ID: 2403.15729\nCommunity:-1"}, {"color": "##28282B", "id": "Large Language Model (LLM) ({\u0027paper_id\u0027: \u00272409.11279\u0027, \u0027relationship_description\u0027: \u0027P-RAG is designed to address the challenges of Embodied Everyday Task, such as lack of explicit task planning and extensive training required to equip models with knowledge of the task environment.\u0027, \u0027triplet_source_id\u0027: \u002709f7ff6c-3b28-4f75-872f-99ccc14b233b\u0027})", "label": "Large Language Model (LLM) ", "shape": "dot", "title": "Node: Large Language Model (LLM) \nPaper ID: 2409.11279\nCommunity:-1"}, {"color": "##28282B", "id": "LangChain ({\u0027paper_id\u0027: \u00272405.13576\u0027, \u0027entity_description\u0027: \u0027A RAG toolkit that is heavy and unwieldy.\u0027, \u0027triplet_source_id\u0027: \u0027a8f61713-df69-4765-8b08-26773e9ef73f\u0027})", "label": "LangChain ", "shape": "dot", "title": "Node: LangChain \nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "RQ-RAG ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027relationship_description\u0027: \u0027RQ-RAG was evaluated on single-hop QA datasets\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "RQ-RAG ", "shape": "dot", "title": "Node: RQ-RAG \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Llama2 model ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027relationship_description\u0027: \u0027RAG incorporates external documents into the response generation process\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Llama2 model ", "shape": "dot", "title": "Node: Llama2 model \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Single-hop QA datasets ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027relationship_description\u0027: \u0027RQ-RAG uses the Llama2 model\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Single-hop QA datasets ", "shape": "dot", "title": "Node: Single-hop QA datasets \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Multi-hop QA datasets ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027relationship_description\u0027: \u0027RQ-RAG was evaluated on single-hop QA datasets\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Multi-hop QA datasets ", "shape": "dot", "title": "Node: Multi-hop QA datasets \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Chi-Min Chan ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Chi-Min Chan ", "shape": "dot", "title": "Node: Chi-Min Chan \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Chunpu Xu ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Chunpu Xu ", "shape": "dot", "title": "Node: Chunpu Xu \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Ruibin Yuan ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Ruibin Yuan ", "shape": "dot", "title": "Node: Ruibin Yuan \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Hongyin Luo ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Hongyin Luo ", "shape": "dot", "title": "Node: Hongyin Luo \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Wei Xue ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Wei Xue ", "shape": "dot", "title": "Node: Wei Xue \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Yike Guo ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Yike Guo ", "shape": "dot", "title": "Node: Yike Guo \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Jie Fu ({\u0027paper_id\u0027: \u00272404.0061\u0027, \u0027entity_description\u0027: \u0027author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274a7ae57f-6794-4149-9188-20b5c9ecd8d2\u0027})", "label": "Jie Fu ", "shape": "dot", "title": "Node: Jie Fu \nPaper ID: 2404.0061\nCommunity:-1"}, {"color": "##28282B", "id": "Sumit Soman ({\u0027paper_id\u0027: \u00272404.00657\u0027, \u0027triplet_source_id\u0027: \u002760171f79-511f-4266-8616-56e3a682ef77\u0027})", "label": "Sumit Soman ", "shape": "dot", "title": "Node: Sumit Soman \nPaper ID: 2404.00657\nCommunity:-1"}, {"color": "##28282B", "id": "Sujoy Roychowdhury ({\u0027paper_id\u0027: \u00272404.00657\u0027, \u0027triplet_source_id\u0027: \u002760171f79-511f-4266-8616-56e3a682ef77\u0027})", "label": "Sujoy Roychowdhury ", "shape": "dot", "title": "Node: Sujoy Roychowdhury \nPaper ID: 2404.00657\nCommunity:-1"}, {"color": "##28282B", "id": "Technical Documents ({\u0027paper_id\u0027: \u00272404.00657\u0027, \u0027relationship_description\u0027: \"Sumit Soman and Sujoy Roychowdhury are co-authors of the paper \u0027Observations on Building RAG Systems for Technical Documents\u0027\", \u0027triplet_source_id\u0027: \u002760171f79-511f-4266-8616-56e3a682ef77\u0027})", "label": "Technical Documents ", "shape": "dot", "title": "Node: Technical Documents \nPaper ID: 2404.00657\nCommunity:-1"}, {"color": "##28282B", "id": "ARAGOG ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027relationship_description\u0027: \u0027HyDE is a method used in ARAGOG\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "ARAGOG ", "shape": "dot", "title": "Node: ARAGOG \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Matou\u0161 Eibich ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "Matou\u0161 Eibich ", "shape": "dot", "title": "Node: Matou\u0161 Eibich \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Shivay Nagpal ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027relationship_description\u0027: \u0027ARAGOG is authored by Matou\u0161 Eibich\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Shivay Nagpal ", "shape": "dot", "title": "Node: Shivay Nagpal \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Alexander Fred-Ojala ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027relationship_description\u0027: \u0027ARAGOG is authored by Shivay Nagpal\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Alexander Fred-Ojala ", "shape": "dot", "title": "Node: Alexander Fred-Ojala \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Hypothetical Document Embedding (HyDE) ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027relationship_description\u0027: \u0027ARAGOG is authored by Alexander Fred-Ojala\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Hypothetical Document Embedding (HyDE) ", "shape": "dot", "title": "Node: Hypothetical Document Embedding (HyDE) \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Maximal Marginal Relevance (MMR) ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A retrieval-augmented generation method\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Maximal Marginal Relevance (MMR) ", "shape": "dot", "title": "Node: Maximal Marginal Relevance (MMR) \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Cohere rerank ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A retrieval-augmented generation method\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Cohere rerank ", "shape": "dot", "title": "Node: Cohere rerank \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Naive RAG system ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A retrieval-augmented generation system\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Naive RAG system ", "shape": "dot", "title": "Node: Naive RAG system \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Multi-query approaches ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A type of retrieval-augmented generation method\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Multi-query approaches ", "shape": "dot", "title": "Node: Multi-query approaches \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Sentence Window Retrieval ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A retrieval-augmented generation method\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Sentence Window Retrieval ", "shape": "dot", "title": "Node: Sentence Window Retrieval \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "Document Summary Index ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A type of document index\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "Document Summary Index ", "shape": "dot", "title": "Node: Document Summary Index \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "GitHub repository ARAGOG ({\u0027paper_id\u0027: \u00272404.01037\u0027, \u0027entity_description\u0027: \u0027A GitHub repository containing research resources\u0027, \u0027triplet_source_id\u0027: \u0027baf1b69e-eeab-4b2f-b382-338652be3e12\u0027})", "label": "GitHub repository ARAGOG ", "shape": "dot", "title": "Node: GitHub repository ARAGOG \nPaper ID: 2404.01037\nCommunity:-1"}, {"color": "##28282B", "id": "CLAPNQ ({\u0027paper_id\u0027: \u00272404.02103\u0027, \u0027relationship_description\u0027: \u0027CLAPNQ is a benchmark dataset for the full RAG pipeline.\u0027, \u0027triplet_source_id\u0027: \u0027e164dd20-3e2b-4a70-9569-802cffcec2de\u0027})", "label": "CLAPNQ ", "shape": "dot", "title": "Node: CLAPNQ \nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "Natural Questions (NQ) ({\u0027paper_id\u0027: \u00272404.02103\u0027, \u0027relationship_description\u0027: \u0027CLAPNQ is a benchmark dataset for the full RAG pipeline.\u0027, \u0027triplet_source_id\u0027: \u0027e164dd20-3e2b-4a70-9569-802cffcec2de\u0027})", "label": "Natural Questions (NQ) ", "shape": "dot", "title": "Node: Natural Questions (NQ) \nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "Sara Rosenthal ({\u0027paper_id\u0027: \u00272404.02103\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027e164dd20-3e2b-4a70-9569-802cffcec2de\u0027})", "label": "Sara Rosenthal ", "shape": "dot", "title": "Node: Sara Rosenthal \nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "Avirup Sil ({\u0027paper_id\u0027: \u00272404.02103\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027e164dd20-3e2b-4a70-9569-802cffcec2de\u0027})", "label": "Avirup Sil ", "shape": "dot", "title": "Node: Avirup Sil \nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "Radu Florian ({\u0027paper_id\u0027: \u00272404.02103\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027e164dd20-3e2b-4a70-9569-802cffcec2de\u0027})", "label": "Radu Florian ", "shape": "dot", "title": "Node: Radu Florian \nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "Salim Roukos ({\u0027paper_id\u0027: \u00272404.02103\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027e164dd20-3e2b-4a70-9569-802cffcec2de\u0027})", "label": "Salim Roukos ", "shape": "dot", "title": "Node: Salim Roukos \nPaper ID: 2404.02103\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027Josep Crego is one of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation ", "shape": "dot", "title": "Node: Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Maxime Bouthors ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Maxime Bouthors ", "shape": "dot", "title": "Node: Maxime Bouthors \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Josep Crego ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027Maxime Bouthors is one of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Josep Crego ", "shape": "dot", "title": "Node: Josep Crego \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Francois Yvon ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027Josep Crego is one of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Francois Yvon ", "shape": "dot", "title": "Node: Francois Yvon \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Neural Machine Translation (RAMT) ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027RAMT uses an edit-based model\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Retrieval-Augmented Neural Machine Translation (RAMT) ", "shape": "dot", "title": "Node: Retrieval-Augmented Neural Machine Translation (RAMT) \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Autoregressive model ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027Francois Yvon is one of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Autoregressive model ", "shape": "dot", "title": "Node: Autoregressive model \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Edit-based model ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027RAMT uses an autoregressive model\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Edit-based model ", "shape": "dot", "title": "Node: Edit-based model \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Large language model with in-context learning ({\u0027paper_id\u0027: \u00272404.02835\u0027, \u0027relationship_description\u0027: \u0027RAMT uses an edit-based model\u0027, \u0027triplet_source_id\u0027: \u0027f9d607dd-d437-4285-ad38-d88b27d5e8c6\u0027})", "label": "Large language model with in-context learning ", "shape": "dot", "title": "Node: Large language model with in-context learning \nPaper ID: 2404.02835\nCommunity:-1"}, {"color": "##28282B", "id": "Financial Documents ({\u0027paper_id\u0027: \u00272404.07221\u0027, \u0027relationship_description\u0027: \u0027Large Language Models are enhanced by Retrieval Augmented Generation, which sources relevant text chunks to base queries upon.\u0027, \u0027triplet_source_id\u0027: \u00277e800680-f74e-4f95-a363-7d287533d7fb\u0027})", "label": "Financial Documents ", "shape": "dot", "title": "Node: Financial Documents \nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "Spurthi Setty ({\u0027paper_id\u0027: \u00272404.07221\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation uses Financial Documents to source relevant text chunks for query-based responses.\u0027, \u0027triplet_source_id\u0027: \u00277e800680-f74e-4f95-a363-7d287533d7fb\u0027})", "label": "Spurthi Setty ", "shape": "dot", "title": "Node: Spurthi Setty \nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "Harsh Thakkar ({\u0027paper_id\u0027: \u00272404.07221\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation uses Financial Documents to source relevant text chunks for query-based responses.\u0027, \u0027triplet_source_id\u0027: \u00277e800680-f74e-4f95-a363-7d287533d7fb\u0027})", "label": "Harsh Thakkar ", "shape": "dot", "title": "Node: Harsh Thakkar \nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "Alyssa Lee ({\u0027paper_id\u0027: \u00272404.07221\u0027, \u0027entity_description\u0027: \"Alyssa Lee is an author of the paper \u0027Improving Retrieval for RAG based Question Answering Models on Financial Documents\u0027.\", \u0027triplet_source_id\u0027: \u00277e800680-f74e-4f95-a363-7d287533d7fb\u0027})", "label": "Alyssa Lee ", "shape": "dot", "title": "Node: Alyssa Lee \nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "Eden Chung ({\u0027paper_id\u0027: \u00272404.07221\u0027, \u0027entity_description\u0027: \"Eden Chung is an author of the paper \u0027Improving Retrieval for RAG based Question Answering Models on Financial Documents\u0027.\", \u0027triplet_source_id\u0027: \u00277e800680-f74e-4f95-a363-7d287533d7fb\u0027})", "label": "Eden Chung ", "shape": "dot", "title": "Node: Eden Chung \nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "Natan Vidra ({\u0027paper_id\u0027: \u00272404.07221\u0027, \u0027entity_description\u0027: \"Natan Vidra is an author of the paper \u0027Improving Retrieval for RAG based Question Answering Models on Financial Documents\u0027.\", \u0027triplet_source_id\u0027: \u00277e800680-f74e-4f95-a363-7d287533d7fb\u0027})", "label": "Natan Vidra ", "shape": "dot", "title": "Node: Natan Vidra \nPaper ID: 2404.07221\nCommunity:-1"}, {"color": "##28282B", "id": "Patrice B\u00e8chard ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Patrice B\u00e8chard ", "shape": "dot", "title": "Node: Patrice B\u00e8chard \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Orlando Marquez Ayala ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Orlando Marquez Ayala ", "shape": "dot", "title": "Node: Orlando Marquez Ayala \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Structured Output ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027relationship_description\u0027: \u0027Generative AI is prone to hallucination\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Structured Output ", "shape": "dot", "title": "Node: Structured Output \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Workflows ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027entity_description\u0027: \u0027Series of tasks or activities that are performed in a specific order\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Workflows ", "shape": "dot", "title": "Node: Workflows \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Natural Language Requirements ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027entity_description\u0027: \u0027Requirements that are expressed in natural language\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Natural Language Requirements ", "shape": "dot", "title": "Node: Natural Language Requirements \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Hallucination ({\u0027paper_id\u0027: \u00272404.08189\u0027, \u0027relationship_description\u0027: \u0027Patrice B\u00e8chard and Orlando Marquez Ayala are authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002779242a10-3c1a-4f29-9342-18f0711a41e5\u0027})", "label": "Hallucination ", "shape": "dot", "title": "Node: Hallucination \nPaper ID: 2404.08189\nCommunity:-1"}, {"color": "##28282B", "id": "Yizheng Huang ({\u0027paper_id\u0027: \u00272404.10981\u0027, \u0027triplet_source_id\u0027: \u002720523d98-b390-41e8-b7f8-27121e6a955e\u0027})", "label": "Yizheng Huang ", "shape": "dot", "title": "Node: Yizheng Huang \nPaper ID: 2404.10981\nCommunity:-1"}, {"color": "##28282B", "id": "Jimmy Huang ({\u0027paper_id\u0027: \u00272404.10981\u0027, \u0027triplet_source_id\u0027: \u002720523d98-b390-41e8-b7f8-27121e6a955e\u0027})", "label": "Jimmy Huang ", "shape": "dot", "title": "Node: Jimmy Huang \nPaper ID: 2404.10981\nCommunity:-1"}, {"color": "##28282B", "id": "Text Domain ({\u0027paper_id\u0027: \u00272404.10981\u0027, \u0027relationship_description\u0027: \"RAG enhances the accuracy and reliability of LLMs\u0027 outputs\", \u0027triplet_source_id\u0027: \u002720523d98-b390-41e8-b7f8-27121e6a955e\u0027})", "label": "Text Domain ", "shape": "dot", "title": "Node: Text Domain \nPaper ID: 2404.10981\nCommunity:-1"}, {"color": "##28282B", "id": "Paper ({\u0027paper_id\u0027: \u00272404.10981\u0027, \u0027entity_description\u0027: \u0027A written work or document\u0027, \u0027triplet_source_id\u0027: \u002720523d98-b390-41e8-b7f8-27121e6a955e\u0027})", "label": "Paper ", "shape": "dot", "title": "Node: Paper \nPaper ID: 2404.10981\nCommunity:-1"}, {"color": "##28282B", "id": "RAGCache ({\u0027paper_id\u0027: \u00272404.12457\u0027, \u0027relationship_description\u0027: \u0027RAGCache optimizes the performance of Large Language Models by caching intermediate states\u0027, \u0027triplet_source_id\u0027: \u00278d76b4a5-0278-41c3-bbab-ba0db45b6b70\u0027})", "label": "RAGCache ", "shape": "dot", "title": "Node: RAGCache \nPaper ID: 2404.12457\nCommunity:-1"}, {"color": "##28282B", "id": "External Knowledge Databases ({\u0027paper_id\u0027: \u00272404.12457\u0027, \u0027relationship_description\u0027: \u0027RAGCache optimizes the performance of Large Language Models by caching intermediate states\u0027, \u0027triplet_source_id\u0027: \u00278d76b4a5-0278-41c3-bbab-ba0db45b6b70\u0027})", "label": "External Knowledge Databases ", "shape": "dot", "title": "Node: External Knowledge Databases \nPaper ID: 2404.12457\nCommunity:-1"}, {"color": "##28282B", "id": "vLLM ({\u0027paper_id\u0027: \u00272404.12457\u0027, \u0027relationship_description\u0027: \u0027RAGCache integrates the strengths of External Knowledge Databases with Large Language Models\u0027, \u0027triplet_source_id\u0027: \u00278d76b4a5-0278-41c3-bbab-ba0db45b6b70\u0027})", "label": "vLLM ", "shape": "dot", "title": "Node: vLLM \nPaper ID: 2404.12457\nCommunity:-1"}, {"color": "##28282B", "id": "Faiss ({\u0027paper_id\u0027: \u00272404.12457\u0027, \u0027relationship_description\u0027: \u0027RAGCache integrates the strengths of External Knowledge Databases with Large Language Models\u0027, \u0027triplet_source_id\u0027: \u00278d76b4a5-0278-41c3-bbab-ba0db45b6b70\u0027})", "label": "Faiss ", "shape": "dot", "title": "Node: Faiss \nPaper ID: 2404.12457\nCommunity:-1"}, {"color": "##28282B", "id": "RAU ({\u0027paper_id\u0027: \u00272404.19543\u0027, \u0027relationship_description\u0027: \u0027RAG integrates information retrieved from external resources with LLMs for generation tasks.\u0027, \u0027triplet_source_id\u0027: \u0027c793c4ea-d46c-473d-b257-73cc52bfd9cc\u0027})", "label": "RAU ", "shape": "dot", "title": "Node: RAU \nPaper ID: 2404.19543\nCommunity:-1"}, {"color": "##28282B", "id": "NLP ({\u0027paper_id\u0027: \u00272404.19543\u0027, \u0027entity_description\u0027: \u0027A field of research that focuses on the interaction between computers and human language.\u0027, \u0027triplet_source_id\u0027: \u0027c793c4ea-d46c-473d-b257-73cc52bfd9cc\u0027})", "label": "NLP ", "shape": "dot", "title": "Node: NLP \nPaper ID: 2404.19543\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Language Models ({\u0027paper_id\u0027: \u00272404.19543\u0027, \u0027relationship_description\u0027: \"Retrieval-Augmented Language Models combine the retrieved information with Language Models\u0027 output.\", \u0027triplet_source_id\u0027: \u0027c793c4ea-d46c-473d-b257-73cc52bfd9cc\u0027})", "label": "Retrieval-Augmented Language Models ", "shape": "dot", "title": "Node: Retrieval-Augmented Language Models \nPaper ID: 2404.19543\nCommunity:-1"}, {"color": "##28282B", "id": "Language Models ({\u0027paper_id\u0027: \u00272410.13339\u0027, \u0027triplet_source_id\u0027: \u0027bff142f7-57eb-4c61-85d5-615bfe4b4cd6\u0027})", "label": "Language Models ", "shape": "dot", "title": "Node: Language Models \nPaper ID: 2410.13339\nCommunity:-1"}, {"color": "##28282B", "id": "Augmentations ({\u0027paper_id\u0027: \u00272404.19543\u0027, \u0027relationship_description\u0027: \"Retrieval-Augmented Language Models combine the retrieved information with Language Models\u0027 output.\", \u0027triplet_source_id\u0027: \u0027c793c4ea-d46c-473d-b257-73cc52bfd9cc\u0027})", "label": "Augmentations ", "shape": "dot", "title": "Node: Augmentations \nPaper ID: 2404.19543\nCommunity:-1"}, {"color": "##28282B", "id": "Github Repository ({\u0027paper_id\u0027: \u00272404.19543\u0027, \u0027entity_description\u0027: \u0027A repository containing the surveyed works and resources for further study.\u0027, \u0027triplet_source_id\u0027: \u0027c793c4ea-d46c-473d-b257-73cc52bfd9cc\u0027})", "label": "Github Repository ", "shape": "dot", "title": "Node: Github Repository \nPaper ID: 2404.19543\nCommunity:-1"}, {"color": "##28282B", "id": "Alireza Salemi ({\u0027paper_id\u0027: \u00272410.09942\u0027, \u0027triplet_source_id\u0027: \u002737b7c0f0-e3ac-47b9-a15d-92a3d045dcad\u0027})", "label": "Alireza Salemi ", "shape": "dot", "title": "Node: Alireza Salemi \nPaper ID: 2410.09942\nCommunity:-1"}, {"color": "##28282B", "id": "Hamed Zamani ({\u0027paper_id\u0027: \u00272410.09942\u0027, \u0027triplet_source_id\u0027: \u002737b7c0f0-e3ac-47b9-a15d-92a3d045dcad\u0027})", "label": "Hamed Zamani ", "shape": "dot", "title": "Node: Hamed Zamani \nPaper ID: 2410.09942\nCommunity:-1"}, {"color": "##28282B", "id": "uRAG ({\u0027paper_id\u0027: \u00272405.00175\u0027, \u0027relationship_description\u0027: \u0027uRAG is a framework that serves multiple RAG systems\u0027, \u0027triplet_source_id\u0027: \u00279f747096-7da2-41f4-be71-2c107e88de6b\u0027})", "label": "uRAG ", "shape": "dot", "title": "Node: uRAG \nPaper ID: 2405.00175\nCommunity:-1"}, {"color": "##28282B", "id": "Search Engine ({\u0027paper_id\u0027: \u00272405.00175\u0027, \u0027relationship_description\u0027: \u0027uRAG is a framework that serves multiple RAG systems\u0027, \u0027triplet_source_id\u0027: \u00279f747096-7da2-41f4-be71-2c107e88de6b\u0027})", "label": "Search Engine ", "shape": "dot", "title": "Node: Search Engine \nPaper ID: 2405.00175\nCommunity:-1"}, {"color": "##28282B", "id": "GAIA ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027relationship_description\u0027: \u0027GAIA is a system that assists in the operation of particle accelerators\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "GAIA ", "shape": "dot", "title": "Node: GAIA \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "Frank Mayet ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Frank Mayet ", "shape": "dot", "title": "Node: Frank Mayet \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Particle Accelerators ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027relationship_description\u0027: \"Frank Mayet is the author of the paper \u0027GAIA: A General AI Assistant for Intelligent Accelerator Operations\u0027\", \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "Particle Accelerators ", "shape": "dot", "title": "Node: Particle Accelerators \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "Operators ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027relationship_description\u0027: \u0027ReAct is used to couple an open-weights large language model with a high-level machine control system framework\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "Operators ", "shape": "dot", "title": "Node: Operators \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "ReAct ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027relationship_description\u0027: \u0027Operators are responsible for running particle accelerators\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "ReAct ", "shape": "dot", "title": "Node: ReAct \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "LLM ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027relationship_description\u0027: \u0027RAIDD is an extension to Retrieval Augmented Generation systems.\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "LLM ", "shape": "dot", "title": "Node: LLM \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "Machine Control System Framework ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027entity_description\u0027: \u0027High-level machine control system framework\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "Machine Control System Framework ", "shape": "dot", "title": "Node: Machine Control System Framework \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "Electronic Logbook ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027entity_description\u0027: \u0027Digital record of machine operations and maintenance\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "Electronic Logbook ", "shape": "dot", "title": "Node: Electronic Logbook \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "Machine Design Documentation ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027entity_description\u0027: \u0027Technical documentation of machine design and operation\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "Machine Design Documentation ", "shape": "dot", "title": "Node: Machine Design Documentation \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "RAG System ({\u0027paper_id\u0027: \u00272405.01359\u0027, \u0027relationship_description\u0027: \u0027ReAct is used to couple an open-weights large language model with a high-level machine control system framework\u0027, \u0027triplet_source_id\u0027: \u0027dd900749-5af2-45f3-89d0-e90a4199b357\u0027})", "label": "RAG System ", "shape": "dot", "title": "Node: RAG System \nPaper ID: 2405.01359\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Large Language Models ({\u0027paper_id\u0027: \u00272405.1967\u0027, \u0027relationship_description\u0027: \u0027Zhicheng Dou is the author of Retrieval-Augmented Large Language Models\u0027, \u0027triplet_source_id\u0027: \u002718b24d7e-4a8e-4b35-b038-c4ff3476dbcd\u0027})", "label": "Retrieval-Augmented Large Language Models ", "shape": "dot", "title": "Node: Retrieval-Augmented Large Language Models \nPaper ID: 2405.1967\nCommunity:-1"}, {"color": "##28282B", "id": "AI-Generated Content ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Content generated by AI systems\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "AI-Generated Content ", "shape": "dot", "title": "Node: AI-Generated Content \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Wenqi Fan ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Wenqi Fan ", "shape": "dot", "title": "Node: Wenqi Fan \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Yujuan Ding ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Yujuan Ding ", "shape": "dot", "title": "Node: Yujuan Ding \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Liangbo Ning ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Liangbo Ning ", "shape": "dot", "title": "Node: Liangbo Ning \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Shijie Wang ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Shijie Wang ", "shape": "dot", "title": "Node: Shijie Wang \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Hengyun Li ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Hengyun Li ", "shape": "dot", "title": "Node: Hengyun Li \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Dawei Yin ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Dawei Yin ", "shape": "dot", "title": "Node: Dawei Yin \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Tat-Seng Chua ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Tat-Seng Chua ", "shape": "dot", "title": "Node: Tat-Seng Chua \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Qing Li ({\u0027paper_id\u0027: \u00272405.06211\u0027, \u0027entity_description\u0027: \u0027Author of the survey paper\u0027, \u0027triplet_source_id\u0027: \u0027e0975e93-d27f-42fb-a7e2-f6fd5704b4e2\u0027})", "label": "Qing Li ", "shape": "dot", "title": "Node: Qing Li \nPaper ID: 2405.06211\nCommunity:-1"}, {"color": "##28282B", "id": "Hao Yu ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "Hao Yu ", "shape": "dot", "title": "Node: Hao Yu \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "Aoran Gan ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027relationship_description\u0027: \"Hao Yu is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "Aoran Gan ", "shape": "dot", "title": "Node: Aoran Gan \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "Kai Zhang ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027relationship_description\u0027: \"Aoran Gan is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "Kai Zhang ", "shape": "dot", "title": "Node: Kai Zhang \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "Shiwei Tong ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027relationship_description\u0027: \"Kai Zhang is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "Shiwei Tong ", "shape": "dot", "title": "Node: Shiwei Tong \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "Qi Liu ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Qi Liu ", "shape": "dot", "title": "Node: Qi Liu \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Zhaofeng Liu ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027relationship_description\u0027: \"Qi Liu is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "Zhaofeng Liu ", "shape": "dot", "title": "Node: Zhaofeng Liu \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "A Unified Evaluation Process of RAG ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027relationship_description\u0027: \"Zhaofeng Liu is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\", \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "A Unified Evaluation Process of RAG ", "shape": "dot", "title": "Node: A Unified Evaluation Process of RAG \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "RAG benchmarks ({\u0027paper_id\u0027: \u00272405.07437\u0027, \u0027entity_description\u0027: \u0027A collection of datasets for evaluating Retrieval-Augmented Generation systems\u0027, \u0027triplet_source_id\u0027: \u0027e95b195f-ce4e-4d69-a883-121385239dd7\u0027})", "label": "RAG benchmarks ", "shape": "dot", "title": "Node: RAG benchmarks \nPaper ID: 2405.07437\nCommunity:-1"}, {"color": "##28282B", "id": "Vatsal Raina ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Vatsal Raina ", "shape": "dot", "title": "Node: Vatsal Raina \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Mark Gales ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Mark Gales ", "shape": "dot", "title": "Node: Mark Gales \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Enterprise retrieval augmented generation (RAG) ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027relationship_description\u0027: \"Both authors contributed to the paper \u0027Question-Based Retrieval using Atomic Units for Enterprise RAG\u0027\", \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Enterprise retrieval augmented generation (RAG) ", "shape": "dot", "title": "Node: Enterprise retrieval augmented generation (RAG) \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Documents ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027relationship_description\u0027: \u0027The RAG framework combines LLMs with internal documents\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Documents ", "shape": "dot", "title": "Node: Documents \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Synthesizer LLM ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027relationship_description\u0027: \u0027The RAG framework combines LLMs with internal documents\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Synthesizer LLM ", "shape": "dot", "title": "Node: Synthesizer LLM \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Atomic statements ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027relationship_description\u0027: \u0027The synthesizer LLM uses documents as input\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Atomic statements ", "shape": "dot", "title": "Node: Atomic statements \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "User query ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027relationship_description\u0027: \u0027Dense retrieval is used to retrieve relevant atomic statements\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "User query ", "shape": "dot", "title": "Node: User query \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Dense retrieval ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027relationship_description\u0027: \u0027Dense retrieval is used to retrieve relevant atomic statements\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Dense retrieval ", "shape": "dot", "title": "Node: Dense retrieval \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "Enterprise LLM ({\u0027paper_id\u0027: \u00272405.12363\u0027, \u0027entity_description\u0027: \u0027A type of language model used in the RAG pipeline\u0027, \u0027triplet_source_id\u0027: \u0027b2fe1914-ff02-4928-a59a-36a673b7b407\u0027})", "label": "Enterprise LLM ", "shape": "dot", "title": "Node: Enterprise LLM \nPaper ID: 2405.12363\nCommunity:-1"}, {"color": "##28282B", "id": "DuetRAG ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027relationship_description\u0027: \u0027DuetRAG augments the input of Large Language Models with relevant retrieved passages\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "DuetRAG ", "shape": "dot", "title": "Node: DuetRAG \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "HotPot QA ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027relationship_description\u0027: \u0027DuetRAG augments the input of Large Language Models with relevant retrieved passages\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "HotPot QA ", "shape": "dot", "title": "Node: HotPot QA \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "Dian Jiao ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of DuetRAG\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "Dian Jiao ", "shape": "dot", "title": "Node: Dian Jiao \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "Li Cai ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of DuetRAG\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "Li Cai ", "shape": "dot", "title": "Node: Li Cai \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "Jingsheng Huang ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of DuetRAG\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "Jingsheng Huang ", "shape": "dot", "title": "Node: Jingsheng Huang \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "Wenqiao Zhang ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of DuetRAG\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "Wenqiao Zhang ", "shape": "dot", "title": "Node: Wenqiao Zhang \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "Siliang Tang ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Siliang Tang ", "shape": "dot", "title": "Node: Siliang Tang \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Yueting Zhuang ({\u0027paper_id\u0027: \u00272405.13002\u0027, \u0027entity_description\u0027: \u0027A researcher involved in the development of DuetRAG\u0027, \u0027triplet_source_id\u0027: \u002740dbdbb8-b6ef-420a-bee3-000765cf9c94\u0027})", "label": "Yueting Zhuang ", "shape": "dot", "title": "Node: Yueting Zhuang \nPaper ID: 2405.13002\nCommunity:-1"}, {"color": "##28282B", "id": "FlashRAG ({\u0027paper_id\u0027: \u00272405.13576\u0027, \u0027relationship_description\u0027: \u0027FlashRAG is related to Retrieval-Augmented Generation (RAG) as it is a toolkit for implementing RAG methods.\u0027, \u0027triplet_source_id\u0027: \u0027a8f61713-df69-4765-8b08-26773e9ef73f\u0027})", "label": "FlashRAG ", "shape": "dot", "title": "Node: FlashRAG \nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "Jiajie Jin ({\u0027paper_id\u0027: \u00272405.13576\u0027, \u0027triplet_source_id\u0027: \u0027a8f61713-df69-4765-8b08-26773e9ef73f\u0027})", "label": "Jiajie Jin ", "shape": "dot", "title": "Node: Jiajie Jin \nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "Yutao Zhu ({\u0027paper_id\u0027: \u00272405.1967\u0027, \u0027triplet_source_id\u0027: \u002718b24d7e-4a8e-4b35-b038-c4ff3476dbcd\u0027})", "label": "Yutao Zhu ", "shape": "dot", "title": "Node: Yutao Zhu \nPaper ID: 2405.1967\nCommunity:-1"}, {"color": "##28282B", "id": "Xinyu Yang ({\u0027paper_id\u0027: \u00272405.13576\u0027, \u0027relationship_description\u0027: \"Yutao Zhu is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u0027a8f61713-df69-4765-8b08-26773e9ef73f\u0027})", "label": "Xinyu Yang ", "shape": "dot", "title": "Node: Xinyu Yang \nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "Chenghao Zhang ({\u0027paper_id\u0027: \u00272405.13576\u0027, \u0027relationship_description\u0027: \"Xinyu Yang is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u0027a8f61713-df69-4765-8b08-26773e9ef73f\u0027})", "label": "Chenghao Zhang ", "shape": "dot", "title": "Node: Chenghao Zhang \nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "Zhicheng Dou ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027Kelong Mao is one of the authors of MemoRAG\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "Zhicheng Dou ", "shape": "dot", "title": "Node: Zhicheng Dou \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "LlamaIndex ({\u0027paper_id\u0027: \u00272405.13576\u0027, \u0027entity_description\u0027: \u0027A RAG toolkit that is heavy and unwieldy.\u0027, \u0027triplet_source_id\u0027: \u0027a8f61713-df69-4765-8b08-26773e9ef73f\u0027})", "label": "LlamaIndex ", "shape": "dot", "title": "Node: LlamaIndex \nPaper ID: 2405.13576\nCommunity:-1"}, {"color": "##28282B", "id": "Caitlin Sikora ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Caitlin Sikora ", "shape": "dot", "title": "Node: Caitlin Sikora \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Ho Ko ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Ho Ko ", "shape": "dot", "title": "Node: Ho Ko \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Yinxiao Liu ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Yinxiao Liu ", "shape": "dot", "title": "Node: Yinxiao Liu \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Chu-Cheng Lin ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Chu-Cheng Lin ", "shape": "dot", "title": "Node: Chu-Cheng Lin \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Lei Shu ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Lei Shu ", "shape": "dot", "title": "Node: Lei Shu \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Liangchen Luo ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Liangchen Luo ", "shape": "dot", "title": "Node: Liangchen Luo \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Lei Meng ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Lei Meng ", "shape": "dot", "title": "Node: Lei Meng \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Bang Liu ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Bang Liu ", "shape": "dot", "title": "Node: Bang Liu \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Jindong Chen ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Jindong Chen ", "shape": "dot", "title": "Node: Jindong Chen \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Sparse RAG ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027relationship_description\u0027: \u0027Sparse RAG encodes retrieved documents in parallel to eliminate latency\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Sparse RAG ", "shape": "dot", "title": "Node: Sparse RAG \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Large language models (LLMs) ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027relationship_description\u0027: \u0027EfficientRAG is a type of retrieval-augmented generation method.\u0027, \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Large language models (LLMs) ", "shape": "dot", "title": "Node: Large language models (LLMs) \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieved documents ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027relationship_description\u0027: \u0027Sparse RAG combines LLMs with retrieval to exhibit robust performance and extensive versatility\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Retrieved documents ", "shape": "dot", "title": "Node: Retrieved documents \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "Control tokens ({\u0027paper_id\u0027: \u00272405.16178\u0027, \u0027relationship_description\u0027: \u0027Sparse RAG encodes retrieved documents in parallel to eliminate latency\u0027, \u0027triplet_source_id\u0027: \u0027722200f5-2c57-4932-b7fd-9bdf90d270ae\u0027})", "label": "Control tokens ", "shape": "dot", "title": "Node: Control tokens \nPaper ID: 2405.16178\nCommunity:-1"}, {"color": "##28282B", "id": "M-RAG ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027Yongjun Xu is an author of the paper introducing M-RAG\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "M-RAG ", "shape": "dot", "title": "Node: M-RAG \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Multi-Agent Reinforcement Learning ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027M-RAG enhances Large Language Models by retrieving relevant memories from an external database\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "Multi-Agent Reinforcement Learning ", "shape": "dot", "title": "Node: Multi-Agent Reinforcement Learning \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Zheng Wang ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027M-RAG leverages Multi-Agent Reinforcement Learning to optimize different language generation tasks explicitly\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "Zheng Wang ", "shape": "dot", "title": "Node: Zheng Wang \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Shu Xian Teo ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027Zheng Wang is an author of the paper introducing M-RAG\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "Shu Xian Teo ", "shape": "dot", "title": "Node: Shu Xian Teo \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Jieer Ouyang ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027Shu Xian Teo is an author of the paper introducing M-RAG\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "Jieer Ouyang ", "shape": "dot", "title": "Node: Jieer Ouyang \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Yongjun Xu ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027Jieer Ouyang is an author of the paper introducing M-RAG\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "Yongjun Xu ", "shape": "dot", "title": "Node: Yongjun Xu \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Wei Shi ({\u0027paper_id\u0027: \u00272405.1642\u0027, \u0027relationship_description\u0027: \u0027Yongjun Xu is an author of the paper introducing M-RAG\u0027, \u0027triplet_source_id\u0027: \u0027ab43993a-1d25-449e-8e04-22e874fcb6a1\u0027})", "label": "Wei Shi ", "shape": "dot", "title": "Node: Wei Shi \nPaper ID: 2405.1642\nCommunity:-1"}, {"color": "##28282B", "id": "Sudeshna Das ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027relationship_description\u0027: \u0027Sudeshna Das is the author of the paper that proposes the Retrieval Augmented Generation (RAG) framework\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Sudeshna Das ", "shape": "dot", "title": "Node: Sudeshna Das \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Yao Ge ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Yao Ge ", "shape": "dot", "title": "Node: Yao Ge \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Yuting Guo ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Yuting Guo ", "shape": "dot", "title": "Node: Yuting Guo \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Swati Rajwal ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Swati Rajwal ", "shape": "dot", "title": "Node: Swati Rajwal \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "JaMor Hairston ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "JaMor Hairston ", "shape": "dot", "title": "Node: JaMor Hairston \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Jeanne Powell ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Jeanne Powell ", "shape": "dot", "title": "Node: Jeanne Powell \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Drew Walker ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Drew Walker ", "shape": "dot", "title": "Node: Drew Walker \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Snigdha Peddireddy ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Snigdha Peddireddy ", "shape": "dot", "title": "Node: Snigdha Peddireddy \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Sahithi Lakamana ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Sahithi Lakamana ", "shape": "dot", "title": "Node: Sahithi Lakamana \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Selen Bozkurt ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Selen Bozkurt ", "shape": "dot", "title": "Node: Selen Bozkurt \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Matthew Reyna ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Matthew Reyna ", "shape": "dot", "title": "Node: Matthew Reyna \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Reza Sameni ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Reza Sameni ", "shape": "dot", "title": "Node: Reza Sameni \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Yunyu Xiao ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Yunyu Xiao ", "shape": "dot", "title": "Node: Yunyu Xiao \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Sangmi Kim ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Sangmi Kim ", "shape": "dot", "title": "Node: Sangmi Kim \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Rasheeta Chandler ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Rasheeta Chandler ", "shape": "dot", "title": "Node: Rasheeta Chandler \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Natalie Hernandez ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Natalie Hernandez ", "shape": "dot", "title": "Node: Natalie Hernandez \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Danielle Mowery ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Danielle Mowery ", "shape": "dot", "title": "Node: Danielle Mowery \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Rachel Wightman ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Rachel Wightman ", "shape": "dot", "title": "Node: Rachel Wightman \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Jennifer Love ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Jennifer Love ", "shape": "dot", "title": "Node: Jennifer Love \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Anthony Spadaro ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Anthony Spadaro ", "shape": "dot", "title": "Node: Anthony Spadaro \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Jeanmarie Perrone ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Jeanmarie Perrone ", "shape": "dot", "title": "Node: Jeanmarie Perrone \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Abeed Sarker ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Abeed Sarker ", "shape": "dot", "title": "Node: Abeed Sarker \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Reddit ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027relationship_description\u0027: \u0027The paper uses a Generative Large Language Model (LLM) in the study\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Reddit ", "shape": "dot", "title": "Node: Reddit \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Generative Large Language Model (LLM) ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027relationship_description\u0027: \u0027Sudeshna Das is the author of the paper that proposes the Retrieval Augmented Generation (RAG) framework\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Generative Large Language Model (LLM) ", "shape": "dot", "title": "Node: Generative Large Language Model (LLM) \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Social media forums ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027relationship_description\u0027: \u0027Reddit is a social media platform used in the study\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Social media forums ", "shape": "dot", "title": "Node: Social media forums \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Emerging drug-related information ({\u0027paper_id\u0027: \u00272405.19519\u0027, \u0027relationship_description\u0027: \u0027Reddit is a social media platform used in the study\u0027, \u0027triplet_source_id\u0027: \u00271f191c00-e53f-4689-8e05-7568a370c702\u0027})", "label": "Emerging drug-related information ", "shape": "dot", "title": "Node: Emerging drug-related information \nPaper ID: 2405.19519\nCommunity:-1"}, {"color": "##28282B", "id": "Zhaoheng Huang ({\u0027paper_id\u0027: \u00272405.1967\u0027, \u0027relationship_description\u0027: \u0027Yutao Zhu is the author of Retrieval-Augmented Large Language Models\u0027, \u0027triplet_source_id\u0027: \u002718b24d7e-4a8e-4b35-b038-c4ff3476dbcd\u0027})", "label": "Zhaoheng Huang ", "shape": "dot", "title": "Node: Zhaoheng Huang \nPaper ID: 2405.1967\nCommunity:-1"}, {"color": "##28282B", "id": "Ji-Rong Wen ({\u0027paper_id\u0027: \u00272405.1967\u0027, \u0027relationship_description\u0027: \u0027Zhicheng Dou is the author of Retrieval-Augmented Large Language Models\u0027, \u0027triplet_source_id\u0027: \u002718b24d7e-4a8e-4b35-b038-c4ff3476dbcd\u0027})", "label": "Ji-Rong Wen ", "shape": "dot", "title": "Node: Ji-Rong Wen \nPaper ID: 2405.1967\nCommunity:-1"}, {"color": "##28282B", "id": "Virtual Tokens ({\u0027paper_id\u0027: \u00272405.1967\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation improves Large Language Models\u0027, \u0027triplet_source_id\u0027: \u002718b24d7e-4a8e-4b35-b038-c4ff3476dbcd\u0027})", "label": "Virtual Tokens ", "shape": "dot", "title": "Node: Virtual Tokens \nPaper ID: 2405.1967\nCommunity:-1"}, {"color": "##28282B", "id": "Wei Tang ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Wei Tang ", "shape": "dot", "title": "Node: Wei Tang \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Yixin Cao ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Wei Tang is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Yixin Cao ", "shape": "dot", "title": "Node: Yixin Cao \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Jiahao Ying ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Yixin Cao is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Jiahao Ying ", "shape": "dot", "title": "Node: Jiahao Ying \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Bo Wang ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Jiahao Ying is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Bo Wang ", "shape": "dot", "title": "Node: Bo Wang \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Yuyue Zhao ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Bo Wang is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Yuyue Zhao ", "shape": "dot", "title": "Node: Yuyue Zhao \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Yong Liao ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Yuyue Zhao is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Yong Liao ", "shape": "dot", "title": "Node: Yong Liao \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Pengyuan Zhou ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Yong Liao is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Pengyuan Zhou ", "shape": "dot", "title": "Node: Pengyuan Zhou \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "A + B framework ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027relationship_description\u0027: \u0027Pengyuan Zhou is the author of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "A + B framework ", "shape": "dot", "title": "Node: A + B framework \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Foundation models ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027entity_description\u0027: \u0027Type of artificial intelligence models\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Foundation models ", "shape": "dot", "title": "Node: Foundation models \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Chat versions of LLMs ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027entity_description\u0027: \u0027Type of artificial intelligence models\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Chat versions of LLMs ", "shape": "dot", "title": "Node: Chat versions of LLMs \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Base versions of LLMs ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027entity_description\u0027: \u0027Type of artificial intelligence models\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Base versions of LLMs ", "shape": "dot", "title": "Node: Base versions of LLMs \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Source documents ({\u0027paper_id\u0027: \u00272406.03963\u0027, \u0027entity_description\u0027: \u0027Type of external knowledge\u0027, \u0027triplet_source_id\u0027: \u0027c5116e7b-dae3-4237-936b-e66271be64c3\u0027})", "label": "Source documents ", "shape": "dot", "title": "Node: Source documents \nPaper ID: 2406.03963\nCommunity:-1"}, {"color": "##28282B", "id": "Multi-Head RAG ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027relationship_description\u0027: \u0027Multi-Head RAG works with Large Language Models (LLMs) to provide more accurate and relevant responses.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Multi-Head RAG ", "shape": "dot", "title": "Node: Multi-Head RAG \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Transformer ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027relationship_description\u0027: \u0027Multi-Head RAG works with Large Language Models (LLMs) to provide more accurate and relevant responses.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Transformer ", "shape": "dot", "title": "Node: Transformer \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Maciej Besta ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Maciej Besta ", "shape": "dot", "title": "Node: Maciej Besta \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Ales Kubicek ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Ales Kubicek ", "shape": "dot", "title": "Node: Ales Kubicek \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Roman Niggli ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Roman Niggli ", "shape": "dot", "title": "Node: Roman Niggli \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Robert Gerstenberger ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Robert Gerstenberger ", "shape": "dot", "title": "Node: Robert Gerstenberger \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Lucas Weitzendorf ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Lucas Weitzendorf ", "shape": "dot", "title": "Node: Lucas Weitzendorf \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Mingyuan Chi ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Mingyuan Chi ", "shape": "dot", "title": "Node: Mingyuan Chi \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Patrick Iff ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Patrick Iff ", "shape": "dot", "title": "Node: Patrick Iff \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Joanna Gajda ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Joanna Gajda ", "shape": "dot", "title": "Node: Joanna Gajda \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Piotr Nyczyk ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Piotr Nyczyk ", "shape": "dot", "title": "Node: Piotr Nyczyk \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "J\u00fcrgen M\u00fcller ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "J\u00fcrgen M\u00fcller ", "shape": "dot", "title": "Node: J\u00fcrgen M\u00fcller \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Hubert Niewiadomski ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Hubert Niewiadomski ", "shape": "dot", "title": "Node: Hubert Niewiadomski \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Marcin Chrapek ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Marcin Chrapek ", "shape": "dot", "title": "Node: Marcin Chrapek \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Micha\u0142 Podstawski ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Micha\u0142 Podstawski ", "shape": "dot", "title": "Node: Micha\u0142 Podstawski \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "Torsten Hoefler ({\u0027paper_id\u0027: \u00272406.05085\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing Multi-Head RAG.\u0027, \u0027triplet_source_id\u0027: \u0027bfbf2394-0fc5-4874-937a-ba227fcd2eef\u0027})", "label": "Torsten Hoefler ", "shape": "dot", "title": "Node: Torsten Hoefler \nPaper ID: 2406.05085\nCommunity:-1"}, {"color": "##28282B", "id": "DR-RAG ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027relationship_description\u0027: \u0027DR-RAG is a variant of Retrieval-Augmented Generation (RAG) that improves document retrieval recall and the accuracy of answers.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "DR-RAG ", "shape": "dot", "title": "Node: DR-RAG \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Question-Answering (QA) ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027relationship_description\u0027: \u0027DR-RAG uses Large Language Models (LLMs) to generate responses to questions.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Question-Answering (QA) ", "shape": "dot", "title": "Node: Question-Answering (QA) \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Zijian Hei ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation (RAG) is applied to the task of Question-Answering (QA).\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Zijian Hei ", "shape": "dot", "title": "Node: Zijian Hei \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Weiling Liu ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation (RAG) is applied to the task of Question-Answering (QA).\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Weiling Liu ", "shape": "dot", "title": "Node: Weiling Liu \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Wenjie Ou ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Wenjie Ou ", "shape": "dot", "title": "Node: Wenjie Ou \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Juyi Qiao ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Juyi Qiao ", "shape": "dot", "title": "Node: Juyi Qiao \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Junming Jiao ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Junming Jiao ", "shape": "dot", "title": "Node: Junming Jiao \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Guowen Song ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Guowen Song ", "shape": "dot", "title": "Node: Guowen Song \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Ting Tian ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Ting Tian ", "shape": "dot", "title": "Node: Ting Tian \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Yi Lin ({\u0027paper_id\u0027: \u00272406.07348\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002766d2c161-319e-4dfd-8f8a-b37a48ed2389\u0027})", "label": "Yi Lin ", "shape": "dot", "title": "Node: Yi Lin \nPaper ID: 2406.07348\nCommunity:-1"}, {"color": "##28282B", "id": "Scott Barnett ({\u0027paper_id\u0027: \u00272406.11201\u0027, \u0027relationship_description\u0027: \u0027Large Language Models are integrated with Retrieval-Augmented Generation (RAG) pipelines to improve accuracy and relevance.\u0027, \u0027triplet_source_id\u0027: \u0027457a81de-42a9-49bb-9b9f-fed726ca9cad\u0027})", "label": "Scott Barnett ", "shape": "dot", "title": "Node: Scott Barnett \nPaper ID: 2406.11201\nCommunity:-1"}, {"color": "##28282B", "id": "Zac Brannelly ({\u0027paper_id\u0027: \u00272406.11201\u0027, \u0027relationship_description\u0027: \u0027Large Language Models are integrated with Retrieval-Augmented Generation (RAG) pipelines to improve accuracy and relevance.\u0027, \u0027triplet_source_id\u0027: \u0027457a81de-42a9-49bb-9b9f-fed726ca9cad\u0027})", "label": "Zac Brannelly ", "shape": "dot", "title": "Node: Zac Brannelly \nPaper ID: 2406.11201\nCommunity:-1"}, {"color": "##28282B", "id": "Stefanus Kurniawan ({\u0027paper_id\u0027: \u00272406.11201\u0027, \u0027relationship_description\u0027: \u0027Scott Barnett and Zac Brannelly are co-authors of the study.\u0027, \u0027triplet_source_id\u0027: \u0027457a81de-42a9-49bb-9b9f-fed726ca9cad\u0027})", "label": "Stefanus Kurniawan ", "shape": "dot", "title": "Node: Stefanus Kurniawan \nPaper ID: 2406.11201\nCommunity:-1"}, {"color": "##28282B", "id": "Sheng Wong ({\u0027paper_id\u0027: \u00272406.11201\u0027, \u0027relationship_description\u0027: \u0027Scott Barnett and Zac Brannelly are co-authors of the study.\u0027, \u0027triplet_source_id\u0027: \u0027457a81de-42a9-49bb-9b9f-fed726ca9cad\u0027})", "label": "Sheng Wong ", "shape": "dot", "title": "Node: Sheng Wong \nPaper ID: 2406.11201\nCommunity:-1"}, {"color": "##28282B", "id": "Gautam B ({\u0027paper_id\u0027: \u00272406.11424\u0027, \u0027triplet_source_id\u0027: \u0027d5392568-8912-4c0c-9b01-646fc65f549d\u0027})", "label": "Gautam B ", "shape": "dot", "title": "Node: Gautam B \nPaper ID: 2406.11424\nCommunity:-1"}, {"color": "##28282B", "id": "Anupam Purwar ({\u0027paper_id\u0027: \u00272407.19794\u0027, \u0027triplet_source_id\u0027: \u0027ea7647ee-0d75-4f6b-a4c7-aa38323b0d75\u0027})", "label": "Anupam Purwar ", "shape": "dot", "title": "Node: Anupam Purwar \nPaper ID: 2407.19794\nCommunity:-1"}, {"color": "##28282B", "id": "Open-Source LLMs ({\u0027paper_id\u0027: \u00272406.11424\u0027, \u0027relationship_description\u0027: \u0027Gautam B and Anupam Purwar are co-authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5392568-8912-4c0c-9b01-646fc65f549d\u0027})", "label": "Open-Source LLMs ", "shape": "dot", "title": "Node: Open-Source LLMs \nPaper ID: 2406.11424\nCommunity:-1"}, {"color": "##28282B", "id": "Enterprise-Specific RAG Systems ({\u0027paper_id\u0027: \u00272406.11424\u0027, \u0027relationship_description\u0027: \u0027Gautam B and Anupam Purwar are co-authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5392568-8912-4c0c-9b01-646fc65f549d\u0027})", "label": "Enterprise-Specific RAG Systems ", "shape": "dot", "title": "Node: Enterprise-Specific RAG Systems \nPaper ID: 2406.11424\nCommunity:-1"}, {"color": "##28282B", "id": "Natural Language Processing ({\u0027paper_id\u0027: \u00272406.11424\u0027, \u0027relationship_description\u0027: \u0027Open-Source LLMs are used in Enterprise-Specific RAG Systems\u0027, \u0027triplet_source_id\u0027: \u0027d5392568-8912-4c0c-9b01-646fc65f549d\u0027})", "label": "Natural Language Processing ", "shape": "dot", "title": "Node: Natural Language Processing \nPaper ID: 2406.11424\nCommunity:-1"}, {"color": "##28282B", "id": "Proprietary Solutions ({\u0027paper_id\u0027: \u00272406.11424\u0027, \u0027entity_description\u0027: \u0027Commercial solutions used in natural language processing tasks\u0027, \u0027triplet_source_id\u0027: \u0027d5392568-8912-4c0c-9b01-646fc65f549d\u0027})", "label": "Proprietary Solutions ", "shape": "dot", "title": "Node: Proprietary Solutions \nPaper ID: 2406.11424\nCommunity:-1"}, {"color": "##28282B", "id": "Antonin Sulc ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Antonin Sulc ", "shape": "dot", "title": "Node: Antonin Sulc \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Alex Bien ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Alex Bien ", "shape": "dot", "title": "Node: Alex Bien \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Annika Eichler ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Annika Eichler ", "shape": "dot", "title": "Node: Annika Eichler \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Daniel Ratner ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Daniel Ratner ", "shape": "dot", "title": "Node: Daniel Ratner \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Florian Rehm ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Florian Rehm ", "shape": "dot", "title": "Node: Florian Rehm \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Gregor Hartmann ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Gregor Hartmann ", "shape": "dot", "title": "Node: Gregor Hartmann \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Hayden Hoschouer ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Hayden Hoschouer ", "shape": "dot", "title": "Node: Hayden Hoschouer \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Henrik Tuennermann ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Henrik Tuennermann ", "shape": "dot", "title": "Node: Henrik Tuennermann \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Jan Kaiser ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Jan Kaiser ", "shape": "dot", "title": "Node: Jan Kaiser \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Jason St. John ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Jason St. John ", "shape": "dot", "title": "Node: Jason St. John \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Jennefer Maldonado ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Jennefer Maldonado ", "shape": "dot", "title": "Node: Jennefer Maldonado \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Kyle Hazelwood ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Kyle Hazelwood ", "shape": "dot", "title": "Node: Kyle Hazelwood \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Raimund Kammering ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Raimund Kammering ", "shape": "dot", "title": "Node: Raimund Kammering \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Thorsten Hellert ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Thorsten Hellert ", "shape": "dot", "title": "Node: Thorsten Hellert \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Tim Wilksen ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Tim Wilksen ", "shape": "dot", "title": "Node: Tim Wilksen \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Verena Kain ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Verena Kain ", "shape": "dot", "title": "Node: Verena Kain \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Wan-Lin Hu ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Wan-Lin Hu ", "shape": "dot", "title": "Node: Wan-Lin Hu \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "DESY ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027Antonin Sulc is one of the authors who developed the RAG model\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "DESY ", "shape": "dot", "title": "Node: DESY \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "BESSY ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027DESY is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "BESSY ", "shape": "dot", "title": "Node: BESSY \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Fermilab ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027BESSY is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Fermilab ", "shape": "dot", "title": "Node: Fermilab \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "BNL ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027Fermilab is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "BNL ", "shape": "dot", "title": "Node: BNL \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "SLAC ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027BNL is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "SLAC ", "shape": "dot", "title": "Node: SLAC \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "LBNL ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027SLAC is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "LBNL ", "shape": "dot", "title": "Node: LBNL \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "CERN ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027LBNL is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "CERN ", "shape": "dot", "title": "Node: CERN \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval Augmented Generation (RAG) model ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Retrieval Augmented Generation (RAG) model ", "shape": "dot", "title": "Node: Retrieval Augmented Generation (RAG) model \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Logbooks ({\u0027paper_id\u0027: \u00272406.12881\u0027, \u0027relationship_description\u0027: \u0027LBNL is one of the particle accelerator facilities associated with logbooks\u0027, \u0027triplet_source_id\u0027: \u002774c587ca-c72e-4f24-8919-7a7958d7f8ae\u0027})", "label": "Logbooks ", "shape": "dot", "title": "Node: Logbooks \nPaper ID: 2406.12881\nCommunity:-1"}, {"color": "##28282B", "id": "Multi-Meta-RAG ({\u0027paper_id\u0027: \u00272406.13213\u0027, \u0027relationship_description\u0027: \u0027Multi-Meta-RAG improves the traditional RAG method by using database filtering with LLM-extracted metadata to select relevant documents.\u0027, \u0027triplet_source_id\u0027: \u0027574dd07e-d0ca-4a6e-bbbc-e5b3c94270a9\u0027})", "label": "Multi-Meta-RAG ", "shape": "dot", "title": "Node: Multi-Meta-RAG \nPaper ID: 2406.13213\nCommunity:-1"}, {"color": "##28282B", "id": "MultiHop-RAG ({\u0027paper_id\u0027: \u00272406.13213\u0027, \u0027relationship_description\u0027: \u0027Multi-Meta-RAG improves the traditional RAG method by using database filtering with LLM-extracted metadata to select relevant documents.\u0027, \u0027triplet_source_id\u0027: \u0027574dd07e-d0ca-4a6e-bbbc-e5b3c94270a9\u0027})", "label": "MultiHop-RAG ", "shape": "dot", "title": "Node: MultiHop-RAG \nPaper ID: 2406.13213\nCommunity:-1"}, {"color": "##28282B", "id": "Mykhailo Poliakov ({\u0027paper_id\u0027: \u00272406.13213\u0027, \u0027relationship_description\u0027: \u0027Multi-Meta-RAG greatly improves the results on the MultiHop-RAG benchmark.\u0027, \u0027triplet_source_id\u0027: \u0027574dd07e-d0ca-4a6e-bbbc-e5b3c94270a9\u0027})", "label": "Mykhailo Poliakov ", "shape": "dot", "title": "Node: Mykhailo Poliakov \nPaper ID: 2406.13213\nCommunity:-1"}, {"color": "##28282B", "id": "Nadiya Shvai ({\u0027paper_id\u0027: \u00272406.13213\u0027, \u0027relationship_description\u0027: \u0027Multi-Meta-RAG greatly improves the results on the MultiHop-RAG benchmark.\u0027, \u0027triplet_source_id\u0027: \u0027574dd07e-d0ca-4a6e-bbbc-e5b3c94270a9\u0027})", "label": "Nadiya Shvai ", "shape": "dot", "title": "Node: Nadiya Shvai \nPaper ID: 2406.13213\nCommunity:-1"}, {"color": "##28282B", "id": "R^2AG ({\u0027paper_id\u0027: \u00272406.13249\u0027, \u0027relationship_description\u0027: \u0027R^2AG augments LLMs with external documents provided by retrievers\u0027, \u0027triplet_source_id\u0027: \u00270d338833-88b9-4b0f-b091-26537272963d\u0027})", "label": "R^2AG ", "shape": "dot", "title": "Node: R^2AG \nPaper ID: 2406.13249\nCommunity:-1"}, {"color": "##28282B", "id": "R$^2$-Former ({\u0027paper_id\u0027: \u00272406.13249\u0027, \u0027entity_description\u0027: \u0027A model used to capture retrieval information in R^2AG\u0027, \u0027triplet_source_id\u0027: \u00270d338833-88b9-4b0f-b091-26537272963d\u0027})", "label": "R$^2$-Former ", "shape": "dot", "title": "Node: R$^2$-Former \nPaper ID: 2406.13249\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-aware prompting strategy ({\u0027paper_id\u0027: \u00272406.13249\u0027, \u0027entity_description\u0027: \"A strategy to integrate retrieval information into LLMs\u0027 generation\", \u0027triplet_source_id\u0027: \u00270d338833-88b9-4b0f-b091-26537272963d\u0027})", "label": "Retrieval-aware prompting strategy ", "shape": "dot", "title": "Node: Retrieval-aware prompting strategy \nPaper ID: 2406.13249\nCommunity:-1"}, {"color": "##28282B", "id": "Fromm ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \u0027Fabrizio Silvestri is the author of the paper discussing RAG systems\u0027, \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Fromm ", "shape": "dot", "title": "Node: Fromm \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Quote ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \u0027Fabrizio Silvestri is the author of the paper discussing RAG systems\u0027, \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Quote ", "shape": "dot", "title": "Node: Quote \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Base models ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \"Fromm is the author of the quote \u0027Seldom is a glance at the statistics enough to understand the meaning of the figures\u0027\", \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Base models ", "shape": "dot", "title": "Node: Base models \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "Instructed LLMs ({\u0027paper_id\u0027: \u00272406.14972\u0027, \u0027relationship_description\u0027: \"Fromm is the author of the quote \u0027Seldom is a glance at the statistics enough to understand the meaning of the figures\u0027\", \u0027triplet_source_id\u0027: \u002757915c2c-d782-4565-8f08-508101409f7c\u0027})", "label": "Instructed LLMs ", "shape": "dot", "title": "Node: Instructed LLMs \nPaper ID: 2406.14972\nCommunity:-1"}, {"color": "##28282B", "id": "FS-RAG ({\u0027paper_id\u0027: \u00272406.16167\u0027, \u0027relationship_description\u0027: \u0027FS-RAG is based on the theory of Frame Semantics\u0027, \u0027triplet_source_id\u0027: \u0027f778213b-f7f0-474f-87e5-fba470cb4774\u0027})", "label": "FS-RAG ", "shape": "dot", "title": "Node: FS-RAG \nPaper ID: 2406.16167\nCommunity:-1"}, {"color": "##28282B", "id": "Harish Tayyar Madabushi ({\u0027paper_id\u0027: \u00272406.16167\u0027, \u0027triplet_source_id\u0027: \u0027f778213b-f7f0-474f-87e5-fba470cb4774\u0027})", "label": "Harish Tayyar Madabushi ", "shape": "dot", "title": "Node: Harish Tayyar Madabushi \nPaper ID: 2406.16167\nCommunity:-1"}, {"color": "##28282B", "id": "Frame Semantics ({\u0027paper_id\u0027: \u00272406.16167\u0027, \u0027relationship_description\u0027: \u0027FS-RAG is an extension to Retrieval Augmented Generation\u0027, \u0027triplet_source_id\u0027: \u0027f778213b-f7f0-474f-87e5-fba470cb4774\u0027})", "label": "Frame Semantics ", "shape": "dot", "title": "Node: Frame Semantics \nPaper ID: 2406.16167\nCommunity:-1"}, {"color": "##28282B", "id": "Ragnar\"ok ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027relationship_description\u0027: \u0027Ragnar\"ok is compared to OpenAI\\\u0027s GPT-4o in the TREC 2024 RAG Track\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "Ragnar\"ok ", "shape": "dot", "title": "Node: Ragnar\"ok \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "TREC 2024 RAG Track ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "TREC 2024 RAG Track ", "shape": "dot", "title": "Node: TREC 2024 RAG Track \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "MS MARCO V2.1 ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027relationship_description\u0027: \u0027Ragnar\"ok is a reusable framework for the TREC 2024 RAG Track\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "MS MARCO V2.1 ", "shape": "dot", "title": "Node: MS MARCO V2.1 \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "OpenAI\u0027s GPT-4o ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027relationship_description\u0027: \u0027Ragnar\"ok uses the MS MARCO V2.1 collection\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "OpenAI\u0027s GPT-4o ", "shape": "dot", "title": "Node: OpenAI\u0027s GPT-4o \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "Cohere\u0027s Command R+ ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027relationship_description\u0027: \u0027Ragnar\"ok is compared to OpenAI\\\u0027s GPT-4o in the TREC 2024 RAG Track\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "Cohere\u0027s Command R+ ", "shape": "dot", "title": "Node: Cohere\u0027s Command R+ \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "Google AI~Overviews ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027entity_description\u0027: \u0027A modern-day search system\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "Google AI~Overviews ", "shape": "dot", "title": "Node: Google AI~Overviews \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "Bing Search ({\u0027paper_id\u0027: \u00272406.16828\u0027, \u0027entity_description\u0027: \u0027A modern-day search system\u0027, \u0027triplet_source_id\u0027: \u002787732fd6-dbc6-40ac-9010-cf193e8d3092\u0027})", "label": "Bing Search ", "shape": "dot", "title": "Node: Bing Search \nPaper ID: 2406.16828\nCommunity:-1"}, {"color": "##28282B", "id": "RICHES ({\u0027paper_id\u0027: \u00272407.00361\u0027, \u0027relationship_description\u0027: \u0027RICHES can work with any Instruction-tuned model, without additional training\u0027, \u0027triplet_source_id\u0027: \u0027bdd79b2e-107f-4a4a-a564-b6d98334b83a\u0027})", "label": "RICHES ", "shape": "dot", "title": "Node: RICHES \nPaper ID: 2407.00361\nCommunity:-1"}, {"color": "##28282B", "id": "Palak Jain ({\u0027paper_id\u0027: \u00272407.00361\u0027, \u0027entity_description\u0027: \u0027Co-author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027bdd79b2e-107f-4a4a-a564-b6d98334b83a\u0027})", "label": "Palak Jain ", "shape": "dot", "title": "Node: Palak Jain \nPaper ID: 2407.00361\nCommunity:-1"}, {"color": "##28282B", "id": "Livio Baldini Soares ({\u0027paper_id\u0027: \u00272407.00361\u0027, \u0027entity_description\u0027: \u0027Co-author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027bdd79b2e-107f-4a4a-a564-b6d98334b83a\u0027})", "label": "Livio Baldini Soares ", "shape": "dot", "title": "Node: Livio Baldini Soares \nPaper ID: 2407.00361\nCommunity:-1"}, {"color": "##28282B", "id": "Tom Kwiatkowski ({\u0027paper_id\u0027: \u00272407.00361\u0027, \u0027entity_description\u0027: \u0027Co-author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027bdd79b2e-107f-4a4a-a564-b6d98334b83a\u0027})", "label": "Tom Kwiatkowski ", "shape": "dot", "title": "Node: Tom Kwiatkowski \nPaper ID: 2407.00361\nCommunity:-1"}, {"color": "##28282B", "id": "ODQA ({\u0027paper_id\u0027: \u00272407.00361\u0027, \u0027relationship_description\u0027: \u0027RICHES can work with any Instruction-tuned model, without additional training\u0027, \u0027triplet_source_id\u0027: \u0027bdd79b2e-107f-4a4a-a564-b6d98334b83a\u0027})", "label": "ODQA ", "shape": "dot", "title": "Node: ODQA \nPaper ID: 2407.00361\nCommunity:-1"}, {"color": "##28282B", "id": "BERGEN ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027relationship_description\u0027: \u0027BERGEN is a library that enhances Large Language Models with external knowledge using Retrieval-Augmented Generation\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "BERGEN ", "shape": "dot", "title": "Node: BERGEN \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "David Rau ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027relationship_description\u0027: \u0027BERGEN is a library that enhances Large Language Models with external knowledge using Retrieval-Augmented Generation\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "David Rau ", "shape": "dot", "title": "Node: David Rau \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Herv\u00e9 D\u0027ejean ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Herv\u00e9 D\u0027ejean ", "shape": "dot", "title": "Node: Herv\u00e9 D\u0027ejean \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Nadezhda Chirkova ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Nadezhda Chirkova ", "shape": "dot", "title": "Node: Nadezhda Chirkova \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Thibault Formal ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Thibault Formal ", "shape": "dot", "title": "Node: Thibault Formal \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Shuai Wang ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Shuai Wang ", "shape": "dot", "title": "Node: Shuai Wang \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Vassilina Nikoulina ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Vassilina Nikoulina ", "shape": "dot", "title": "Node: Vassilina Nikoulina \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "St\u00e9phane Clinchant ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \"Co-author of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "St\u00e9phane Clinchant ", "shape": "dot", "title": "Node: St\u00e9phane Clinchant \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Evaluation datasets ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \u0027Collections of data used to evaluate the performance of Retrieval-Augmented Generation approaches\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Evaluation datasets ", "shape": "dot", "title": "Node: Evaluation datasets \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Collections ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \u0027Groups of data used to evaluate the performance of Retrieval-Augmented Generation approaches\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Collections ", "shape": "dot", "title": "Node: Collections \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Metrics ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \u0027Methods used to evaluate the performance of Retrieval-Augmented Generation approaches\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Metrics ", "shape": "dot", "title": "Node: Metrics \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Rerankers ({\u0027paper_id\u0027: \u00272407.01102\u0027, \u0027entity_description\u0027: \u0027Components of Retrieval-Augmented Generation approaches that rank retrieved information\u0027, \u0027triplet_source_id\u0027: \u0027af2240a9-c0e7-4f71-9fc0-41d41a877c01\u0027})", "label": "Rerankers ", "shape": "dot", "title": "Node: Rerankers \nPaper ID: 2407.01102\nCommunity:-1"}, {"color": "##28282B", "id": "Xiaohua Wang ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Xiaohua Wang ", "shape": "dot", "title": "Node: Xiaohua Wang \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Zhenghua Wang ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Zhenghua Wang ", "shape": "dot", "title": "Node: Zhenghua Wang \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Xuan Gao ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Xuan Gao ", "shape": "dot", "title": "Node: Xuan Gao \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Feiran Zhang ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Feiran Zhang ", "shape": "dot", "title": "Node: Feiran Zhang \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Yixin Wu ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Yixin Wu ", "shape": "dot", "title": "Node: Yixin Wu \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Zhibo Xu ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Zhibo Xu ", "shape": "dot", "title": "Node: Zhibo Xu \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Tianyuan Shi ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Tianyuan Shi ", "shape": "dot", "title": "Node: Tianyuan Shi \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Zhengyuan Wang ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Zhengyuan Wang ", "shape": "dot", "title": "Node: Zhengyuan Wang \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Shizheng Li ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Shizheng Li ", "shape": "dot", "title": "Node: Shizheng Li \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Qi Qian ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Qi Qian ", "shape": "dot", "title": "Node: Qi Qian \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Ruicheng Yin ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Ruicheng Yin ", "shape": "dot", "title": "Node: Ruicheng Yin \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Changze Lv ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Changze Lv ", "shape": "dot", "title": "Node: Changze Lv \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Xiaoqing Zheng ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Xiaoqing Zheng ", "shape": "dot", "title": "Node: Xiaoqing Zheng \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Xuanjing Huang ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Xuanjing Huang ", "shape": "dot", "title": "Node: Xuanjing Huang \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Query-Dependent Retrievals ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation enhances Large Language Models\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Query-Dependent Retrievals ", "shape": "dot", "title": "Node: Query-Dependent Retrievals \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Multimodal Retrieval Techniques ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027relationship_description\u0027: \u0027Query-Dependent Retrievals enhance Large Language Models\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Multimodal Retrieval Techniques ", "shape": "dot", "title": "Node: Multimodal Retrieval Techniques \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Question-Answering Capabilities ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027relationship_description\u0027: \u0027Query-Dependent Retrievals enhance Large Language Models\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Question-Answering Capabilities ", "shape": "dot", "title": "Node: Question-Answering Capabilities \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Visual Inputs ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027relationship_description\u0027: \u0027Multimodal Retrieval Techniques enhance Question-Answering Capabilities\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Visual Inputs ", "shape": "dot", "title": "Node: Visual Inputs \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Multimodal Content ({\u0027paper_id\u0027: \u00272407.01219\u0027, \u0027relationship_description\u0027: \u0027Multimodal Retrieval Techniques enhance Question-Answering Capabilities\u0027, \u0027triplet_source_id\u0027: \u00278e81023f-7bc5-4750-9fed-29c897804728\u0027})", "label": "Multimodal Content ", "shape": "dot", "title": "Node: Multimodal Content \nPaper ID: 2407.01219\nCommunity:-1"}, {"color": "##28282B", "id": "Meta-prompting Optimized Retrieval-augmented Generation ({\u0027paper_id\u0027: \u00272407.03955\u0027, \u0027relationship_description\u0027: \u0027Meta-prompting Optimized Retrieval-augmented Generation refines the retrieved content before including it in the prompt.\u0027, \u0027triplet_source_id\u0027: \u002727d5254a-6f38-4049-bae7-ddc596d6f95a\u0027})", "label": "Meta-prompting Optimized Retrieval-augmented Generation ", "shape": "dot", "title": "Node: Meta-prompting Optimized Retrieval-augmented Generation \nPaper ID: 2407.03955\nCommunity:-1"}, {"color": "##28282B", "id": "StrategyQA dataset ({\u0027paper_id\u0027: \u00272407.03955\u0027, \u0027relationship_description\u0027: \u0027Meta-prompting Optimized Retrieval-augmented Generation refines the retrieved content before including it in the prompt.\u0027, \u0027triplet_source_id\u0027: \u002727d5254a-6f38-4049-bae7-ddc596d6f95a\u0027})", "label": "StrategyQA dataset ", "shape": "dot", "title": "Node: StrategyQA dataset \nPaper ID: 2407.03955\nCommunity:-1"}, {"color": "##28282B", "id": "Jo\u00e3o Rodrigues ({\u0027paper_id\u0027: \u00272407.03955\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002727d5254a-6f38-4049-bae7-ddc596d6f95a\u0027})", "label": "Jo\u00e3o Rodrigues ", "shape": "dot", "title": "Node: Jo\u00e3o Rodrigues \nPaper ID: 2407.03955\nCommunity:-1"}, {"color": "##28282B", "id": "Ant\u00f3nio Branco ({\u0027paper_id\u0027: \u00272407.03955\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002727d5254a-6f38-4049-bae7-ddc596d6f95a\u0027})", "label": "Ant\u00f3nio Branco ", "shape": "dot", "title": "Node: Ant\u00f3nio Branco \nPaper ID: 2407.03955\nCommunity:-1"}, {"color": "##28282B", "id": "Speculative RAG ({\u0027paper_id\u0027: \u00272407.08223\u0027, \u0027relationship_description\u0027: \u0027Speculative RAG uses large language models to generate and verify RAG drafts.\u0027, \u0027triplet_source_id\u0027: \u002710005ebf-3b49-491d-9a47-ead999b80718\u0027})", "label": "Speculative RAG ", "shape": "dot", "title": "Node: Speculative RAG \nPaper ID: 2407.08223\nCommunity:-1"}, {"color": "##28282B", "id": "TrivaQA ({\u0027paper_id\u0027: \u00272407.08223\u0027, \u0027relationship_description\u0027: \u0027Speculative RAG uses large language models to generate and verify RAG drafts.\u0027, \u0027triplet_source_id\u0027: \u002710005ebf-3b49-491d-9a47-ead999b80718\u0027})", "label": "TrivaQA ", "shape": "dot", "title": "Node: TrivaQA \nPaper ID: 2407.08223\nCommunity:-1"}, {"color": "##28282B", "id": "MuSiQue ({\u0027paper_id\u0027: \u00272407.08223\u0027, \u0027entity_description\u0027: \u0027A benchmark used to evaluate the performance of RAG systems.\u0027, \u0027triplet_source_id\u0027: \u002710005ebf-3b49-491d-9a47-ead999b80718\u0027})", "label": "MuSiQue ", "shape": "dot", "title": "Node: MuSiQue \nPaper ID: 2407.08223\nCommunity:-1"}, {"color": "##28282B", "id": "PubHealth ({\u0027paper_id\u0027: \u00272407.08223\u0027, \u0027entity_description\u0027: \u0027A benchmark used to evaluate the performance of RAG systems.\u0027, \u0027triplet_source_id\u0027: \u002710005ebf-3b49-491d-9a47-ead999b80718\u0027})", "label": "PubHealth ", "shape": "dot", "title": "Node: PubHealth \nPaper ID: 2407.08223\nCommunity:-1"}, {"color": "##28282B", "id": "ARC-Challenge ({\u0027paper_id\u0027: \u00272407.08223\u0027, \u0027entity_description\u0027: \u0027A benchmark used to evaluate the performance of RAG systems.\u0027, \u0027triplet_source_id\u0027: \u002710005ebf-3b49-491d-9a47-ead999b80718\u0027})", "label": "ARC-Challenge ", "shape": "dot", "title": "Node: ARC-Challenge \nPaper ID: 2407.08223\nCommunity:-1"}, {"color": "##28282B", "id": "RAGBench ({\u0027paper_id\u0027: \u00272407.11005\u0027, \u0027relationship_description\u0027: \u0027RAGBench uses the TRACe framework for evaluation.\u0027, \u0027triplet_source_id\u0027: \u00274288c468-29eb-45a9-bc47-35c886f049fd\u0027})", "label": "RAGBench ", "shape": "dot", "title": "Node: RAGBench \nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "Robert Friel ({\u0027paper_id\u0027: \u00272407.11005\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGBench.\u0027, \u0027triplet_source_id\u0027: \u00274288c468-29eb-45a9-bc47-35c886f049fd\u0027})", "label": "Robert Friel ", "shape": "dot", "title": "Node: Robert Friel \nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "Masha Belyi ({\u0027paper_id\u0027: \u00272407.11005\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGBench.\u0027, \u0027triplet_source_id\u0027: \u00274288c468-29eb-45a9-bc47-35c886f049fd\u0027})", "label": "Masha Belyi ", "shape": "dot", "title": "Node: Masha Belyi \nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "Atindriyo Sanyal ({\u0027paper_id\u0027: \u00272407.11005\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGBench.\u0027, \u0027triplet_source_id\u0027: \u00274288c468-29eb-45a9-bc47-35c886f049fd\u0027})", "label": "Atindriyo Sanyal ", "shape": "dot", "title": "Node: Atindriyo Sanyal \nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "RoBERTa ({\u0027paper_id\u0027: \u00272407.11005\u0027, \u0027relationship_description\u0027: \u0027RAGBench uses the TRACe framework for evaluation.\u0027, \u0027triplet_source_id\u0027: \u00274288c468-29eb-45a9-bc47-35c886f049fd\u0027})", "label": "RoBERTa ", "shape": "dot", "title": "Node: RoBERTa \nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "TRACe ({\u0027paper_id\u0027: \u00272407.11005\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation systems are powered by Large Language Models (LLMs).\u0027, \u0027triplet_source_id\u0027: \u00274288c468-29eb-45a9-bc47-35c886f049fd\u0027})", "label": "TRACe ", "shape": "dot", "title": "Node: TRACe \nPaper ID: 2407.11005\nCommunity:-1"}, {"color": "##28282B", "id": "NinjaLLM ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027relationship_description\u0027: \"NinjaLLM\u0027s performance was benchmarked on the Natural Questions dataset.\", \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "NinjaLLM ", "shape": "dot", "title": "Node: NinjaLLM \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Tengfei Xue ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027relationship_description\u0027: \u0027NinjaLLM is fine-tuned using SageMaker.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Tengfei Xue ", "shape": "dot", "title": "Node: Tengfei Xue \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Xuefeng Li ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper, contributing to the development of NinjaLLM.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Xuefeng Li ", "shape": "dot", "title": "Node: Xuefeng Li \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Roman Smirnov ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper, contributing to the development of NinjaLLM.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Roman Smirnov ", "shape": "dot", "title": "Node: Roman Smirnov \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Tahir Azim ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper, contributing to the development of NinjaLLM.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Tahir Azim ", "shape": "dot", "title": "Node: Tahir Azim \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Arash Sadrieh ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper, contributing to the development of NinjaLLM.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Arash Sadrieh ", "shape": "dot", "title": "Node: Arash Sadrieh \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Babak Pahlavan ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper, contributing to the development of NinjaLLM.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Babak Pahlavan ", "shape": "dot", "title": "Node: Babak Pahlavan \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "AWS Trainium ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "AWS Trainium ", "shape": "dot", "title": "Node: AWS Trainium \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Inferentia2 ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027relationship_description\u0027: \u0027NinjaLLM is hosted on AWS Trainium AI chips.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Inferentia2 ", "shape": "dot", "title": "Node: Inferentia2 \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "SageMaker ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027relationship_description\u0027: \u0027NinjaLLM is hosted on Inferentia2 AI chips.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "SageMaker ", "shape": "dot", "title": "Node: SageMaker \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Natural Questions ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027relationship_description\u0027: \u0027Tengfei Xue contributed to the development of NinjaLLM.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Natural Questions ", "shape": "dot", "title": "Node: Natural Questions \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "HotPotQA ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027relationship_description\u0027: \"NinjaLLM\u0027s performance was benchmarked on the Natural Questions dataset.\", \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "HotPotQA ", "shape": "dot", "title": "Node: HotPotQA \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "DBRX ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027A model used for comparison with the RAG system.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "DBRX ", "shape": "dot", "title": "Node: DBRX \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Mixtral Instruct ({\u0027paper_id\u0027: \u00272407.12057\u0027, \u0027entity_description\u0027: \u0027A model used for comparison with the RAG system.\u0027, \u0027triplet_source_id\u0027: \u002779eeda11-562f-4664-bddf-02f37d26941a\u0027})", "label": "Mixtral Instruct ", "shape": "dot", "title": "Node: Mixtral Instruct \nPaper ID: 2407.12057\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Generation for Natural Language Processing: A Survey ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027relationship_description\u0027: \u0027The paper reviews the techniques of RAG and its applications\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Retrieval-Augmented Generation for Natural Language Processing: A Survey ", "shape": "dot", "title": "Node: Retrieval-Augmented Generation for Natural Language Processing: A Survey \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Shangyu Wu ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Shangyu Wu ", "shape": "dot", "title": "Node: Shangyu Wu \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Ying Xiong ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Ying Xiong ", "shape": "dot", "title": "Node: Ying Xiong \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Yufei Cui ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Yufei Cui ", "shape": "dot", "title": "Node: Yufei Cui \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Haolun Wu ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Haolun Wu ", "shape": "dot", "title": "Node: Haolun Wu \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Can Chen ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Can Chen ", "shape": "dot", "title": "Node: Can Chen \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Ye Yuan ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Ye Yuan ", "shape": "dot", "title": "Node: Ye Yuan \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Lianming Huang ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Lianming Huang ", "shape": "dot", "title": "Node: Lianming Huang \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Xue Liu ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Xue Liu ", "shape": "dot", "title": "Node: Xue Liu \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Tei-Wei Kuo ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Tei-Wei Kuo ", "shape": "dot", "title": "Node: Tei-Wei Kuo \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Nan Guan ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Nan Guan ", "shape": "dot", "title": "Node: Nan Guan \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Chun Jason Xue ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Chun Jason Xue ", "shape": "dot", "title": "Node: Chun Jason Xue \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-augmented generation (RAG) ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027relationship_description\u0027: \u0027StructRAG is a framework that enhances LLMs in knowledge-intensive reasoning tasks\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Retrieval-augmented generation (RAG) ", "shape": "dot", "title": "Node: Retrieval-augmented generation (RAG) \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge database ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027A database that stores knowledge\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Knowledge database ", "shape": "dot", "title": "Node: Knowledge database \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Natural language processing ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027entity_description\u0027: \u0027A field of study that focuses on the interaction between computers and human language\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Natural language processing ", "shape": "dot", "title": "Node: Natural language processing \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue ({\u0027paper_id\u0027: \u00272407.13193\u0027, \u0027relationship_description\u0027: \u0027The paper reviews the techniques of RAG and its applications\u0027, \u0027triplet_source_id\u0027: \u00271a5445c6-650c-4b08-8abb-4e32bc2a11b0\u0027})", "label": "Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue ", "shape": "dot", "title": "Node: Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue \nPaper ID: 2407.13193\nCommunity:-1"}, {"color": "##28282B", "id": "Document-Grounded Question-Answering ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Document-Grounded Question-Answering ", "shape": "dot", "title": "Node: Document-Grounded Question-Answering \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Electronic Design Automation ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027relationship_description\u0027: \u0027Retrieval augmented generation enhances the accuracy and reliability of generative AI models for document-grounded question-answering tasks.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Electronic Design Automation ", "shape": "dot", "title": "Node: Electronic Design Automation \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "OpenROAD ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027relationship_description\u0027: \u0027Retrieval augmented generation is applied to knowledge-intensive vertical domains, such as electronic design automation.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "OpenROAD ", "shape": "dot", "title": "Node: OpenROAD \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "ORD-QA ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027relationship_description\u0027: \u0027Retrieval augmented generation is applied to knowledge-intensive vertical domains, such as electronic design automation.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "ORD-QA ", "shape": "dot", "title": "Node: ORD-QA \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Tairu Qiu ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Tairu Qiu ", "shape": "dot", "title": "Node: Tairu Qiu \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Yuan Pu ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Yuan Pu ", "shape": "dot", "title": "Node: Yuan Pu \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Zhuolun He ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Zhuolun He ", "shape": "dot", "title": "Node: Zhuolun He \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Haoyuan Wu ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Haoyuan Wu ", "shape": "dot", "title": "Node: Haoyuan Wu \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Bei Yu ({\u0027paper_id\u0027: \u00272407.15353\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u002723359d27-654b-40d0-b99a-2acfe088a295\u0027})", "label": "Bei Yu ", "shape": "dot", "title": "Node: Bei Yu \nPaper ID: 2407.15353\nCommunity:-1"}, {"color": "##28282B", "id": "Gemini-1.5 ({\u0027paper_id\u0027: \u00272407.16833\u0027, \u0027relationship_description\u0027: \u0027RAG is a tool used by LLMs to efficiently process overly lengthy contexts.\u0027, \u0027triplet_source_id\u0027: \u0027b288777c-864d-4f14-ae8e-9236f1771fa1\u0027})", "label": "Gemini-1.5 ", "shape": "dot", "title": "Node: Gemini-1.5 \nPaper ID: 2407.16833\nCommunity:-1"}, {"color": "##28282B", "id": "GPT-4 ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027relationship_description\u0027: \u0027The Bailicai framework implements the Retrieval-Augmented Generation approach\u0027, \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "GPT-4 ", "shape": "dot", "title": "Node: GPT-4 \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "Self-Route ({\u0027paper_id\u0027: \u00272407.16833\u0027, \u0027relationship_description\u0027: \u0027Self-Route routes queries to RAG based on model self-reflection.\u0027, \u0027triplet_source_id\u0027: \u0027b288777c-864d-4f14-ae8e-9236f1771fa1\u0027})", "label": "Self-Route ", "shape": "dot", "title": "Node: Self-Route \nPaper ID: 2407.16833\nCommunity:-1"}, {"color": "##28282B", "id": "Public datasets ({\u0027paper_id\u0027: \u00272407.16833\u0027, \u0027entity_description\u0027: \u0027Various datasets used to benchmark RAG and LC across three latest LLMs.\u0027, \u0027triplet_source_id\u0027: \u0027b288777c-864d-4f14-ae8e-9236f1771fa1\u0027})", "label": "Public datasets ", "shape": "dot", "title": "Node: Public datasets \nPaper ID: 2407.16833\nCommunity:-1"}, {"color": "##28282B", "id": "Kush Juvekar ({\u0027paper_id\u0027: \u00272407.19794\u0027, \u0027triplet_source_id\u0027: \u0027ea7647ee-0d75-4f6b-a4c7-aa38323b0d75\u0027})", "label": "Kush Juvekar ", "shape": "dot", "title": "Node: Kush Juvekar \nPaper ID: 2407.19794\nCommunity:-1"}, {"color": "##28282B", "id": "Context Window Utilization ({\u0027paper_id\u0027: \u00272407.19794\u0027, \u0027relationship_description\u0027: \u0027Kush Juvekar and Anupam Purwar are authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027ea7647ee-0d75-4f6b-a4c7-aa38323b0d75\u0027})", "label": "Context Window Utilization ", "shape": "dot", "title": "Node: Context Window Utilization \nPaper ID: 2407.19794\nCommunity:-1"}, {"color": "##28282B", "id": "RAG systems ({\u0027paper_id\u0027: \u00272407.19794\u0027, \u0027relationship_description\u0027: \u0027RAG systems use Context Window Utilization as a hyper-parameter\u0027, \u0027triplet_source_id\u0027: \u0027ea7647ee-0d75-4f6b-a4c7-aa38323b0d75\u0027})", "label": "RAG systems ", "shape": "dot", "title": "Node: RAG systems \nPaper ID: 2407.19794\nCommunity:-1"}, {"color": "##28282B", "id": "External knowledge bases ({\u0027paper_id\u0027: \u00272407.19794\u0027, \u0027relationship_description\u0027: \u0027RAG systems use Context Window Utilization as a hyper-parameter\u0027, \u0027triplet_source_id\u0027: \u0027ea7647ee-0d75-4f6b-a4c7-aa38323b0d75\u0027})", "label": "External knowledge bases ", "shape": "dot", "title": "Node: External knowledge bases \nPaper ID: 2407.19794\nCommunity:-1"}, {"color": "##28282B", "id": "Bailicai ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027relationship_description\u0027: \u0027The Bailicai framework augments the performance of LLMs in medicine\u0027, \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "Bailicai ", "shape": "dot", "title": "Node: Bailicai \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "Cui Long ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications\u0027\", \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "Cui Long ", "shape": "dot", "title": "Node: Cui Long \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "Yongbin Liu ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications\u0027\", \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "Yongbin Liu ", "shape": "dot", "title": "Node: Yongbin Liu \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "Chunping Ouyang ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications\u0027\", \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "Chunping Ouyang ", "shape": "dot", "title": "Node: Chunping Ouyang \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "Ying Yu ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications\u0027\", \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "Ying Yu ", "shape": "dot", "title": "Node: Ying Yu \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "GPT-3.5 ({\u0027paper_id\u0027: \u00272407.21055\u0027, \u0027relationship_description\u0027: \u0027Large Language Models (LLMs) are compared to GPT-4 in terms of performance in the medical domain\u0027, \u0027triplet_source_id\u0027: \u002718700bd5-44d6-4540-9ecb-e2465fd0aa67\u0027})", "label": "GPT-3.5 ", "shape": "dot", "title": "Node: GPT-3.5 \nPaper ID: 2407.21055\nCommunity:-1"}, {"color": "##28282B", "id": "RAGEval ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027relationship_description\u0027: \u0027RAGEval uses LLMs to generate high-quality documents, questions, answers, and references.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "RAGEval ", "shape": "dot", "title": "Node: RAGEval \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Kunlun Zhu ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027relationship_description\u0027: \u0027RAGEval uses LLMs to generate high-quality documents, questions, answers, and references.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Kunlun Zhu ", "shape": "dot", "title": "Node: Kunlun Zhu \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Yifan Luo ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Yifan Luo ", "shape": "dot", "title": "Node: Yifan Luo \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Dingling Xu ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Dingling Xu ", "shape": "dot", "title": "Node: Dingling Xu \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Ruobing Wang ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Ruobing Wang ", "shape": "dot", "title": "Node: Ruobing Wang \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Shi Yu ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Shi Yu ", "shape": "dot", "title": "Node: Shi Yu \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Shuo Wang ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Shuo Wang ", "shape": "dot", "title": "Node: Shuo Wang \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Yukun Yan ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Yukun Yan ", "shape": "dot", "title": "Node: Yukun Yan \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Zhenghao Liu ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Zhenghao Liu ", "shape": "dot", "title": "Node: Zhenghao Liu \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Xu Han ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Xu Han ", "shape": "dot", "title": "Node: Xu Han \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Zhiyuan Liu ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Zhiyuan Liu ", "shape": "dot", "title": "Node: Zhiyuan Liu \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "Maosong Sun ({\u0027paper_id\u0027: \u00272408.01262\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper introducing RAGEval.\u0027, \u0027triplet_source_id\u0027: \u002712034803-ff63-4fd3-bc17-155d08ca7475\u0027})", "label": "Maosong Sun ", "shape": "dot", "title": "Node: Maosong Sun \nPaper ID: 2408.01262\nCommunity:-1"}, {"color": "##28282B", "id": "RAG Foundry ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \u0027IntelLabs developed the RAG Foundry framework.\u0027, \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "RAG Foundry ", "shape": "dot", "title": "Node: RAG Foundry \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "Daniel Fleischer ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "Daniel Fleischer ", "shape": "dot", "title": "Node: Daniel Fleischer \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "Moshe Berchansky ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \"Daniel Fleischer is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "Moshe Berchansky ", "shape": "dot", "title": "Node: Moshe Berchansky \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "Moshe Wasserblat ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \"Moshe Berchansky is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "Moshe Wasserblat ", "shape": "dot", "title": "Node: Moshe Wasserblat \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "Peter Izsak ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \"Moshe Wasserblat is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "Peter Izsak ", "shape": "dot", "title": "Node: Peter Izsak \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "Llama-3 ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \"Peter Izsak is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "Llama-3 ", "shape": "dot", "title": "Node: Llama-3 \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "Phi-3 ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \u0027RAG Foundry uses Llama-3 as a large language model.\u0027, \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "Phi-3 ", "shape": "dot", "title": "Node: Phi-3 \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "IntelLabs ({\u0027paper_id\u0027: \u00272408.02545\u0027, \u0027relationship_description\u0027: \u0027RAG Foundry uses Phi-3 as a large language model.\u0027, \u0027triplet_source_id\u0027: \u002794c83921-5f32-4810-9ae8-bbe0daf9d455\u0027})", "label": "IntelLabs ", "shape": "dot", "title": "Node: IntelLabs \nPaper ID: 2408.02545\nCommunity:-1"}, {"color": "##28282B", "id": "EfficientRAG ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027relationship_description\u0027: \u0027EfficientRAG uses large language models to generate new queries.\u0027, \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "EfficientRAG ", "shape": "dot", "title": "Node: EfficientRAG \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Ziyuan Zhuang ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Ziyuan Zhuang ", "shape": "dot", "title": "Node: Ziyuan Zhuang \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Zhiyang Zhang ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Zhiyang Zhang ", "shape": "dot", "title": "Node: Zhiyang Zhang \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Sitao Cheng ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Sitao Cheng ", "shape": "dot", "title": "Node: Sitao Cheng \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Fangkai Yang ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Fangkai Yang ", "shape": "dot", "title": "Node: Fangkai Yang \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Jia Liu ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Jia Liu ", "shape": "dot", "title": "Node: Jia Liu \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Shujian Huang ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Shujian Huang ", "shape": "dot", "title": "Node: Shujian Huang \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Qingwei Lin ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Qingwei Lin ", "shape": "dot", "title": "Node: Qingwei Lin \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Saravan Rajmohan ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Saravan Rajmohan ", "shape": "dot", "title": "Node: Saravan Rajmohan \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Dongmei Zhang ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Dongmei Zhang ", "shape": "dot", "title": "Node: Dongmei Zhang \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Qi Zhang ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027EfficientRAG: Efficient Retriever for Multi-Hop Question Answering\u0027.\", \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Qi Zhang ", "shape": "dot", "title": "Node: Qi Zhang \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Multi-hop question-answering datasets ({\u0027paper_id\u0027: \u00272408.04259\u0027, \u0027relationship_description\u0027: \u0027EfficientRAG uses large language models to generate new queries.\u0027, \u0027triplet_source_id\u0027: \u00277cc6dbee-164c-427b-bd5f-ec5fa29e7558\u0027})", "label": "Multi-hop question-answering datasets ", "shape": "dot", "title": "Node: Multi-hop question-answering datasets \nPaper ID: 2408.04259\nCommunity:-1"}, {"color": "##28282B", "id": "Hybrid RAG System ({\u0027paper_id\u0027: \u00272408.05141\u0027, \u0027relationship_description\u0027: \u0027The Hybrid RAG System was evaluated on the CRAG Dataset.\u0027, \u0027triplet_source_id\u0027: \u002710509c89-f230-4bcb-8643-70f70bcf53ff\u0027})", "label": "Hybrid RAG System ", "shape": "dot", "title": "Node: Hybrid RAG System \nPaper ID: 2408.05141\nCommunity:-1"}, {"color": "##28282B", "id": "CRAG Dataset ({\u0027paper_id\u0027: \u00272408.05141\u0027, \u0027relationship_description\u0027: \u0027The Hybrid RAG System enhances the accuracy and reduces hallucinations of Large Language Models.\u0027, \u0027triplet_source_id\u0027: \u002710509c89-f230-4bcb-8643-70f70bcf53ff\u0027})", "label": "CRAG Dataset ", "shape": "dot", "title": "Node: CRAG Dataset \nPaper ID: 2408.05141\nCommunity:-1"}, {"color": "##28282B", "id": "Meta CRAG KDD Cup 2024 Competition ({\u0027paper_id\u0027: \u00272408.05141\u0027, \u0027entity_description\u0027: \u0027A competition where the proposed system was evaluated.\u0027, \u0027triplet_source_id\u0027: \u002710509c89-f230-4bcb-8643-70f70bcf53ff\u0027})", "label": "Meta CRAG KDD Cup 2024 Competition ", "shape": "dot", "title": "Node: Meta CRAG KDD Cup 2024 Competition \nPaper ID: 2408.05141\nCommunity:-1"}, {"color": "##28282B", "id": "Shizueyy ({\u0027paper_id\u0027: \u00272408.05141\u0027, \u0027relationship_description\u0027: \u0027The Hybrid RAG System was evaluated on the CRAG Dataset.\u0027, \u0027triplet_source_id\u0027: \u002710509c89-f230-4bcb-8643-70f70bcf53ff\u0027})", "label": "Shizueyy ", "shape": "dot", "title": "Node: Shizueyy \nPaper ID: 2408.05141\nCommunity:-1"}, {"color": "##28282B", "id": "Samhaa R. El-Beltagy ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "Samhaa R. El-Beltagy ", "shape": "dot", "title": "Node: Samhaa R. El-Beltagy \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "Mohamed A. Abdallah ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "Mohamed A. Abdallah ", "shape": "dot", "title": "Node: Mohamed A. Abdallah \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "Arabic ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027relationship_description\u0027: \u0027They co-authored the paper\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "Arabic ", "shape": "dot", "title": "Node: Arabic \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "Semantic embedding models ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027relationship_description\u0027: \u0027RAG is applied to Arabic language\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "Semantic embedding models ", "shape": "dot", "title": "Node: Semantic embedding models \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "LLMs (Large Language Models) ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027relationship_description\u0027: \u0027Semantic embedding models are used in the retrieval stage of RAG\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "LLMs (Large Language Models) ", "shape": "dot", "title": "Node: LLMs (Large Language Models) \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "Document dialect ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027entity_description\u0027: \u0027Variation in document language\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "Document dialect ", "shape": "dot", "title": "Node: Document dialect \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "Query dialect ({\u0027paper_id\u0027: \u00272408.07425\u0027, \u0027entity_description\u0027: \u0027Variation in query language\u0027, \u0027triplet_source_id\u0027: \u002704c78a31-7442-43cd-81d1-a791e696f6f0\u0027})", "label": "Query dialect ", "shape": "dot", "title": "Node: Query dialect \nPaper ID: 2408.07425\nCommunity:-1"}, {"color": "##28282B", "id": "RAGChecker ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027relationship_description\u0027: \u0027RAGChecker was developed by Dongyu Ru and other authors\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "RAGChecker ", "shape": "dot", "title": "Node: RAGChecker \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Dongyu Ru ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027relationship_description\u0027: \u0027RAGChecker evaluates the performance of RAG systems\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Dongyu Ru ", "shape": "dot", "title": "Node: Dongyu Ru \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Lin Qiu ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Lin Qiu ", "shape": "dot", "title": "Node: Lin Qiu \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Xiangkun Hu ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Xiangkun Hu ", "shape": "dot", "title": "Node: Xiangkun Hu \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Tianhang Zhang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Tianhang Zhang ", "shape": "dot", "title": "Node: Tianhang Zhang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Peng Shi ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Peng Shi ", "shape": "dot", "title": "Node: Peng Shi \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Shuaichen Chang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Shuaichen Chang ", "shape": "dot", "title": "Node: Shuaichen Chang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Cheng Jiayang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Cheng Jiayang ", "shape": "dot", "title": "Node: Cheng Jiayang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Cunxiang Wang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Cunxiang Wang ", "shape": "dot", "title": "Node: Cunxiang Wang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Shichao Sun ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Shichao Sun ", "shape": "dot", "title": "Node: Shichao Sun \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Huanyu Li ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Huanyu Li ", "shape": "dot", "title": "Node: Huanyu Li \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Zizhao Zhang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Zizhao Zhang ", "shape": "dot", "title": "Node: Zizhao Zhang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Binjie Wang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Binjie Wang ", "shape": "dot", "title": "Node: Binjie Wang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Jiarong Jiang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Jiarong Jiang ", "shape": "dot", "title": "Node: Jiarong Jiang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Tong He ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Tong He ", "shape": "dot", "title": "Node: Tong He \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Zhiguo Wang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Zhiguo Wang ", "shape": "dot", "title": "Node: Zhiguo Wang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Pengfei Liu ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Pengfei Liu ", "shape": "dot", "title": "Node: Pengfei Liu \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Yue Zhang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Yue Zhang ", "shape": "dot", "title": "Node: Yue Zhang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Zheng Zhang ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Zheng Zhang ", "shape": "dot", "title": "Node: Zheng Zhang \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Amazon Science ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027relationship_description\u0027: \u0027RAGChecker was developed by Dongyu Ru and other authors\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "Amazon Science ", "shape": "dot", "title": "Node: Amazon Science \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "https://github.com/amazon-science/RAGChecker ({\u0027paper_id\u0027: \u00272408.08067\u0027, \u0027entity_description\u0027: \u0027The GitHub repository for the RAGChecker framework\u0027, \u0027triplet_source_id\u0027: \u0027775e3b7a-02cb-434f-94a7-4256b57da23d\u0027})", "label": "https://github.com/amazon-science/RAGChecker ", "shape": "dot", "title": "Node: https://github.com/amazon-science/RAGChecker \nPaper ID: 2408.08067\nCommunity:-1"}, {"color": "##28282B", "id": "Graph Retrieval-Augmented Generation ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Graph Retrieval-Augmented Generation ", "shape": "dot", "title": "Node: Graph Retrieval-Augmented Generation \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "GraphRAG ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027relationship_description\u0027: \u0027GraphRAG extends Retrieval-Augmented Generation by leveraging structural information across entities\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "GraphRAG ", "shape": "dot", "title": "Node: GraphRAG \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Boci Peng ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027relationship_description\u0027: \u0027GraphRAG extends Retrieval-Augmented Generation by leveraging structural information across entities\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Boci Peng ", "shape": "dot", "title": "Node: Boci Peng \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Yongchao Liu ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Yongchao Liu ", "shape": "dot", "title": "Node: Yongchao Liu \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Xiaohe Bo ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Xiaohe Bo ", "shape": "dot", "title": "Node: Xiaohe Bo \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Haizhou Shi ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Haizhou Shi ", "shape": "dot", "title": "Node: Haizhou Shi \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Chuntao Hong ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Chuntao Hong ", "shape": "dot", "title": "Node: Chuntao Hong \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Yan Zhang ({\u0027paper_id\u0027: \u00272408.08921\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of GraphRAG\u0027, \u0027triplet_source_id\u0027: \u00276c720003-0e59-4213-8a98-9844722331b7\u0027})", "label": "Yan Zhang ", "shape": "dot", "title": "Node: Yan Zhang \nPaper ID: 2408.08921\nCommunity:-1"}, {"color": "##28282B", "id": "Pandora\u0027s Box ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027relationship_description\u0027: \u0027RAG noise can be used to augment the capabilities of large language models\u0027, \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Pandora\u0027s Box ", "shape": "dot", "title": "Node: Pandora\u0027s Box \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Aladdin\u0027s Lamp ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027relationship_description\u0027: \"Jinyang Wu compares the concept of Pandora\u0027s Box to the concept of RAG noise\", \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Aladdin\u0027s Lamp ", "shape": "dot", "title": "Node: Aladdin\u0027s Lamp \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "RAG Noise ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027relationship_description\u0027: \"Jinyang Wu compares the concept of Aladdin\u0027s Lamp to the concept of RAG noise\", \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "RAG Noise ", "shape": "dot", "title": "Node: RAG Noise \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Jinyang Wu ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027relationship_description\u0027: \"Jinyang Wu compares the concept of Pandora\u0027s Box to the concept of RAG noise\", \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Jinyang Wu ", "shape": "dot", "title": "Node: Jinyang Wu \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Feihu Che ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Feihu Che ", "shape": "dot", "title": "Node: Feihu Che \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Chuyuan Zhang ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Chuyuan Zhang ", "shape": "dot", "title": "Node: Chuyuan Zhang \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Jianhua Tao ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Jianhua Tao ", "shape": "dot", "title": "Node: Jianhua Tao \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Pengpeng Shao ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027entity_description\u0027: \u0027A researcher and author of the paper\u0027, \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Pengpeng Shao ", "shape": "dot", "title": "Node: Pengpeng Shao \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "Noise RAG Benchmark (NoiserBench) ({\u0027paper_id\u0027: \u00272408.13533\u0027, \u0027relationship_description\u0027: \"Jinyang Wu compares the concept of Aladdin\u0027s Lamp to the concept of RAG noise\", \u0027triplet_source_id\u0027: \u00274fb5f797-db1f-4ae7-aa4c-5ba453b9e003\u0027})", "label": "Noise RAG Benchmark (NoiserBench) ", "shape": "dot", "title": "Node: Noise RAG Benchmark (NoiserBench) \nPaper ID: 2408.13533\nCommunity:-1"}, {"color": "##28282B", "id": "OP-RAG ({\u0027paper_id\u0027: \u00272409.01666\u0027, \u0027relationship_description\u0027: \u0027RAG has been compared to LLMs in terms of performance in long-context applications\u0027, \u0027triplet_source_id\u0027: \u00274866e251-6d13-4090-b7f3-3bcda5a7bca3\u0027})", "label": "OP-RAG ", "shape": "dot", "title": "Node: OP-RAG \nPaper ID: 2409.01666\nCommunity:-1"}, {"color": "##28282B", "id": "Tan Yu ({\u0027paper_id\u0027: \u00272409.01666\u0027, \u0027relationship_description\u0027: \"Tan Yu and Anbang Xu are co-authors of the paper \u0027In Defense of RAG in the Era of Long-Context Language Models\u0027\", \u0027triplet_source_id\u0027: \u00274866e251-6d13-4090-b7f3-3bcda5a7bca3\u0027})", "label": "Tan Yu ", "shape": "dot", "title": "Node: Tan Yu \nPaper ID: 2409.01666\nCommunity:-1"}, {"color": "##28282B", "id": "Anbang Xu ({\u0027paper_id\u0027: \u00272409.01666\u0027, \u0027relationship_description\u0027: \u0027OP-RAG has improved the performance of RAG for long-context question-answer applications\u0027, \u0027triplet_source_id\u0027: \u00274866e251-6d13-4090-b7f3-3bcda5a7bca3\u0027})", "label": "Anbang Xu ", "shape": "dot", "title": "Node: Anbang Xu \nPaper ID: 2409.01666\nCommunity:-1"}, {"color": "##28282B", "id": "Rama Akkiraju ({\u0027paper_id\u0027: \u00272409.01666\u0027, \u0027relationship_description\u0027: \"Tan Yu and Anbang Xu are co-authors of the paper \u0027In Defense of RAG in the Era of Long-Context Language Models\u0027\", \u0027triplet_source_id\u0027: \u00274866e251-6d13-4090-b7f3-3bcda5a7bca3\u0027})", "label": "Rama Akkiraju ", "shape": "dot", "title": "Node: Rama Akkiraju \nPaper ID: 2409.01666\nCommunity:-1"}, {"color": "##28282B", "id": "MARAGS ({\u0027paper_id\u0027: \u00272409.03171\u0027, \u0027relationship_description\u0027: \u0027MARAGS uses an LLM to produce generations.\u0027, \u0027triplet_source_id\u0027: \u002745c76d63-1b08-47e7-afad-f798e732becf\u0027})", "label": "MARAGS ", "shape": "dot", "title": "Node: MARAGS \nPaper ID: 2409.03171\nCommunity:-1"}, {"color": "##28282B", "id": "Meta\u0027s Comprehensive RAG (CRAG) ({\u0027paper_id\u0027: \u00272409.03171\u0027, \u0027triplet_source_id\u0027: \u002745c76d63-1b08-47e7-afad-f798e732becf\u0027})", "label": "Meta\u0027s Comprehensive RAG (CRAG) ", "shape": "dot", "title": "Node: Meta\u0027s Comprehensive RAG (CRAG) \nPaper ID: 2409.03171\nCommunity:-1"}, {"color": "##28282B", "id": "KDD CUP 2024 ({\u0027paper_id\u0027: \u00272409.03171\u0027, \u0027relationship_description\u0027: \"MARAGS is a system designed for Meta\u0027s Comprehensive RAG (CRAG) competition.\", \u0027triplet_source_id\u0027: \u002745c76d63-1b08-47e7-afad-f798e732becf\u0027})", "label": "KDD CUP 2024 ", "shape": "dot", "title": "Node: KDD CUP 2024 \nPaper ID: 2409.03171\nCommunity:-1"}, {"color": "##28282B", "id": "API endpoints ({\u0027paper_id\u0027: \u00272409.03171\u0027, \u0027relationship_description\u0027: \u0027MARAGS uses an LLM to produce generations.\u0027, \u0027triplet_source_id\u0027: \u002745c76d63-1b08-47e7-afad-f798e732becf\u0027})", "label": "API endpoints ", "shape": "dot", "title": "Node: API endpoints \nPaper ID: 2409.03171\nCommunity:-1"}, {"color": "##28282B", "id": "OneGen ({\u0027paper_id\u0027: \u00272409.05152\u0027, \u0027relationship_description\u0027: \u0027OneGen enables LLMs to handle RAG tasks that require both generation and retrieval.\u0027, \u0027triplet_source_id\u0027: \u00279df29a90-fa23-48b3-b7cf-67812ac4da49\u0027})", "label": "OneGen ", "shape": "dot", "title": "Node: OneGen \nPaper ID: 2409.05152\nCommunity:-1"}, {"color": "##28282B", "id": "Entity Linking ({\u0027paper_id\u0027: \u00272409.05152\u0027, \u0027relationship_description\u0027: \u0027OneGen enables LLMs to handle RAG tasks that require both generation and retrieval.\u0027, \u0027triplet_source_id\u0027: \u00279df29a90-fa23-48b3-b7cf-67812ac4da49\u0027})", "label": "Entity Linking ", "shape": "dot", "title": "Node: Entity Linking \nPaper ID: 2409.05152\nCommunity:-1"}, {"color": "##28282B", "id": "MemoRAG ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027Kelong Mao is one of the authors of MemoRAG\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "MemoRAG ", "shape": "dot", "title": "Node: MemoRAG \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "Hongjin Qian ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027MemoRAG uses long-term memory to store information\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "Hongjin Qian ", "shape": "dot", "title": "Node: Hongjin Qian \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "Peitian Zhang ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027Hongjin Qian is one of the authors of MemoRAG\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "Peitian Zhang ", "shape": "dot", "title": "Node: Peitian Zhang \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "Zheng Liu ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027Peitian Zhang is one of the authors of MemoRAG\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "Zheng Liu ", "shape": "dot", "title": "Node: Zheng Liu \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "Kelong Mao ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027Zheng Liu is one of the authors of MemoRAG\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "Kelong Mao ", "shape": "dot", "title": "Node: Kelong Mao \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "Long-term memory ({\u0027paper_id\u0027: \u00272409.05591\u0027, \u0027relationship_description\u0027: \u0027MemoRAG is a type of Retrieval-Augmented Generation (RAG)\u0027, \u0027triplet_source_id\u0027: \u002767d6de0c-1bf5-4ef1-933a-2007634d2900\u0027})", "label": "Long-term memory ", "shape": "dot", "title": "Node: Long-term memory \nPaper ID: 2409.05591\nCommunity:-1"}, {"color": "##28282B", "id": "SFR-RAG ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG is evaluated on the TriviaQA benchmark\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "SFR-RAG ", "shape": "dot", "title": "Node: SFR-RAG \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Xuan-Phi Nguyen ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Xuan-Phi Nguyen ", "shape": "dot", "title": "Node: Xuan-Phi Nguyen \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Shrey Pandit ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Shrey Pandit ", "shape": "dot", "title": "Node: Shrey Pandit \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Senthil Purushwalkam ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Senthil Purushwalkam ", "shape": "dot", "title": "Node: Senthil Purushwalkam \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Austin Xu ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Austin Xu ", "shape": "dot", "title": "Node: Austin Xu \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Hailin Chen ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Hailin Chen ", "shape": "dot", "title": "Node: Hailin Chen \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Yifei Ming ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Yifei Ming ", "shape": "dot", "title": "Node: Yifei Ming \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Silvio Savarese ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Silvio Savarese ", "shape": "dot", "title": "Node: Silvio Savarese \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Caiming Xong ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Caiming Xong ", "shape": "dot", "title": "Node: Caiming Xong \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Shafiq Joty ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027entity_description\u0027: \"Author of the paper \u0027SFR-RAG: Towards Contextually Faithful LLMs\u0027\", \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Shafiq Joty ", "shape": "dot", "title": "Node: Shafiq Joty \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "HotpotQA ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG uses large language models (LLMs) to enhance factual accuracy and relevance\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "HotpotQA ", "shape": "dot", "title": "Node: HotpotQA \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "TriviaQA ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG is evaluated on the HotpotQA benchmark\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "TriviaQA ", "shape": "dot", "title": "Node: TriviaQA \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "ContextualBench ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG is evaluated on the TriviaQA benchmark\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "ContextualBench ", "shape": "dot", "title": "Node: ContextualBench \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "Command-R+ (104B) ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG is evaluated on the ContextualBench evaluation framework\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "Command-R+ (104B) ", "shape": "dot", "title": "Node: Command-R+ (104B) \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "GPT-4o ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG-9B is compared to the Command-R+ (104B) model\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "GPT-4o ", "shape": "dot", "title": "Node: GPT-4o \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "SFR-RAG-9B ({\u0027paper_id\u0027: \u00272409.09916\u0027, \u0027relationship_description\u0027: \u0027SFR-RAG-9B is compared to the Command-R+ (104B) model\u0027, \u0027triplet_source_id\u0027: \u0027a73366dd-d3d6-4164-bc1e-d22f0e4a4566\u0027})", "label": "SFR-RAG-9B ", "shape": "dot", "title": "Node: SFR-RAG-9B \nPaper ID: 2409.09916\nCommunity:-1"}, {"color": "##28282B", "id": "P-RAG ({\u0027paper_id\u0027: \u00272409.11279\u0027, \u0027relationship_description\u0027: \u0027P-RAG is designed to address the challenges of Embodied Everyday Task, such as lack of explicit task planning and extensive training required to equip models with knowledge of the task environment.\u0027, \u0027triplet_source_id\u0027: \u002709f7ff6c-3b28-4f75-872f-99ccc14b233b\u0027})", "label": "P-RAG ", "shape": "dot", "title": "Node: P-RAG \nPaper ID: 2409.11279\nCommunity:-1"}, {"color": "##28282B", "id": "Embodied Everyday Task ({\u0027paper_id\u0027: \u00272409.11279\u0027, \u0027triplet_source_id\u0027: \u002709f7ff6c-3b28-4f75-872f-99ccc14b233b\u0027})", "label": "Embodied Everyday Task ", "shape": "dot", "title": "Node: Embodied Everyday Task \nPaper ID: 2409.11279\nCommunity:-1"}, {"color": "##28282B", "id": "Progressive Retrieval Augmented Generation ({\u0027paper_id\u0027: \u00272409.11279\u0027, \u0027entity_description\u0027: \u0027A method that retrieves relevant information from the database in an iterative approach to progressively update the database.\u0027, \u0027triplet_source_id\u0027: \u002709f7ff6c-3b28-4f75-872f-99ccc14b233b\u0027})", "label": "Progressive Retrieval Augmented Generation ", "shape": "dot", "title": "Node: Progressive Retrieval Augmented Generation \nPaper ID: 2409.11279\nCommunity:-1"}, {"color": "##28282B", "id": "Conventional RAG methods ({\u0027paper_id\u0027: \u00272409.11279\u0027, \u0027entity_description\u0027: \u0027Methods that retrieve relevant information from the database in a one-shot manner to assist generation.\u0027, \u0027triplet_source_id\u0027: \u002709f7ff6c-3b28-4f75-872f-99ccc14b233b\u0027})", "label": "Conventional RAG methods ", "shape": "dot", "title": "Node: Conventional RAG methods \nPaper ID: 2409.11279\nCommunity:-1"}, {"color": "##28282B", "id": "Sourav Verma ({\u0027paper_id\u0027: \u00272409.13385\u0027, \u0027relationship_description\u0027: \u0027Large Language Models use Retrieval-Augmented Generation to improve the consistency and coherence of generated content.\u0027, \u0027triplet_source_id\u0027: \u002739e32117-2c18-45c8-b867-99b5506e1800\u0027})", "label": "Sourav Verma ", "shape": "dot", "title": "Node: Sourav Verma \nPaper ID: 2409.13385\nCommunity:-1"}, {"color": "##28282B", "id": "Contextual Compression ({\u0027paper_id\u0027: \u00272409.13385\u0027, \u0027relationship_description\u0027: \u0027Large Language Models use Retrieval-Augmented Generation to improve the consistency and coherence of generated content.\u0027, \u0027triplet_source_id\u0027: \u002739e32117-2c18-45c8-b867-99b5506e1800\u0027})", "label": "Contextual Compression ", "shape": "dot", "title": "Node: Contextual Compression \nPaper ID: 2409.13385\nCommunity:-1"}, {"color": "##28282B", "id": "Shuo Yu ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Shuo Yu ", "shape": "dot", "title": "Node: Shuo Yu \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Mingyue Cheng ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Mingyue Cheng ", "shape": "dot", "title": "Node: Mingyue Cheng \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Jiqian Yang ({\u0027paper_id\u0027: \u00272409.13694\u0027, \u0027relationship_description\u0027: \u0027Mingyue Cheng is the author of the paper about RAG\u0027, \u0027triplet_source_id\u0027: \u00273f0148c4-cb74-4aec-8313-5d9263033c93\u0027})", "label": "Jiqian Yang ", "shape": "dot", "title": "Node: Jiqian Yang \nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "Jie Ouyang ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027relationship_description\u0027: \u0027APEX team solved the CRAG benchmark challenge\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Jie Ouyang ", "shape": "dot", "title": "Node: Jie Ouyang \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Anhui Province Key Laboratory of Big Data Analysis and Application ({\u0027paper_id\u0027: \u00272409.13694\u0027, \u0027relationship_description\u0027: \u0027Jie Ouyang is the author of the paper about RAG\u0027, \u0027triplet_source_id\u0027: \u00273f0148c4-cb74-4aec-8313-5d9263033c93\u0027})", "label": "Anhui Province Key Laboratory of Big Data Analysis and Application ", "shape": "dot", "title": "Node: Anhui Province Key Laboratory of Big Data Analysis and Application \nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "University of Science and Technology of China ({\u0027paper_id\u0027: \u00272409.13694\u0027, \u0027relationship_description\u0027: \u0027Shuo Yu is affiliated with Anhui Province Key Laboratory of Big Data Analysis and Application\u0027, \u0027triplet_source_id\u0027: \u00273f0148c4-cb74-4aec-8313-5d9263033c93\u0027})", "label": "University of Science and Technology of China ", "shape": "dot", "title": "Node: University of Science and Technology of China \nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "State Key Laboratory of Cognitive Intelligence ({\u0027paper_id\u0027: \u00272409.13694\u0027, \u0027relationship_description\u0027: \u0027Shuo Yu is affiliated with University of Science and Technology of China\u0027, \u0027triplet_source_id\u0027: \u00273f0148c4-cb74-4aec-8313-5d9263033c93\u0027})", "label": "State Key Laboratory of Cognitive Intelligence ", "shape": "dot", "title": "Node: State Key Laboratory of Cognitive Intelligence \nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "KDD Cup 2024 CRAG competition ({\u0027paper_id\u0027: \u00272409.13694\u0027, \u0027entity_description\u0027: \u0027Competition\u0027, \u0027triplet_source_id\u0027: \u00273f0148c4-cb74-4aec-8313-5d9263033c93\u0027})", "label": "KDD Cup 2024 CRAG competition ", "shape": "dot", "title": "Node: KDD Cup 2024 CRAG competition \nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "CRAG dataset ({\u0027paper_id\u0027: \u00272409.13694\u0027, \u0027entity_description\u0027: \u0027Dataset used in the study\u0027, \u0027triplet_source_id\u0027: \u00273f0148c4-cb74-4aec-8313-5d9263033c93\u0027})", "label": "CRAG dataset ", "shape": "dot", "title": "Node: CRAG dataset \nPaper ID: 2409.13694\nCommunity:-1"}, {"color": "##28282B", "id": "Meta KDD Cup 2024 ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027relationship_description\u0027: \u0027APEX team solved the CRAG benchmark challenge\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Meta KDD Cup 2024 ", "shape": "dot", "title": "Node: Meta KDD Cup 2024 \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "CRAG ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027relationship_description\u0027: \u0027APEX team participated in the Meta KDD Cup 2024\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "CRAG ", "shape": "dot", "title": "Node: CRAG \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "APEX ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027relationship_description\u0027: \u0027APEX team participated in the Meta KDD Cup 2024\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "APEX ", "shape": "dot", "title": "Node: APEX \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Yucong Luo ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Yucong Luo ", "shape": "dot", "title": "Node: Yucong Luo \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "Daoyu Wang ({\u0027paper_id\u0027: \u00272409.15337\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027d5767b92-46e2-4dc9-b62d-678a8d6f37af\u0027})", "label": "Daoyu Wang ", "shape": "dot", "title": "Node: Daoyu Wang \nPaper ID: 2409.15337\nCommunity:-1"}, {"color": "##28282B", "id": "GEM-RAG ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027relationship_description\u0027: \u0027GPT-3.5 Turbo is used to evaluate the performance of GEM-RAG.\u0027, \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "GEM-RAG ", "shape": "dot", "title": "Node: GEM-RAG \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "Brendan Hogan Rappazzo ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "Brendan Hogan Rappazzo ", "shape": "dot", "title": "Node: Brendan Hogan Rappazzo \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "Yingheng Wang ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "Yingheng Wang ", "shape": "dot", "title": "Node: Yingheng Wang \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "Aaron Ferber ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "Aaron Ferber ", "shape": "dot", "title": "Node: Aaron Ferber \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "Carla Gomes ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027entity_description\u0027: \"One of the authors of the paper \u0027GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation\u0027.\", \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "Carla Gomes ", "shape": "dot", "title": "Node: Carla Gomes \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "UnifiedQA ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027relationship_description\u0027: \u0027GEM-RAG is a method for Retrieval Augmented Generation.\u0027, \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "UnifiedQA ", "shape": "dot", "title": "Node: UnifiedQA \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "GPT-3.5 Turbo ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027relationship_description\u0027: \u0027UnifiedQA is used to evaluate the performance of GEM-RAG.\u0027, \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "GPT-3.5 Turbo ", "shape": "dot", "title": "Node: GPT-3.5 Turbo \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "SBERT ({\u0027paper_id\u0027: \u00272409.15566\u0027, \u0027relationship_description\u0027: \u0027GEM-RAG uses SBERT as a text encoder.\u0027, \u0027triplet_source_id\u0027: \u00272e2fa5a4-7555-44e6-88b3-d23631a1ffdb\u0027})", "label": "SBERT ", "shape": "dot", "title": "Node: SBERT \nPaper ID: 2409.15566\nCommunity:-1"}, {"color": "##28282B", "id": "FlexRAG (Flexible Context Adaptation for RAG) ({\u0027paper_id\u0027: \u00272409.15699\u0027, \u0027relationship_description\u0027: \u0027RAG systems use LLMs to encode retrieved contexts and generate responses.\u0027, \u0027triplet_source_id\u0027: \u0027d2af8dbf-21ca-4d26-858b-bfa7f1a352ca\u0027})", "label": "FlexRAG (Flexible Context Adaptation for RAG) ", "shape": "dot", "title": "Node: FlexRAG (Flexible Context Adaptation for RAG) \nPaper ID: 2409.15699\nCommunity:-1"}, {"color": "##28282B", "id": "Question-answering datasets ({\u0027paper_id\u0027: \u00272409.15699\u0027, \u0027entity_description\u0027: \u0027Collections of questions and answers used to evaluate the performance of RAG systems.\u0027, \u0027triplet_source_id\u0027: \u0027d2af8dbf-21ca-4d26-858b-bfa7f1a352ca\u0027})", "label": "Question-answering datasets ", "shape": "dot", "title": "Node: Question-answering datasets \nPaper ID: 2409.15699\nCommunity:-1"}, {"color": "##28282B", "id": "Question Answering ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027relationship_description\u0027: \u0027LoRA is used in PEFT as a parameter-efficient fine-tuning technique.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "Question Answering ", "shape": "dot", "title": "Node: Question Answering \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "Prompt Engineering ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027entity_description\u0027: \u0027The process of designing and optimizing prompts for language models to improve their performance.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "Prompt Engineering ", "shape": "dot", "title": "Node: Prompt Engineering \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "Resource Efficiency ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027entity_description\u0027: \u0027The goal of minimizing the use of resources such as computational power, memory, and storage.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "Resource Efficiency ", "shape": "dot", "title": "Node: Resource Efficiency \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "RAFT ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027relationship_description\u0027: \u0027Retrieval Augmented Generation integrates external knowledge into Large Language Models to enhance accuracy and relevancy in question answering tasks.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "RAFT ", "shape": "dot", "title": "Node: RAFT \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "PEFT ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027relationship_description\u0027: \u0027RAFT combines with PEFT to reduce fine-tuning and storage requirements.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "PEFT ", "shape": "dot", "title": "Node: PEFT \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "LoRA ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027relationship_description\u0027: \u0027RAFT combines with PEFT to reduce fine-tuning and storage requirements.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "LoRA ", "shape": "dot", "title": "Node: LoRA \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "CRAFT ({\u0027paper_id\u0027: \u00272409.17648\u0027, \u0027relationship_description\u0027: \u0027LoRA is used in PEFT as a parameter-efficient fine-tuning technique.\u0027, \u0027triplet_source_id\u0027: \u0027af9803d2-2b5d-4624-add8-fcc1e7756748\u0027})", "label": "CRAFT ", "shape": "dot", "title": "Node: CRAFT \nPaper ID: 2409.17648\nCommunity:-1"}, {"color": "##28282B", "id": "BSharedRAG ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027relationship_description\u0027: \u0027BSharedRAG uses the Low-Rank Adaptation (LoRA) module\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "BSharedRAG ", "shape": "dot", "title": "Node: BSharedRAG \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Kaisi Guan ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027relationship_description\u0027: \u0027BSharedRAG uses the Low-Rank Adaptation (LoRA) module\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Kaisi Guan ", "shape": "dot", "title": "Node: Kaisi Guan \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Qian Cao ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Qian Cao ", "shape": "dot", "title": "Node: Qian Cao \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Yuchong Sun ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Yuchong Sun ", "shape": "dot", "title": "Node: Yuchong Sun \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Xiting Wang ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Xiting Wang ", "shape": "dot", "title": "Node: Xiting Wang \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Ruihua Song ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Ruihua Song ", "shape": "dot", "title": "Node: Ruihua Song \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "e-commerce ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "e-commerce ", "shape": "dot", "title": "Node: e-commerce \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Low-Rank Adaptation (LoRA) ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027relationship_description\u0027: \u0027BSharedRAG incorporates the Retrieval Augmented Generation (RAG) technique\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Low-Rank Adaptation (LoRA) ", "shape": "dot", "title": "Node: Low-Rank Adaptation (LoRA) \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "BLEU-3 ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027entity_description\u0027: \u0027A metric for evaluating the quality of generated text\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "BLEU-3 ", "shape": "dot", "title": "Node: BLEU-3 \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Hit@3 ({\u0027paper_id\u0027: \u00272409.20075\u0027, \u0027entity_description\u0027: \u0027A metric for evaluating the performance of a retrieval system\u0027, \u0027triplet_source_id\u0027: \u002749f4dda4-a119-4696-ba6d-8e2d8d41a001\u0027})", "label": "Hit@3 ", "shape": "dot", "title": "Node: Hit@3 \nPaper ID: 2409.20075\nCommunity:-1"}, {"color": "##28282B", "id": "Retro-li ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027relationship_description\u0027: \u0027Retro-li contains a non-parametric memory that is used to retrieve information and improve language modeling capabilities.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Retro-li ", "shape": "dot", "title": "Node: Retro-li \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Retro ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Retro ", "shape": "dot", "title": "Node: Retro \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Gentiana Rashiti ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of Retro-li.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Gentiana Rashiti ", "shape": "dot", "title": "Node: Gentiana Rashiti \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Geethan Karunaratne ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of Retro-li.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Geethan Karunaratne ", "shape": "dot", "title": "Node: Geethan Karunaratne \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Mrinmaya Sachan ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of Retro-li.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Mrinmaya Sachan ", "shape": "dot", "title": "Node: Mrinmaya Sachan \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Abu Sebastian ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of Retro-li.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Abu Sebastian ", "shape": "dot", "title": "Node: Abu Sebastian \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Abbas Rahimi ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027entity_description\u0027: \u0027A researcher who contributed to the development of Retro-li.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Abbas Rahimi ", "shape": "dot", "title": "Node: Abbas Rahimi \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "IBM ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027entity_description\u0027: \u0027The organization that developed and released the Retrieval-Enhanced-Transformer-Little code.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "IBM ", "shape": "dot", "title": "Node: IBM \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Semantic Similarity Search ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027relationship_description\u0027: \u0027Retro-li is an improved version of Retro that uses a small-scale database and semantic similarity search to improve language modeling capabilities and reduce toxicity and hallucinations.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Semantic Similarity Search ", "shape": "dot", "title": "Node: Semantic Similarity Search \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Non-Parametric Memory ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027relationship_description\u0027: \u0027Retro-li uses semantic similarity search to find accurate and better neighbors in a small-scale database.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Non-Parametric Memory ", "shape": "dot", "title": "Node: Non-Parametric Memory \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Analog In-Memory Computing Hardware ({\u0027paper_id\u0027: \u00272410.00004\u0027, \u0027relationship_description\u0027: \u0027Retro-li contains a non-parametric memory that is used to retrieve information and improve language modeling capabilities.\u0027, \u0027triplet_source_id\u0027: \u00272028915e-fbdd-49ab-9a2e-f8c5ed4c1752\u0027})", "label": "Analog In-Memory Computing Hardware ", "shape": "dot", "title": "Node: Analog In-Memory Computing Hardware \nPaper ID: 2410.00004\nCommunity:-1"}, {"color": "##28282B", "id": "Jingyu Liu ({\u0027paper_id\u0027: \u00272410.02338\u0027, \u0027entity_description\u0027: \u0027Author of the paper, Jingyu Liu\u0027, \u0027triplet_source_id\u0027: \u0027af0a5060-d0b5-4cf6-878f-ff1503408091\u0027})", "label": "Jingyu Liu ", "shape": "dot", "title": "Node: Jingyu Liu \nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "Jiaen Lin ({\u0027paper_id\u0027: \u00272410.02338\u0027, \u0027entity_description\u0027: \u0027Author of the paper, Jiaen Lin\u0027, \u0027triplet_source_id\u0027: \u0027af0a5060-d0b5-4cf6-878f-ff1503408091\u0027})", "label": "Jiaen Lin ", "shape": "dot", "title": "Node: Jiaen Lin \nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "Yong Liu ({\u0027paper_id\u0027: \u00272410.02338\u0027, \u0027entity_description\u0027: \u0027Author of the paper, Yong Liu\u0027, \u0027triplet_source_id\u0027: \u0027af0a5060-d0b5-4cf6-878f-ff1503408091\u0027})", "label": "Yong Liu ", "shape": "dot", "title": "Node: Yong Liu \nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "DPrompt tuning ({\u0027paper_id\u0027: \u00272410.02338\u0027, \u0027relationship_description\u0027: \u0027RAG requires preprocessing of information in documents to filter out noise\u0027, \u0027triplet_source_id\u0027: \u0027af0a5060-d0b5-4cf6-878f-ff1503408091\u0027})", "label": "DPrompt tuning ", "shape": "dot", "title": "Node: DPrompt tuning \nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "documents ({\u0027paper_id\u0027: \u00272410.02338\u0027, \u0027relationship_description\u0027: \u0027RAG helps the reasoning process of LLM\u0027, \u0027triplet_source_id\u0027: \u0027af0a5060-d0b5-4cf6-878f-ff1503408091\u0027})", "label": "documents ", "shape": "dot", "title": "Node: documents \nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "preprocessing ({\u0027paper_id\u0027: \u00272410.02338\u0027, \u0027relationship_description\u0027: \u0027RAG requires preprocessing of information in documents to filter out noise\u0027, \u0027triplet_source_id\u0027: \u0027af0a5060-d0b5-4cf6-878f-ff1503408091\u0027})", "label": "preprocessing ", "shape": "dot", "title": "Node: preprocessing \nPaper ID: 2410.02338\nCommunity:-1"}, {"color": "##28282B", "id": "Long Context Question Answering ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "Long Context Question Answering ", "shape": "dot", "title": "Node: Long Context Question Answering \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "RAIDD ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027relationship_description\u0027: \u0027RAIDD is an extension to Retrieval Augmented Generation systems.\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "RAIDD ", "shape": "dot", "title": "Node: RAIDD \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "Keyush Shah ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "Keyush Shah ", "shape": "dot", "title": "Node: Keyush Shah \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "Abhishek Goyal ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "Abhishek Goyal ", "shape": "dot", "title": "Node: Abhishek Goyal \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "Isaac Wasserman ({\u0027paper_id\u0027: \u00272410.03754\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u0027825212d3-ce47-479e-ace0-c60958cd948f\u0027})", "label": "Isaac Wasserman ", "shape": "dot", "title": "Node: Isaac Wasserman \nPaper ID: 2410.03754\nCommunity:-1"}, {"color": "##28282B", "id": "StructRAG ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027relationship_description\u0027: \u0027RAG is a method that augments LLMs in knowledge-based tasks\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "StructRAG ", "shape": "dot", "title": "Node: StructRAG \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Zhuoqun Li ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Zhuoqun Li ", "shape": "dot", "title": "Node: Zhuoqun Li \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Xuanang Chen ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Xuanang Chen ", "shape": "dot", "title": "Node: Xuanang Chen \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Haiyang Yu ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Haiyang Yu ", "shape": "dot", "title": "Node: Haiyang Yu \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Yaojie Lu ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Yaojie Lu ", "shape": "dot", "title": "Node: Yaojie Lu \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Qiaoyu Tang ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Qiaoyu Tang ", "shape": "dot", "title": "Node: Qiaoyu Tang \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Fei Huang ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Fei Huang ", "shape": "dot", "title": "Node: Fei Huang \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Yongbin Li ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Yongbin Li ", "shape": "dot", "title": "Node: Yongbin Li \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge-intensive reasoning ({\u0027paper_id\u0027: \u00272410.08815\u0027, \u0027relationship_description\u0027: \u0027RAG is a method that augments LLMs in knowledge-based tasks\u0027, \u0027triplet_source_id\u0027: \u002753ab3d20-b796-4d5c-ad7a-19fb5588b8f8\u0027})", "label": "Knowledge-intensive reasoning ", "shape": "dot", "title": "Node: Knowledge-intensive reasoning \nPaper ID: 2410.08815\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieval-Augmented Generation (RAG) agents ({\u0027paper_id\u0027: \u00272410.09942\u0027, \u0027relationship_description\u0027: \u0027RAG agents use the LLM as a backbone\u0027, \u0027triplet_source_id\u0027: \u002737b7c0f0-e3ac-47b9-a15d-92a3d045dcad\u0027})", "label": "Retrieval-Augmented Generation (RAG) agents ", "shape": "dot", "title": "Node: Retrieval-Augmented Generation (RAG) agents \nPaper ID: 2410.09942\nCommunity:-1"}, {"color": "##28282B", "id": "Backbone Large Language Model (LLM) ({\u0027paper_id\u0027: \u00272410.09942\u0027, \u0027relationship_description\u0027: \u0027They co-authored the paper\u0027, \u0027triplet_source_id\u0027: \u002737b7c0f0-e3ac-47b9-a15d-92a3d045dcad\u0027})", "label": "Backbone Large Language Model (LLM) ", "shape": "dot", "title": "Node: Backbone Large Language Model (LLM) \nPaper ID: 2410.09942\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge-Intensive Language Tasks (KILT) benchmark ({\u0027paper_id\u0027: \u00272410.09942\u0027, \u0027relationship_description\u0027: \u0027RAG agents use the LLM as a backbone\u0027, \u0027triplet_source_id\u0027: \u002737b7c0f0-e3ac-47b9-a15d-92a3d045dcad\u0027})", "label": "Knowledge-Intensive Language Tasks (KILT) benchmark ", "shape": "dot", "title": "Node: Knowledge-Intensive Language Tasks (KILT) benchmark \nPaper ID: 2410.09942\nCommunity:-1"}, {"color": "##28282B", "id": "FunnelRAG ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Baotian Hu is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "FunnelRAG ", "shape": "dot", "title": "Node: FunnelRAG \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Xinping Zhao ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027FunnelRAG is used in Large Language Models\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Xinping Zhao ", "shape": "dot", "title": "Node: Xinping Zhao \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Yan Zhong ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Xinping Zhao is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Yan Zhong ", "shape": "dot", "title": "Node: Yan Zhong \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Zetian Sun ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Yan Zhong is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Zetian Sun ", "shape": "dot", "title": "Node: Zetian Sun \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Xinshuo Hu ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Zetian Sun is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Xinshuo Hu ", "shape": "dot", "title": "Node: Xinshuo Hu \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Zhenyu Liu ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Xinshuo Hu is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Zhenyu Liu ", "shape": "dot", "title": "Node: Zhenyu Liu \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Dongfang Li ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Zhenyu Liu is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Dongfang Li ", "shape": "dot", "title": "Node: Dongfang Li \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Baotian Hu ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Dongfang Li is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Baotian Hu ", "shape": "dot", "title": "Node: Baotian Hu \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Min Zhang ({\u0027paper_id\u0027: \u00272410.10293\u0027, \u0027relationship_description\u0027: \u0027Baotian Hu is one of the authors of FunnelRAG\u0027, \u0027triplet_source_id\u0027: \u00274ac0591c-70a7-4d56-8dc8-5fb390575ea6\u0027})", "label": "Min Zhang ", "shape": "dot", "title": "Node: Min Zhang \nPaper ID: 2410.10293\nCommunity:-1"}, {"color": "##28282B", "id": "Wenjia Zhai ({\u0027paper_id\u0027: \u00272410.11321\u0027, \u0027triplet_source_id\u0027: \u002711f6a5bc-a6ad-43c6-80e2-11bbfb232dec\u0027})", "label": "Wenjia Zhai ", "shape": "dot", "title": "Node: Wenjia Zhai \nPaper ID: 2410.11321\nCommunity:-1"}, {"color": "##28282B", "id": "Self-adaptive Multimodal Retrieval-Augmented Generation ({\u0027paper_id\u0027: \u00272410.11321\u0027, \u0027relationship_description\u0027: \"Wenjia Zhai is the author of the paper \u0027Self-adaptive Multimodal Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u002711f6a5bc-a6ad-43c6-80e2-11bbfb232dec\u0027})", "label": "Self-adaptive Multimodal Retrieval-Augmented Generation ", "shape": "dot", "title": "Node: Self-adaptive Multimodal Retrieval-Augmented Generation \nPaper ID: 2410.11321\nCommunity:-1"}, {"color": "##28282B", "id": "Traditional Retrieval-Augmented Generation ({\u0027paper_id\u0027: \u00272410.11321\u0027, \u0027relationship_description\u0027: \"Wenjia Zhai is the author of the paper \u0027Self-adaptive Multimodal Retrieval-Augmented Generation\u0027\", \u0027triplet_source_id\u0027: \u002711f6a5bc-a6ad-43c6-80e2-11bbfb232dec\u0027})", "label": "Traditional Retrieval-Augmented Generation ", "shape": "dot", "title": "Node: Traditional Retrieval-Augmented Generation \nPaper ID: 2410.11321\nCommunity:-1"}, {"color": "##28282B", "id": "SAM-RAG ({\u0027paper_id\u0027: \u00272410.11321\u0027, \u0027relationship_description\u0027: \u0027SAM-RAG is an application of Multimodal Retrieval-Augmented Generation\u0027, \u0027triplet_source_id\u0027: \u002711f6a5bc-a6ad-43c6-80e2-11bbfb232dec\u0027})", "label": "SAM-RAG ", "shape": "dot", "title": "Node: SAM-RAG \nPaper ID: 2410.11321\nCommunity:-1"}, {"color": "##28282B", "id": "Multimodal Retrieval-Augmented Generation ({\u0027paper_id\u0027: \u00272410.11321\u0027, \u0027relationship_description\u0027: \u0027Self-adaptive Multimodal Retrieval-Augmented Generation is an alternative to Traditional Retrieval-Augmented Generation\u0027, \u0027triplet_source_id\u0027: \u002711f6a5bc-a6ad-43c6-80e2-11bbfb232dec\u0027})", "label": "Multimodal Retrieval-Augmented Generation ", "shape": "dot", "title": "Node: Multimodal Retrieval-Augmented Generation \nPaper ID: 2410.11321\nCommunity:-1"}, {"color": "##28282B", "id": "CoFE-RAG ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027relationship_description\u0027: \u0027CoFE-RAG enhances Large Language Models to generate more accurate and reliable answers\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "CoFE-RAG ", "shape": "dot", "title": "Node: CoFE-RAG \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Jintao Liu ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027relationship_description\u0027: \u0027CoFE-RAG enhances Large Language Models to generate more accurate and reliable answers\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "Jintao Liu ", "shape": "dot", "title": "Node: Jintao Liu \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Ruixue Ding ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "Ruixue Ding ", "shape": "dot", "title": "Node: Ruixue Ding \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Linhao Zhang ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "Linhao Zhang ", "shape": "dot", "title": "Node: Linhao Zhang \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Pengjun Xie ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "Pengjun Xie ", "shape": "dot", "title": "Node: Pengjun Xie \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Fie Huang ({\u0027paper_id\u0027: \u00272410.12248\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u002792b99fba-dcd0-425a-ac34-48ebd0870836\u0027})", "label": "Fie Huang ", "shape": "dot", "title": "Node: Fie Huang \nPaper ID: 2410.12248\nCommunity:-1"}, {"color": "##28282B", "id": "Shailja Gupta ({\u0027paper_id\u0027: \u00272410.12837\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027fbbedd4d-bd29-481c-9be9-bd84f57c739c\u0027})", "label": "Shailja Gupta ", "shape": "dot", "title": "Node: Shailja Gupta \nPaper ID: 2410.12837\nCommunity:-1"}, {"color": "##28282B", "id": "Rajesh Ranjan ({\u0027paper_id\u0027: \u00272410.12837\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027fbbedd4d-bd29-481c-9be9-bd84f57c739c\u0027})", "label": "Rajesh Ranjan ", "shape": "dot", "title": "Node: Rajesh Ranjan \nPaper ID: 2410.12837\nCommunity:-1"}, {"color": "##28282B", "id": "Surya Narayan Singh ({\u0027paper_id\u0027: \u00272410.12837\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper\u0027, \u0027triplet_source_id\u0027: \u0027fbbedd4d-bd29-481c-9be9-bd84f57c739c\u0027})", "label": "Surya Narayan Singh ", "shape": "dot", "title": "Node: Surya Narayan Singh \nPaper ID: 2410.12837\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge-intensive tasks ({\u0027paper_id\u0027: \u00272410.12837\u0027, \u0027relationship_description\u0027: \u0027RAG combines retrieval mechanisms with generative language models to enhance the accuracy of LLMs\u0027, \u0027triplet_source_id\u0027: \u0027fbbedd4d-bd29-481c-9be9-bd84f57c739c\u0027})", "label": "Knowledge-intensive tasks ", "shape": "dot", "title": "Node: Knowledge-intensive tasks \nPaper ID: 2410.12837\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge Retrieval ({\u0027paper_id\u0027: \u00272410.13258\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation uses Knowledge Selection to select relevant knowledge from the retrieved knowledge.\u0027, \u0027triplet_source_id\u0027: \u00275c41d11a-7a50-4de7-ba89-18ba3e8aa9dc\u0027})", "label": "Knowledge Retrieval ", "shape": "dot", "title": "Node: Knowledge Retrieval \nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "Knowledge Selection ({\u0027paper_id\u0027: \u00272410.13258\u0027, \u0027relationship_description\u0027: \u0027Retrieval-Augmented Generation uses Knowledge Selection to select relevant knowledge from the retrieved knowledge.\u0027, \u0027triplet_source_id\u0027: \u00275c41d11a-7a50-4de7-ba89-18ba3e8aa9dc\u0027})", "label": "Knowledge Selection ", "shape": "dot", "title": "Node: Knowledge Selection \nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "Natural Language Generation ({\u0027paper_id\u0027: \u00272410.13258\u0027, \u0027entity_description\u0027: \u0027The field of study that focuses on generating human-like language from a given input.\u0027, \u0027triplet_source_id\u0027: \u00275c41d11a-7a50-4de7-ba89-18ba3e8aa9dc\u0027})", "label": "Natural Language Generation ", "shape": "dot", "title": "Node: Natural Language Generation \nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "Xiangci Li ({\u0027paper_id\u0027: \u00272410.13258\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u00275c41d11a-7a50-4de7-ba89-18ba3e8aa9dc\u0027})", "label": "Xiangci Li ", "shape": "dot", "title": "Node: Xiangci Li \nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "Jessica Ouyang ({\u0027paper_id\u0027: \u00272410.13258\u0027, \u0027entity_description\u0027: \u0027One of the authors of the paper.\u0027, \u0027triplet_source_id\u0027: \u00275c41d11a-7a50-4de7-ba89-18ba3e8aa9dc\u0027})", "label": "Jessica Ouyang ", "shape": "dot", "title": "Node: Jessica Ouyang \nPaper ID: 2410.13258\nCommunity:-1"}, {"color": "##28282B", "id": "Probing-RAG ({\u0027paper_id\u0027: \u00272410.13339\u0027, \u0027relationship_description\u0027: \u0027Probing-RAG utilizes a pre-trained prober to capture the internal cognition of language models.\u0027, \u0027triplet_source_id\u0027: \u0027bff142f7-57eb-4c61-85d5-615bfe4b4cd6\u0027})", "label": "Probing-RAG ", "shape": "dot", "title": "Node: Probing-RAG \nPaper ID: 2410.13339\nCommunity:-1"}, {"color": "##28282B", "id": "Retrieve-and-Generate ({\u0027paper_id\u0027: \u00272410.13339\u0027, \u0027entity_description\u0027: \u0027A traditional process that retrieves and incorporates relevant external knowledge into language models.\u0027, \u0027triplet_source_id\u0027: \u0027bff142f7-57eb-4c61-85d5-615bfe4b4cd6\u0027})", "label": "Retrieve-and-Generate ", "shape": "dot", "title": "Node: Retrieve-and-Generate \nPaper ID: 2410.13339\nCommunity:-1"}, {"color": "##28282B", "id": "Prober ({\u0027paper_id\u0027: \u00272410.13339\u0027, \u0027relationship_description\u0027: \u0027Probing-RAG enhances language models by retrieving and incorporating relevant external knowledge.\u0027, \u0027triplet_source_id\u0027: \u0027bff142f7-57eb-4c61-85d5-615bfe4b4cd6\u0027})", "label": "Prober ", "shape": "dot", "title": "Node: Prober \nPaper ID: 2410.13339\nCommunity:-1"}, {"color": "##28282B", "id": "Open-domain QA Datasets ({\u0027paper_id\u0027: \u00272410.13339\u0027, \u0027relationship_description\u0027: \u0027Probing-RAG utilizes a pre-trained prober to capture the internal cognition of language models.\u0027, \u0027triplet_source_id\u0027: \u0027bff142f7-57eb-4c61-85d5-615bfe4b4cd6\u0027})", "label": "Open-domain QA Datasets ", "shape": "dot", "title": "Node: Open-domain QA Datasets \nPaper ID: 2410.13339\nCommunity:-1"}, {"color": "##28282B", "id": "AutoRAG ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027relationship_description\u0027: \u0027The authors of the paper propose the AutoRAG framework\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "AutoRAG ", "shape": "dot", "title": "Node: AutoRAG \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Dongkyu Kim ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "Dongkyu Kim ", "shape": "dot", "title": "Node: Dongkyu Kim \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Byoungwook Kim ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "Byoungwook Kim ", "shape": "dot", "title": "Node: Byoungwook Kim \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Donggeon Han ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027entity_description\u0027: \u0027Author of the paper\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "Donggeon Han ", "shape": "dot", "title": "Node: Donggeon Han \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "##28282B", "id": "Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich ({\u0027paper_id\u0027: \u00272410.20878\u0027, \u0027relationship_description\u0027: \u0027AutoRAG enhances the Retrieval-Augmented Generation technology\u0027, \u0027triplet_source_id\u0027: \u0027ab42493a-3b44-4042-9e41-aca51e4263ed\u0027})", "label": "Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich ", "shape": "dot", "title": "Node: Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich \nPaper ID: 2410.20878\nCommunity:-1"}, {"color": "#ff0000", "id": "Fine-tune the Entire RAG Architecture", "label": "Fine-tune the Entire RAG Architecture", "shape": "dot", "title": "Node: Fine-tune the Entire RAG Architecture\nPaper ID: N/A\nCommunity:0"}, {"color": "#ff0000", "id": "RAG Architecture", "label": "RAG Architecture", "shape": "dot", "title": "Node: RAG Architecture\nPaper ID: N/A\nCommunity:0"}, {"color": "#ff0000", "id": "DPR Retriever", "label": "DPR Retriever", "shape": "dot", "title": "Node: DPR Retriever\nPaper ID: N/A\nCommunity:0"}, {"color": "#ff0000", "id": "Shamane Siriwardhana", "label": "Shamane Siriwardhana", "shape": "dot", "title": "Node: Shamane Siriwardhana\nPaper ID: N/A\nCommunity:0"}, {"color": "#0062ff", "id": "Large Language Models", "label": "Large Language Models", "shape": "dot", "title": "Node: Large Language Models\nPaper ID: N/A\nCommunity:63"}, {"color": "#c100ff", "id": "Retrieval Augmented Generation", "label": "Retrieval Augmented Generation", "shape": "dot", "title": "Node: Retrieval Augmented Generation\nPaper ID: N/A\nCommunity:83"}, {"color": "#c100ff", "id": "Medical Education", "label": "Medical Education", "shape": "dot", "title": "Node: Medical Education\nPaper ID: N/A\nCommunity:83"}, {"color": "#ff6600", "id": "Cheonsu Jeong", "label": "Cheonsu Jeong", "shape": "dot", "title": "Node: Cheonsu Jeong\nPaper ID: N/A\nCommunity:7"}, {"color": "#ff6600", "id": "Large Language Models (LLM)", "label": "Large Language Models (LLM)", "shape": "dot", "title": "Node: Large Language Models (LLM)\nPaper ID: N/A\nCommunity:7"}, {"color": "#ff6600", "id": "Retrieval-Augmented Generation (RAG) model", "label": "Retrieval-Augmented Generation (RAG) model", "shape": "dot", "title": "Node: Retrieval-Augmented Generation (RAG) model\nPaper ID: N/A\nCommunity:7"}, {"color": "#ff6600", "id": "Generative AI services", "label": "Generative AI services", "shape": "dot", "title": "Node: Generative AI services\nPaper ID: N/A\nCommunity:7"}, {"color": "#ff009b", "id": "Retrieval-Augmented Generation", "label": "Retrieval-Augmented Generation", "shape": "dot", "title": "Node: Retrieval-Augmented Generation\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "Retrieval-Augmented Generation Benchmark", "label": "Retrieval-Augmented Generation Benchmark", "shape": "dot", "title": "Node: Retrieval-Augmented Generation Benchmark\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff0035", "id": "RAGAS", "label": "RAGAS", "shape": "dot", "title": "Node: RAGAS\nPaper ID: N/A\nCommunity:101"}, {"color": "#0602ff", "id": "Retrieval Augmented Generation (RAG)", "label": "Retrieval Augmented Generation (RAG)", "shape": "dot", "title": "Node: Retrieval Augmented Generation (RAG)\nPaper ID: N/A\nCommunity:70"}, {"color": "#ff0035", "id": "LLMs", "label": "LLMs", "shape": "dot", "title": "Node: LLMs\nPaper ID: N/A\nCommunity:101"}, {"color": "#ff0035", "id": "Shahul Es", "label": "Shahul Es", "shape": "dot", "title": "Node: Shahul Es\nPaper ID: N/A\nCommunity:101"}, {"color": "#ff009b", "id": "External Databases", "label": "External Databases", "shape": "dot", "title": "Node: External Databases\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff9200", "id": "Naive RAG", "label": "Naive RAG", "shape": "dot", "title": "Node: Naive RAG\nPaper ID: N/A\nCommunity:10"}, {"color": "#ff9200", "id": "Advanced RAG", "label": "Advanced RAG", "shape": "dot", "title": "Node: Advanced RAG\nPaper ID: N/A\nCommunity:10"}, {"color": "#ffa000", "id": "Retrievers", "label": "Retrievers", "shape": "dot", "title": "Node: Retrievers\nPaper ID: N/A\nCommunity:11"}, {"color": "#0062ff", "id": "Retrieval-augmented Generation", "label": "Retrieval-augmented Generation", "shape": "dot", "title": "Node: Retrieval-augmented Generation\nPaper ID: N/A\nCommunity:63"}, {"color": "##28282B", "id": "Paulo Finardi", "label": "Paulo Finardi", "shape": "dot", "title": "Node: Paulo Finardi\nPaper ID: N/A\nCommunity:105"}, {"color": "##28282B", "id": "The Chronicles of RAG", "label": "The Chronicles of RAG", "shape": "dot", "title": "Node: The Chronicles of RAG\nPaper ID: N/A\nCommunity:105"}, {"color": "#ff0026", "id": "RAG", "label": "RAG", "shape": "dot", "title": "Node: RAG\nPaper ID: N/A\nCommunity:102"}, {"color": "#0036ff", "id": "OpenAI", "label": "OpenAI", "shape": "dot", "title": "Node: OpenAI\nPaper ID: N/A\nCommunity:66"}, {"color": "#0036ff", "id": "gpt-4", "label": "gpt-4", "shape": "dot", "title": "Node: gpt-4\nPaper ID: N/A\nCommunity:66"}, {"color": "#ffaf00", "id": "Google", "label": "Google", "shape": "dot", "title": "Node: Google\nPaper ID: N/A\nCommunity:12"}, {"color": "#ffaf00", "id": "Gemini Pro", "label": "Gemini Pro", "shape": "dot", "title": "Node: Gemini Pro\nPaper ID: N/A\nCommunity:12"}, {"color": "#ff0026", "id": "Harry Potter", "label": "Harry Potter", "shape": "dot", "title": "Node: Harry Potter\nPaper ID: N/A\nCommunity:102"}, {"color": "#ff009b", "id": "Information Retrieval", "label": "Information Retrieval", "shape": "dot", "title": "Node: Information Retrieval\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff008c", "id": "Generative AI", "label": "Generative AI", "shape": "dot", "title": "Node: Generative AI\nPaper ID: N/A\nCommunity:95"}, {"color": "#f800fb", "id": "Large Language Models (LLMs)", "label": "Large Language Models (LLMs)", "shape": "dot", "title": "Node: Large Language Models (LLMs)\nPaper ID: N/A\nCommunity:87"}, {"color": "#5b00ff", "id": "Retrieval-Augmented Generation (RAG)", "label": "Retrieval-Augmented Generation (RAG)", "shape": "dot", "title": "Node: Retrieval-Augmented Generation (RAG)\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Corrective Retrieval Augmented Generation (CRAG)", "label": "Corrective Retrieval Augmented Generation (CRAG)", "shape": "dot", "title": "Node: Corrective Retrieval Augmented Generation (CRAG)\nPaper ID: N/A\nCommunity:76"}, {"color": "#0054ff", "id": "CRUD-RAG", "label": "CRUD-RAG", "shape": "dot", "title": "Node: CRUD-RAG\nPaper ID: N/A\nCommunity:64"}, {"color": "#0054ff", "id": "Knowledge Sources", "label": "Knowledge Sources", "shape": "dot", "title": "Node: Knowledge Sources\nPaper ID: N/A\nCommunity:64"}, {"color": "#0054ff", "id": "CRUD", "label": "CRUD", "shape": "dot", "title": "Node: CRUD\nPaper ID: N/A\nCommunity:64"}, {"color": "#0054ff", "id": "Create", "label": "Create", "shape": "dot", "title": "Node: Create\nPaper ID: N/A\nCommunity:64"}, {"color": "#0054ff", "id": "Read", "label": "Read", "shape": "dot", "title": "Node: Read\nPaper ID: N/A\nCommunity:64"}, {"color": "##28282B", "id": "HiQA", "label": "HiQA", "shape": "dot", "title": "Node: HiQA\nPaper ID: N/A\nCommunity:106"}, {"color": "##28282B", "id": "MasQA", "label": "MasQA", "shape": "dot", "title": "Node: MasQA\nPaper ID: N/A\nCommunity:106"}, {"color": "#ffcc00", "id": "Julien Pierre Edmond Ghali", "label": "Julien Pierre Edmond Ghali", "shape": "dot", "title": "Node: Julien Pierre Edmond Ghali\nPaper ID: N/A\nCommunity:14"}, {"color": "#ffcc00", "id": "Kosuke Shima", "label": "Kosuke Shima", "shape": "dot", "title": "Node: Kosuke Shima\nPaper ID: N/A\nCommunity:14"}, {"color": "#ffcc00", "id": "Koichi Moriyama", "label": "Koichi Moriyama", "shape": "dot", "title": "Node: Koichi Moriyama\nPaper ID: N/A\nCommunity:14"}, {"color": "#ffcc00", "id": "Atsuko Mutoh", "label": "Atsuko Mutoh", "shape": "dot", "title": "Node: Atsuko Mutoh\nPaper ID: N/A\nCommunity:14"}, {"color": "#ffcc00", "id": "Nobuhiro Inuzuka", "label": "Nobuhiro Inuzuka", "shape": "dot", "title": "Node: Nobuhiro Inuzuka\nPaper ID: N/A\nCommunity:14"}, {"color": "#8700ff", "id": "BERT", "label": "BERT", "shape": "dot", "title": "Node: BERT\nPaper ID: N/A\nCommunity:79"}, {"color": "#5b00ff", "id": "Orca2", "label": "Orca2", "shape": "dot", "title": "Node: Orca2\nPaper ID: N/A\nCommunity:76"}, {"color": "#8700ff", "id": "UMAP", "label": "UMAP", "shape": "dot", "title": "Node: UMAP\nPaper ID: N/A\nCommunity:79"}, {"color": "#6900ff", "id": "Penghao Zhao", "label": "Penghao Zhao", "shape": "dot", "title": "Node: Penghao Zhao\nPaper ID: N/A\nCommunity:77"}, {"color": "#6900ff", "id": "Artificial Intelligence Generated Content (AIGC)", "label": "Artificial Intelligence Generated Content (AIGC)", "shape": "dot", "title": "Node: Artificial Intelligence Generated Content (AIGC)\nPaper ID: N/A\nCommunity:77"}, {"color": "#ffdb00", "id": "PKU-DAIR", "label": "PKU-DAIR", "shape": "dot", "title": "Node: PKU-DAIR\nPaper ID: N/A\nCommunity:15"}, {"color": "#ffdb00", "id": "RAG-Survey", "label": "RAG-Survey", "shape": "dot", "title": "Node: RAG-Survey\nPaper ID: N/A\nCommunity:15"}, {"color": "#ffe900", "id": "Retrieval Augmented Generation Systems", "label": "Retrieval Augmented Generation Systems", "shape": "dot", "title": "Node: Retrieval Augmented Generation Systems\nPaper ID: N/A\nCommunity:16"}, {"color": "#ffe900", "id": "Large-Language Model (LLM)", "label": "Large-Language Model (LLM)", "shape": "dot", "title": "Node: Large-Language Model (LLM)\nPaper ID: N/A\nCommunity:16"}, {"color": "#ffe900", "id": "Vector Database", "label": "Vector Database", "shape": "dot", "title": "Node: Vector Database\nPaper ID: N/A\nCommunity:16"}, {"color": "#ffe900", "id": "Boolean Agent", "label": "Boolean Agent", "shape": "dot", "title": "Node: Boolean Agent\nPaper ID: N/A\nCommunity:16"}, {"color": "#ff00d5", "id": "PipeRAG", "label": "PipeRAG", "shape": "dot", "title": "Node: PipeRAG\nPaper ID: N/A\nCommunity:90"}, {"color": "#ff00d5", "id": "Algorithm-System Co-design", "label": "Algorithm-System Co-design", "shape": "dot", "title": "Node: Algorithm-System Co-design\nPaper ID: N/A\nCommunity:90"}, {"color": "#9500ff", "id": "RAGGED", "label": "RAGGED", "shape": "dot", "title": "Node: RAGGED\nPaper ID: N/A\nCommunity:80"}, {"color": "#5b00ff", "id": "Language Models (LMs)", "label": "Language Models (LMs)", "shape": "dot", "title": "Node: Language Models (LMs)\nPaper ID: N/A\nCommunity:76"}, {"color": "#9500ff", "id": "Document-Based Question Answering (DBQA)", "label": "Document-Based Question Answering (DBQA)", "shape": "dot", "title": "Node: Document-Based Question Answering (DBQA)\nPaper ID: N/A\nCommunity:80"}, {"color": "#ffbe00", "id": "DRAGIN", "label": "DRAGIN", "shape": "dot", "title": "Node: DRAGIN\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu", "label": "Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu", "shape": "dot", "title": "Node: Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "GitHub", "label": "GitHub", "shape": "dot", "title": "Node: GitHub\nPaper ID: N/A\nCommunity:13"}, {"color": "#fbf500", "id": "Anuja Tayal", "label": "Anuja Tayal", "shape": "dot", "title": "Node: Anuja Tayal\nPaper ID: N/A\nCommunity:17"}, {"color": "#fbf500", "id": "Aman Tyagi", "label": "Aman Tyagi", "shape": "dot", "title": "Node: Aman Tyagi\nPaper ID: N/A\nCommunity:17"}, {"color": "#5b00ff", "id": "Conversational Systems", "label": "Conversational Systems", "shape": "dot", "title": "Node: Conversational Systems\nPaper ID: N/A\nCommunity:76"}, {"color": "#f6ff00", "id": "Dynamic Contexts", "label": "Dynamic Contexts", "shape": "dot", "title": "Node: Dynamic Contexts\nPaper ID: N/A\nCommunity:18"}, {"color": "#f6ff00", "id": "Suggestion Questions", "label": "Suggestion Questions", "shape": "dot", "title": "Node: Suggestion Questions\nPaper ID: N/A\nCommunity:18"}, {"color": "#e8ff00", "id": "Loops On Retrieval Augmented Generation (LoRAG)", "label": "Loops On Retrieval Augmented Generation (LoRAG)", "shape": "dot", "title": "Node: Loops On Retrieval Augmented Generation (LoRAG)\nPaper ID: N/A\nCommunity:19"}, {"color": "#e8ff00", "id": "Ayush Thakur", "label": "Ayush Thakur", "shape": "dot", "title": "Node: Ayush Thakur\nPaper ID: N/A\nCommunity:19"}, {"color": "#e8ff00", "id": "Rashmi Vashisth", "label": "Rashmi Vashisth", "shape": "dot", "title": "Node: Rashmi Vashisth\nPaper ID: N/A\nCommunity:19"}, {"color": "#e8ff00", "id": "Benchmark datasets", "label": "Benchmark datasets", "shape": "dot", "title": "Node: Benchmark datasets\nPaper ID: N/A\nCommunity:19"}, {"color": "#e8ff00", "id": "State-of-the-art models", "label": "State-of-the-art models", "shape": "dot", "title": "Node: State-of-the-art models\nPaper ID: N/A\nCommunity:19"}, {"color": "##28282B", "id": "Karthik Suresh", "label": "Karthik Suresh", "shape": "dot", "title": "Node: Karthik Suresh\nPaper ID: N/A\nCommunity:110"}, {"color": "##28282B", "id": "RAGS4EIC", "label": "RAGS4EIC", "shape": "dot", "title": "Node: RAGS4EIC\nPaper ID: N/A\nCommunity:110"}, {"color": "##28282B", "id": "Neeltje Kackar", "label": "Neeltje Kackar", "shape": "dot", "title": "Node: Neeltje Kackar\nPaper ID: N/A\nCommunity:110"}, {"color": "##28282B", "id": "Luke Schleck", "label": "Luke Schleck", "shape": "dot", "title": "Node: Luke Schleck\nPaper ID: N/A\nCommunity:110"}, {"color": "##28282B", "id": "Cristiano Fanelli", "label": "Cristiano Fanelli", "shape": "dot", "title": "Node: Cristiano Fanelli\nPaper ID: N/A\nCommunity:110"}, {"color": "##28282B", "id": "Electron-Ion Collider (EIC)", "label": "Electron-Ion Collider (EIC)", "shape": "dot", "title": "Node: Electron-Ion Collider (EIC)\nPaper ID: N/A\nCommunity:110"}, {"color": "##28282B", "id": "Large Language Model (LLM)", "label": "Large Language Model (LLM)", "shape": "dot", "title": "Node: Large Language Model (LLM)\nPaper ID: N/A\nCommunity:112"}, {"color": "##28282B", "id": "LangChain", "label": "LangChain", "shape": "dot", "title": "Node: LangChain\nPaper ID: N/A\nCommunity:110"}, {"color": "#ff00c7", "id": "RQ-RAG", "label": "RQ-RAG", "shape": "dot", "title": "Node: RQ-RAG\nPaper ID: N/A\nCommunity:91"}, {"color": "#ff00c7", "id": "Llama2 model", "label": "Llama2 model", "shape": "dot", "title": "Node: Llama2 model\nPaper ID: N/A\nCommunity:91"}, {"color": "#ff00c7", "id": "Single-hop QA datasets", "label": "Single-hop QA datasets", "shape": "dot", "title": "Node: Single-hop QA datasets\nPaper ID: N/A\nCommunity:91"}, {"color": "#ff00c7", "id": "Multi-hop QA datasets", "label": "Multi-hop QA datasets", "shape": "dot", "title": "Node: Multi-hop QA datasets\nPaper ID: N/A\nCommunity:91"}, {"color": "#caff00", "id": "Sumit Soman", "label": "Sumit Soman", "shape": "dot", "title": "Node: Sumit Soman\nPaper ID: N/A\nCommunity:21"}, {"color": "#caff00", "id": "Sujoy Roychowdhury", "label": "Sujoy Roychowdhury", "shape": "dot", "title": "Node: Sujoy Roychowdhury\nPaper ID: N/A\nCommunity:21"}, {"color": "#ff0026", "id": "Technical Documents", "label": "Technical Documents", "shape": "dot", "title": "Node: Technical Documents\nPaper ID: N/A\nCommunity:102"}, {"color": "##28282B", "id": "ARAGOG", "label": "ARAGOG", "shape": "dot", "title": "Node: ARAGOG\nPaper ID: N/A\nCommunity:111"}, {"color": "##28282B", "id": "Matou\u0161 Eibich", "label": "Matou\u0161 Eibich", "shape": "dot", "title": "Node: Matou\u0161 Eibich\nPaper ID: N/A\nCommunity:111"}, {"color": "##28282B", "id": "Shivay Nagpal", "label": "Shivay Nagpal", "shape": "dot", "title": "Node: Shivay Nagpal\nPaper ID: N/A\nCommunity:111"}, {"color": "##28282B", "id": "Alexander Fred-Ojala", "label": "Alexander Fred-Ojala", "shape": "dot", "title": "Node: Alexander Fred-Ojala\nPaper ID: N/A\nCommunity:111"}, {"color": "##28282B", "id": "Hypothetical Document Embedding (HyDE)", "label": "Hypothetical Document Embedding (HyDE)", "shape": "dot", "title": "Node: Hypothetical Document Embedding (HyDE)\nPaper ID: N/A\nCommunity:111"}, {"color": "##28282B", "id": "CLAPNQ", "label": "CLAPNQ", "shape": "dot", "title": "Node: CLAPNQ\nPaper ID: N/A\nCommunity:107"}, {"color": "##28282B", "id": "Natural Questions (NQ)", "label": "Natural Questions (NQ)", "shape": "dot", "title": "Node: Natural Questions (NQ)\nPaper ID: N/A\nCommunity:107"}, {"color": "#bcff00", "id": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation", "label": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation", "shape": "dot", "title": "Node: Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation\nPaper ID: N/A\nCommunity:22"}, {"color": "#bcff00", "id": "Maxime Bouthors", "label": "Maxime Bouthors", "shape": "dot", "title": "Node: Maxime Bouthors\nPaper ID: N/A\nCommunity:22"}, {"color": "#bcff00", "id": "Josep Crego", "label": "Josep Crego", "shape": "dot", "title": "Node: Josep Crego\nPaper ID: N/A\nCommunity:22"}, {"color": "#bcff00", "id": "Francois Yvon", "label": "Francois Yvon", "shape": "dot", "title": "Node: Francois Yvon\nPaper ID: N/A\nCommunity:22"}, {"color": "#adff00", "id": "Retrieval-Augmented Neural Machine Translation (RAMT)", "label": "Retrieval-Augmented Neural Machine Translation (RAMT)", "shape": "dot", "title": "Node: Retrieval-Augmented Neural Machine Translation (RAMT)\nPaper ID: N/A\nCommunity:23"}, {"color": "#adff00", "id": "Autoregressive model", "label": "Autoregressive model", "shape": "dot", "title": "Node: Autoregressive model\nPaper ID: N/A\nCommunity:23"}, {"color": "#adff00", "id": "Edit-based model", "label": "Edit-based model", "shape": "dot", "title": "Node: Edit-based model\nPaper ID: N/A\nCommunity:23"}, {"color": "#adff00", "id": "Large language model with in-context learning", "label": "Large language model with in-context learning", "shape": "dot", "title": "Node: Large language model with in-context learning\nPaper ID: N/A\nCommunity:23"}, {"color": "#c100ff", "id": "Financial Documents", "label": "Financial Documents", "shape": "dot", "title": "Node: Financial Documents\nPaper ID: N/A\nCommunity:83"}, {"color": "#9fff00", "id": "Spurthi Setty", "label": "Spurthi Setty", "shape": "dot", "title": "Node: Spurthi Setty\nPaper ID: N/A\nCommunity:24"}, {"color": "#9fff00", "id": "Harsh Thakkar", "label": "Harsh Thakkar", "shape": "dot", "title": "Node: Harsh Thakkar\nPaper ID: N/A\nCommunity:24"}, {"color": "#90ff00", "id": "Patrice B\u00e8chard", "label": "Patrice B\u00e8chard", "shape": "dot", "title": "Node: Patrice B\u00e8chard\nPaper ID: N/A\nCommunity:25"}, {"color": "#90ff00", "id": "Orlando Marquez Ayala", "label": "Orlando Marquez Ayala", "shape": "dot", "title": "Node: Orlando Marquez Ayala\nPaper ID: N/A\nCommunity:25"}, {"color": "#ff008c", "id": "Hallucination", "label": "Hallucination", "shape": "dot", "title": "Node: Hallucination\nPaper ID: N/A\nCommunity:95"}, {"color": "#ff009b", "id": "Structured Output", "label": "Structured Output", "shape": "dot", "title": "Node: Structured Output\nPaper ID: N/A\nCommunity:94"}, {"color": "#81ff00", "id": "Yizheng Huang", "label": "Yizheng Huang", "shape": "dot", "title": "Node: Yizheng Huang\nPaper ID: N/A\nCommunity:26"}, {"color": "#81ff00", "id": "Jimmy Huang", "label": "Jimmy Huang", "shape": "dot", "title": "Node: Jimmy Huang\nPaper ID: N/A\nCommunity:26"}, {"color": "#5b00ff", "id": "Text Domain", "label": "Text Domain", "shape": "dot", "title": "Node: Text Domain\nPaper ID: N/A\nCommunity:76"}, {"color": "#ff00b8", "id": "RAGCache", "label": "RAGCache", "shape": "dot", "title": "Node: RAGCache\nPaper ID: N/A\nCommunity:92"}, {"color": "#ff00b8", "id": "External Knowledge Databases", "label": "External Knowledge Databases", "shape": "dot", "title": "Node: External Knowledge Databases\nPaper ID: N/A\nCommunity:92"}, {"color": "#73ff00", "id": "vLLM", "label": "vLLM", "shape": "dot", "title": "Node: vLLM\nPaper ID: N/A\nCommunity:27"}, {"color": "#73ff00", "id": "Faiss", "label": "Faiss", "shape": "dot", "title": "Node: Faiss\nPaper ID: N/A\nCommunity:27"}, {"color": "#ff0035", "id": "RAU", "label": "RAU", "shape": "dot", "title": "Node: RAU\nPaper ID: N/A\nCommunity:101"}, {"color": "#ffa000", "id": "Retrieval-Augmented Language Models", "label": "Retrieval-Augmented Language Models", "shape": "dot", "title": "Node: Retrieval-Augmented Language Models\nPaper ID: N/A\nCommunity:11"}, {"color": "#ffa000", "id": "Language Models", "label": "Language Models", "shape": "dot", "title": "Node: Language Models\nPaper ID: N/A\nCommunity:11"}, {"color": "#ffa000", "id": "Augmentations", "label": "Augmentations", "shape": "dot", "title": "Node: Augmentations\nPaper ID: N/A\nCommunity:11"}, {"color": "#64ff00", "id": "Alireza Salemi", "label": "Alireza Salemi", "shape": "dot", "title": "Node: Alireza Salemi\nPaper ID: N/A\nCommunity:28"}, {"color": "#64ff00", "id": "Hamed Zamani", "label": "Hamed Zamani", "shape": "dot", "title": "Node: Hamed Zamani\nPaper ID: N/A\nCommunity:28"}, {"color": "#ff0017", "id": "uRAG", "label": "uRAG", "shape": "dot", "title": "Node: uRAG\nPaper ID: N/A\nCommunity:103"}, {"color": "#ff0017", "id": "Search Engine", "label": "Search Engine", "shape": "dot", "title": "Node: Search Engine\nPaper ID: N/A\nCommunity:103"}, {"color": "#55ff00", "id": "GAIA", "label": "GAIA", "shape": "dot", "title": "Node: GAIA\nPaper ID: N/A\nCommunity:29"}, {"color": "#55ff00", "id": "Particle Accelerators", "label": "Particle Accelerators", "shape": "dot", "title": "Node: Particle Accelerators\nPaper ID: N/A\nCommunity:29"}, {"color": "#55ff00", "id": "Frank Mayet", "label": "Frank Mayet", "shape": "dot", "title": "Node: Frank Mayet\nPaper ID: N/A\nCommunity:29"}, {"color": "#55ff00", "id": "Operators", "label": "Operators", "shape": "dot", "title": "Node: Operators\nPaper ID: N/A\nCommunity:29"}, {"color": "#de00ff", "id": "ReAct", "label": "ReAct", "shape": "dot", "title": "Node: ReAct\nPaper ID: N/A\nCommunity:85"}, {"color": "#de00ff", "id": "LLM", "label": "LLM", "shape": "dot", "title": "Node: LLM\nPaper ID: N/A\nCommunity:85"}, {"color": "#55ff00", "id": "RAG System", "label": "RAG System", "shape": "dot", "title": "Node: RAG System\nPaper ID: N/A\nCommunity:29"}, {"color": "#0028ff", "id": "Retrieval-Augmented Large Language Models", "label": "Retrieval-Augmented Large Language Models", "shape": "dot", "title": "Node: Retrieval-Augmented Large Language Models\nPaper ID: N/A\nCommunity:67"}, {"color": "#ff009b", "id": "Hao Yu", "label": "Hao Yu", "shape": "dot", "title": "Node: Hao Yu\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "Aoran Gan", "label": "Aoran Gan", "shape": "dot", "title": "Node: Aoran Gan\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "Kai Zhang", "label": "Kai Zhang", "shape": "dot", "title": "Node: Kai Zhang\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "Shiwei Tong", "label": "Shiwei Tong", "shape": "dot", "title": "Node: Shiwei Tong\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "Qi Liu", "label": "Qi Liu", "shape": "dot", "title": "Node: Qi Liu\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "Zhaofeng Liu", "label": "Zhaofeng Liu", "shape": "dot", "title": "Node: Zhaofeng Liu\nPaper ID: N/A\nCommunity:94"}, {"color": "#ff009b", "id": "A Unified Evaluation Process of RAG", "label": "A Unified Evaluation Process of RAG", "shape": "dot", "title": "Node: A Unified Evaluation Process of RAG\nPaper ID: N/A\nCommunity:94"}, {"color": "#47ff00", "id": "Vatsal Raina", "label": "Vatsal Raina", "shape": "dot", "title": "Node: Vatsal Raina\nPaper ID: N/A\nCommunity:30"}, {"color": "#47ff00", "id": "Mark Gales", "label": "Mark Gales", "shape": "dot", "title": "Node: Mark Gales\nPaper ID: N/A\nCommunity:30"}, {"color": "#f800fb", "id": "Enterprise retrieval augmented generation (RAG)", "label": "Enterprise retrieval augmented generation (RAG)", "shape": "dot", "title": "Node: Enterprise retrieval augmented generation (RAG)\nPaper ID: N/A\nCommunity:87"}, {"color": "#38ff00", "id": "Documents", "label": "Documents", "shape": "dot", "title": "Node: Documents\nPaper ID: N/A\nCommunity:31"}, {"color": "#38ff00", "id": "Synthesizer LLM", "label": "Synthesizer LLM", "shape": "dot", "title": "Node: Synthesizer LLM\nPaper ID: N/A\nCommunity:31"}, {"color": "#2aff00", "id": "Atomic statements", "label": "Atomic statements", "shape": "dot", "title": "Node: Atomic statements\nPaper ID: N/A\nCommunity:32"}, {"color": "#2aff00", "id": "Dense retrieval", "label": "Dense retrieval", "shape": "dot", "title": "Node: Dense retrieval\nPaper ID: N/A\nCommunity:32"}, {"color": "#2aff00", "id": "User query", "label": "User query", "shape": "dot", "title": "Node: User query\nPaper ID: N/A\nCommunity:32"}, {"color": "#ff007e", "id": "DuetRAG", "label": "DuetRAG", "shape": "dot", "title": "Node: DuetRAG\nPaper ID: N/A\nCommunity:96"}, {"color": "#ff007e", "id": "HotPot QA", "label": "HotPot QA", "shape": "dot", "title": "Node: HotPot QA\nPaper ID: N/A\nCommunity:96"}, {"color": "#0019ff", "id": "FlashRAG", "label": "FlashRAG", "shape": "dot", "title": "Node: FlashRAG\nPaper ID: N/A\nCommunity:68"}, {"color": "#0019ff", "id": "Jiajie Jin", "label": "Jiajie Jin", "shape": "dot", "title": "Node: Jiajie Jin\nPaper ID: N/A\nCommunity:68"}, {"color": "#0019ff", "id": "Yutao Zhu", "label": "Yutao Zhu", "shape": "dot", "title": "Node: Yutao Zhu\nPaper ID: N/A\nCommunity:68"}, {"color": "#0019ff", "id": "Xinyu Yang", "label": "Xinyu Yang", "shape": "dot", "title": "Node: Xinyu Yang\nPaper ID: N/A\nCommunity:68"}, {"color": "#0019ff", "id": "Chenghao Zhang", "label": "Chenghao Zhang", "shape": "dot", "title": "Node: Chenghao Zhang\nPaper ID: N/A\nCommunity:68"}, {"color": "#0028ff", "id": "Zhicheng Dou", "label": "Zhicheng Dou", "shape": "dot", "title": "Node: Zhicheng Dou\nPaper ID: N/A\nCommunity:67"}, {"color": "#00ffdd", "id": "Sparse RAG", "label": "Sparse RAG", "shape": "dot", "title": "Node: Sparse RAG\nPaper ID: N/A\nCommunity:50"}, {"color": "#00ffdd", "id": "Large language models (LLMs)", "label": "Large language models (LLMs)", "shape": "dot", "title": "Node: Large language models (LLMs)\nPaper ID: N/A\nCommunity:50"}, {"color": "#00ffdd", "id": "Retrieved documents", "label": "Retrieved documents", "shape": "dot", "title": "Node: Retrieved documents\nPaper ID: N/A\nCommunity:50"}, {"color": "#00ffdd", "id": "Control tokens", "label": "Control tokens", "shape": "dot", "title": "Node: Control tokens\nPaper ID: N/A\nCommunity:50"}, {"color": "#0045ff", "id": "M-RAG", "label": "M-RAG", "shape": "dot", "title": "Node: M-RAG\nPaper ID: N/A\nCommunity:65"}, {"color": "#0045ff", "id": "Multi-Agent Reinforcement Learning", "label": "Multi-Agent Reinforcement Learning", "shape": "dot", "title": "Node: Multi-Agent Reinforcement Learning\nPaper ID: N/A\nCommunity:65"}, {"color": "#0045ff", "id": "Zheng Wang", "label": "Zheng Wang", "shape": "dot", "title": "Node: Zheng Wang\nPaper ID: N/A\nCommunity:65"}, {"color": "#0045ff", "id": "Shu Xian Teo", "label": "Shu Xian Teo", "shape": "dot", "title": "Node: Shu Xian Teo\nPaper ID: N/A\nCommunity:65"}, {"color": "#0045ff", "id": "Jieer Ouyang", "label": "Jieer Ouyang", "shape": "dot", "title": "Node: Jieer Ouyang\nPaper ID: N/A\nCommunity:65"}, {"color": "#0045ff", "id": "Yongjun Xu", "label": "Yongjun Xu", "shape": "dot", "title": "Node: Yongjun Xu\nPaper ID: N/A\nCommunity:65"}, {"color": "#0045ff", "id": "Wei Shi", "label": "Wei Shi", "shape": "dot", "title": "Node: Wei Shi\nPaper ID: N/A\nCommunity:65"}, {"color": "#2000ff", "id": "Sudeshna Das", "label": "Sudeshna Das", "shape": "dot", "title": "Node: Sudeshna Das\nPaper ID: N/A\nCommunity:72"}, {"color": "#2000ff", "id": "Generative Large Language Model (LLM)", "label": "Generative Large Language Model (LLM)", "shape": "dot", "title": "Node: Generative Large Language Model (LLM)\nPaper ID: N/A\nCommunity:72"}, {"color": "#1bff00", "id": "Reddit", "label": "Reddit", "shape": "dot", "title": "Node: Reddit\nPaper ID: N/A\nCommunity:33"}, {"color": "#1bff00", "id": "Social media forums", "label": "Social media forums", "shape": "dot", "title": "Node: Social media forums\nPaper ID: N/A\nCommunity:33"}, {"color": "#1bff00", "id": "Emerging drug-related information", "label": "Emerging drug-related information", "shape": "dot", "title": "Node: Emerging drug-related information\nPaper ID: N/A\nCommunity:33"}, {"color": "#0028ff", "id": "Zhaoheng Huang", "label": "Zhaoheng Huang", "shape": "dot", "title": "Node: Zhaoheng Huang\nPaper ID: N/A\nCommunity:67"}, {"color": "#0028ff", "id": "Ji-Rong Wen", "label": "Ji-Rong Wen", "shape": "dot", "title": "Node: Ji-Rong Wen\nPaper ID: N/A\nCommunity:67"}, {"color": "#ff009b", "id": "Virtual Tokens", "label": "Virtual Tokens", "shape": "dot", "title": "Node: Virtual Tokens\nPaper ID: N/A\nCommunity:94"}, {"color": "#5b00ff", "id": "Wei Tang", "label": "Wei Tang", "shape": "dot", "title": "Node: Wei Tang\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Yixin Cao", "label": "Yixin Cao", "shape": "dot", "title": "Node: Yixin Cao\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Jiahao Ying", "label": "Jiahao Ying", "shape": "dot", "title": "Node: Jiahao Ying\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Bo Wang", "label": "Bo Wang", "shape": "dot", "title": "Node: Bo Wang\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Yuyue Zhao", "label": "Yuyue Zhao", "shape": "dot", "title": "Node: Yuyue Zhao\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Yong Liao", "label": "Yong Liao", "shape": "dot", "title": "Node: Yong Liao\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Pengyuan Zhou", "label": "Pengyuan Zhou", "shape": "dot", "title": "Node: Pengyuan Zhou\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "A + B framework", "label": "A + B framework", "shape": "dot", "title": "Node: A + B framework\nPaper ID: N/A\nCommunity:76"}, {"color": "#2f00ff", "id": "Multi-Head RAG", "label": "Multi-Head RAG", "shape": "dot", "title": "Node: Multi-Head RAG\nPaper ID: N/A\nCommunity:73"}, {"color": "#2f00ff", "id": "Transformer", "label": "Transformer", "shape": "dot", "title": "Node: Transformer\nPaper ID: N/A\nCommunity:73"}, {"color": "#f800fb", "id": "DR-RAG", "label": "DR-RAG", "shape": "dot", "title": "Node: DR-RAG\nPaper ID: N/A\nCommunity:87"}, {"color": "#5b00ff", "id": "Question-Answering (QA)", "label": "Question-Answering (QA)", "shape": "dot", "title": "Node: Question-Answering (QA)\nPaper ID: N/A\nCommunity:76"}, {"color": "#0cff00", "id": "Zijian Hei", "label": "Zijian Hei", "shape": "dot", "title": "Node: Zijian Hei\nPaper ID: N/A\nCommunity:34"}, {"color": "#0cff00", "id": "Weiling Liu", "label": "Weiling Liu", "shape": "dot", "title": "Node: Weiling Liu\nPaper ID: N/A\nCommunity:34"}, {"color": "#04ff06", "id": "Scott Barnett", "label": "Scott Barnett", "shape": "dot", "title": "Node: Scott Barnett\nPaper ID: N/A\nCommunity:35"}, {"color": "#04ff06", "id": "Zac Brannelly", "label": "Zac Brannelly", "shape": "dot", "title": "Node: Zac Brannelly\nPaper ID: N/A\nCommunity:35"}, {"color": "#00ff10", "id": "Stefanus Kurniawan", "label": "Stefanus Kurniawan", "shape": "dot", "title": "Node: Stefanus Kurniawan\nPaper ID: N/A\nCommunity:36"}, {"color": "#00ff10", "id": "Sheng Wong", "label": "Sheng Wong", "shape": "dot", "title": "Node: Sheng Wong\nPaper ID: N/A\nCommunity:36"}, {"color": "#00ff1f", "id": "Gautam B", "label": "Gautam B", "shape": "dot", "title": "Node: Gautam B\nPaper ID: N/A\nCommunity:37"}, {"color": "#00ff1f", "id": "Anupam Purwar", "label": "Anupam Purwar", "shape": "dot", "title": "Node: Anupam Purwar\nPaper ID: N/A\nCommunity:37"}, {"color": "#00ff2d", "id": "Open-Source LLMs", "label": "Open-Source LLMs", "shape": "dot", "title": "Node: Open-Source LLMs\nPaper ID: N/A\nCommunity:38"}, {"color": "#00ff2d", "id": "Enterprise-Specific RAG Systems", "label": "Enterprise-Specific RAG Systems", "shape": "dot", "title": "Node: Enterprise-Specific RAG Systems\nPaper ID: N/A\nCommunity:38"}, {"color": "#5b00ff", "id": "Natural Language Processing", "label": "Natural Language Processing", "shape": "dot", "title": "Node: Natural Language Processing\nPaper ID: N/A\nCommunity:76"}, {"color": "#00ff3c", "id": "Antonin Sulc", "label": "Antonin Sulc", "shape": "dot", "title": "Node: Antonin Sulc\nPaper ID: N/A\nCommunity:39"}, {"color": "#00ff3c", "id": "Retrieval Augmented Generation (RAG) model", "label": "Retrieval Augmented Generation (RAG) model", "shape": "dot", "title": "Node: Retrieval Augmented Generation (RAG) model\nPaper ID: N/A\nCommunity:39"}, {"color": "#00ff4a", "id": "DESY", "label": "DESY", "shape": "dot", "title": "Node: DESY\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "Logbooks", "label": "Logbooks", "shape": "dot", "title": "Node: Logbooks\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "BESSY", "label": "BESSY", "shape": "dot", "title": "Node: BESSY\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "Fermilab", "label": "Fermilab", "shape": "dot", "title": "Node: Fermilab\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "BNL", "label": "BNL", "shape": "dot", "title": "Node: BNL\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "SLAC", "label": "SLAC", "shape": "dot", "title": "Node: SLAC\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "LBNL", "label": "LBNL", "shape": "dot", "title": "Node: LBNL\nPaper ID: N/A\nCommunity:40"}, {"color": "#00ff4a", "id": "CERN", "label": "CERN", "shape": "dot", "title": "Node: CERN\nPaper ID: N/A\nCommunity:40"}, {"color": "##28282B", "id": "Multi-Meta-RAG", "label": "Multi-Meta-RAG", "shape": "dot", "title": "Node: Multi-Meta-RAG\nPaper ID: N/A\nCommunity:108"}, {"color": "##28282B", "id": "MultiHop-RAG", "label": "MultiHop-RAG", "shape": "dot", "title": "Node: MultiHop-RAG\nPaper ID: N/A\nCommunity:108"}, {"color": "#00ff59", "id": "Mykhailo Poliakov", "label": "Mykhailo Poliakov", "shape": "dot", "title": "Node: Mykhailo Poliakov\nPaper ID: N/A\nCommunity:41"}, {"color": "#00ff59", "id": "Nadiya Shvai", "label": "Nadiya Shvai", "shape": "dot", "title": "Node: Nadiya Shvai\nPaper ID: N/A\nCommunity:41"}, {"color": "#ffa000", "id": "R^2AG", "label": "R^2AG", "shape": "dot", "title": "Node: R^2AG\nPaper ID: N/A\nCommunity:11"}, {"color": "#0602ff", "id": "Florin Cuconasu", "label": "Florin Cuconasu", "shape": "dot", "title": "Node: Florin Cuconasu\nPaper ID: N/A\nCommunity:70"}, {"color": "#0602ff", "id": "Giovanni Trappolini", "label": "Giovanni Trappolini", "shape": "dot", "title": "Node: Giovanni Trappolini\nPaper ID: N/A\nCommunity:70"}, {"color": "#0602ff", "id": "Nicola Tonellotto", "label": "Nicola Tonellotto", "shape": "dot", "title": "Node: Nicola Tonellotto\nPaper ID: N/A\nCommunity:70"}, {"color": "#0602ff", "id": "Fabrizio Silvestri", "label": "Fabrizio Silvestri", "shape": "dot", "title": "Node: Fabrizio Silvestri\nPaper ID: N/A\nCommunity:70"}, {"color": "#00ff68", "id": "Fromm", "label": "Fromm", "shape": "dot", "title": "Node: Fromm\nPaper ID: N/A\nCommunity:42"}, {"color": "#00ff68", "id": "Quote", "label": "Quote", "shape": "dot", "title": "Node: Quote\nPaper ID: N/A\nCommunity:42"}, {"color": "#00ff76", "id": "Base models", "label": "Base models", "shape": "dot", "title": "Node: Base models\nPaper ID: N/A\nCommunity:43"}, {"color": "#00ff76", "id": "Instructed LLMs", "label": "Instructed LLMs", "shape": "dot", "title": "Node: Instructed LLMs\nPaper ID: N/A\nCommunity:43"}, {"color": "#d000ff", "id": "FS-RAG", "label": "FS-RAG", "shape": "dot", "title": "Node: FS-RAG\nPaper ID: N/A\nCommunity:84"}, {"color": "#d000ff", "id": "Harish Tayyar Madabushi", "label": "Harish Tayyar Madabushi", "shape": "dot", "title": "Node: Harish Tayyar Madabushi\nPaper ID: N/A\nCommunity:84"}, {"color": "#d000ff", "id": "Frame Semantics", "label": "Frame Semantics", "shape": "dot", "title": "Node: Frame Semantics\nPaper ID: N/A\nCommunity:84"}, {"color": "#00ff85", "id": "Ragnar ok", "label": "Ragnar ok", "shape": "dot", "title": "Node: Ragnar ok\nPaper ID: N/A\nCommunity:44"}, {"color": "#00ff85", "id": "TREC 2024 RAG Track", "label": "TREC 2024 RAG Track", "shape": "dot", "title": "Node: TREC 2024 RAG Track\nPaper ID: N/A\nCommunity:44"}, {"color": "#00ff85", "id": "MS MARCO V2.1", "label": "MS MARCO V2.1", "shape": "dot", "title": "Node: MS MARCO V2.1\nPaper ID: N/A\nCommunity:44"}, {"color": "#00ff85", "id": "OpenAI\u0027s GPT-4o", "label": "OpenAI\u0027s GPT-4o", "shape": "dot", "title": "Node: OpenAI\u0027s GPT-4o\nPaper ID: N/A\nCommunity:44"}, {"color": "#00ff85", "id": "Cohere\u0027s Command R+", "label": "Cohere\u0027s Command R+", "shape": "dot", "title": "Node: Cohere\u0027s Command R+\nPaper ID: N/A\nCommunity:44"}, {"color": "#de00ff", "id": "RICHES", "label": "RICHES", "shape": "dot", "title": "Node: RICHES\nPaper ID: N/A\nCommunity:85"}, {"color": "#de00ff", "id": "ODQA", "label": "ODQA", "shape": "dot", "title": "Node: ODQA\nPaper ID: N/A\nCommunity:85"}, {"color": "#ff0052", "id": "BERGEN", "label": "BERGEN", "shape": "dot", "title": "Node: BERGEN\nPaper ID: N/A\nCommunity:99"}, {"color": "#ff0052", "id": "David Rau", "label": "David Rau", "shape": "dot", "title": "Node: David Rau\nPaper ID: N/A\nCommunity:99"}, {"color": "#5b00ff", "id": "Xiaohua Wang", "label": "Xiaohua Wang", "shape": "dot", "title": "Node: Xiaohua Wang\nPaper ID: N/A\nCommunity:76"}, {"color": "#0062ff", "id": "Query-Dependent Retrievals", "label": "Query-Dependent Retrievals", "shape": "dot", "title": "Node: Query-Dependent Retrievals\nPaper ID: N/A\nCommunity:63"}, {"color": "#00ff94", "id": "Multimodal Retrieval Techniques", "label": "Multimodal Retrieval Techniques", "shape": "dot", "title": "Node: Multimodal Retrieval Techniques\nPaper ID: N/A\nCommunity:45"}, {"color": "#00ff94", "id": "Question-Answering Capabilities", "label": "Question-Answering Capabilities", "shape": "dot", "title": "Node: Question-Answering Capabilities\nPaper ID: N/A\nCommunity:45"}, {"color": "#00ffa2", "id": "Visual Inputs", "label": "Visual Inputs", "shape": "dot", "title": "Node: Visual Inputs\nPaper ID: N/A\nCommunity:46"}, {"color": "#00ffa2", "id": "Multimodal Content", "label": "Multimodal Content", "shape": "dot", "title": "Node: Multimodal Content\nPaper ID: N/A\nCommunity:46"}, {"color": "#0062ff", "id": "Meta-prompting Optimized Retrieval-augmented Generation", "label": "Meta-prompting Optimized Retrieval-augmented Generation", "shape": "dot", "title": "Node: Meta-prompting Optimized Retrieval-augmented Generation\nPaper ID: N/A\nCommunity:63"}, {"color": "#0062ff", "id": "StrategyQA dataset", "label": "StrategyQA dataset", "shape": "dot", "title": "Node: StrategyQA dataset\nPaper ID: N/A\nCommunity:63"}, {"color": "#3e00ff", "id": "Speculative RAG", "label": "Speculative RAG", "shape": "dot", "title": "Node: Speculative RAG\nPaper ID: N/A\nCommunity:74"}, {"color": "#3e00ff", "id": "TrivaQA", "label": "TrivaQA", "shape": "dot", "title": "Node: TrivaQA\nPaper ID: N/A\nCommunity:74"}, {"color": "#ff0043", "id": "RAGBench", "label": "RAGBench", "shape": "dot", "title": "Node: RAGBench\nPaper ID: N/A\nCommunity:100"}, {"color": "#ff0043", "id": "TRACe", "label": "TRACe", "shape": "dot", "title": "Node: TRACe\nPaper ID: N/A\nCommunity:100"}, {"color": "#ff0043", "id": "RoBERTa", "label": "RoBERTa", "shape": "dot", "title": "Node: RoBERTa\nPaper ID: N/A\nCommunity:100"}, {"color": "#00ffb1", "id": "NinjaLLM", "label": "NinjaLLM", "shape": "dot", "title": "Node: NinjaLLM\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffb1", "id": "AWS Trainium", "label": "AWS Trainium", "shape": "dot", "title": "Node: AWS Trainium\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffb1", "id": "Inferentia2", "label": "Inferentia2", "shape": "dot", "title": "Node: Inferentia2\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffb1", "id": "SageMaker", "label": "SageMaker", "shape": "dot", "title": "Node: SageMaker\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffb1", "id": "Tengfei Xue", "label": "Tengfei Xue", "shape": "dot", "title": "Node: Tengfei Xue\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffb1", "id": "Natural Questions", "label": "Natural Questions", "shape": "dot", "title": "Node: Natural Questions\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffb1", "id": "HotPotQA", "label": "HotPotQA", "shape": "dot", "title": "Node: HotPotQA\nPaper ID: N/A\nCommunity:47"}, {"color": "#00ffdd", "id": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "label": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "shape": "dot", "title": "Node: Retrieval-Augmented Generation for Natural Language Processing: A Survey\nPaper ID: N/A\nCommunity:50"}, {"color": "#00ffdd", "id": "Retrieval-augmented generation (RAG)", "label": "Retrieval-augmented generation (RAG)", "shape": "dot", "title": "Node: Retrieval-augmented generation (RAG)\nPaper ID: N/A\nCommunity:50"}, {"color": "#00ffdd", "id": "Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue", "label": "Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue", "shape": "dot", "title": "Node: Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue\nPaper ID: N/A\nCommunity:50"}, {"color": "#c100ff", "id": "Document-Grounded Question-Answering", "label": "Document-Grounded Question-Answering", "shape": "dot", "title": "Node: Document-Grounded Question-Answering\nPaper ID: N/A\nCommunity:83"}, {"color": "#c100ff", "id": "Electronic Design Automation", "label": "Electronic Design Automation", "shape": "dot", "title": "Node: Electronic Design Automation\nPaper ID: N/A\nCommunity:83"}, {"color": "#00ffbf", "id": "OpenROAD", "label": "OpenROAD", "shape": "dot", "title": "Node: OpenROAD\nPaper ID: N/A\nCommunity:48"}, {"color": "#00ffbf", "id": "ORD-QA", "label": "ORD-QA", "shape": "dot", "title": "Node: ORD-QA\nPaper ID: N/A\nCommunity:48"}, {"color": "#f800fb", "id": "Gemini-1.5", "label": "Gemini-1.5", "shape": "dot", "title": "Node: Gemini-1.5\nPaper ID: N/A\nCommunity:87"}, {"color": "#f800fb", "id": "GPT-4", "label": "GPT-4", "shape": "dot", "title": "Node: GPT-4\nPaper ID: N/A\nCommunity:87"}, {"color": "#c100ff", "id": "Self-Route", "label": "Self-Route", "shape": "dot", "title": "Node: Self-Route\nPaper ID: N/A\nCommunity:83"}, {"color": "#00ff1f", "id": "Kush Juvekar", "label": "Kush Juvekar", "shape": "dot", "title": "Node: Kush Juvekar\nPaper ID: N/A\nCommunity:37"}, {"color": "#5b00ff", "id": "Context Window Utilization", "label": "Context Window Utilization", "shape": "dot", "title": "Node: Context Window Utilization\nPaper ID: N/A\nCommunity:76"}, {"color": "#00ffce", "id": "RAG systems", "label": "RAG systems", "shape": "dot", "title": "Node: RAG systems\nPaper ID: N/A\nCommunity:49"}, {"color": "#00ffce", "id": "External knowledge bases", "label": "External knowledge bases", "shape": "dot", "title": "Node: External knowledge bases\nPaper ID: N/A\nCommunity:49"}, {"color": "#f800fb", "id": "Bailicai", "label": "Bailicai", "shape": "dot", "title": "Node: Bailicai\nPaper ID: N/A\nCommunity:87"}, {"color": "#f800fb", "id": "GPT-3.5", "label": "GPT-3.5", "shape": "dot", "title": "Node: GPT-3.5\nPaper ID: N/A\nCommunity:87"}, {"color": "##28282B", "id": "Modular RAG", "label": "Modular RAG", "shape": "dot", "title": "Node: Modular RAG\nPaper ID: N/A\nCommunity:104"}, {"color": "##28282B", "id": "Yunfan Gao", "label": "Yunfan Gao", "shape": "dot", "title": "Node: Yunfan Gao\nPaper ID: N/A\nCommunity:104"}, {"color": "#ff0035", "id": "RAGEval", "label": "RAGEval", "shape": "dot", "title": "Node: RAGEval\nPaper ID: N/A\nCommunity:101"}, {"color": "#ff0035", "id": "Kunlun Zhu", "label": "Kunlun Zhu", "shape": "dot", "title": "Node: Kunlun Zhu\nPaper ID: N/A\nCommunity:101"}, {"color": "#ffbe00", "id": "RAG Foundry", "label": "RAG Foundry", "shape": "dot", "title": "Node: RAG Foundry\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Daniel Fleischer", "label": "Daniel Fleischer", "shape": "dot", "title": "Node: Daniel Fleischer\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Moshe Berchansky", "label": "Moshe Berchansky", "shape": "dot", "title": "Node: Moshe Berchansky\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Moshe Wasserblat", "label": "Moshe Wasserblat", "shape": "dot", "title": "Node: Moshe Wasserblat\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Peter Izsak", "label": "Peter Izsak", "shape": "dot", "title": "Node: Peter Izsak\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Llama-3", "label": "Llama-3", "shape": "dot", "title": "Node: Llama-3\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Phi-3", "label": "Phi-3", "shape": "dot", "title": "Node: Phi-3\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "IntelLabs", "label": "IntelLabs", "shape": "dot", "title": "Node: IntelLabs\nPaper ID: N/A\nCommunity:13"}, {"color": "#00ffdd", "id": "EfficientRAG", "label": "EfficientRAG", "shape": "dot", "title": "Node: EfficientRAG\nPaper ID: N/A\nCommunity:50"}, {"color": "#00ffdd", "id": "Multi-hop question-answering datasets", "label": "Multi-hop question-answering datasets", "shape": "dot", "title": "Node: Multi-hop question-answering datasets\nPaper ID: N/A\nCommunity:50"}, {"color": "#fd00f1", "id": "Hybrid RAG System", "label": "Hybrid RAG System", "shape": "dot", "title": "Node: Hybrid RAG System\nPaper ID: N/A\nCommunity:88"}, {"color": "#fd00f1", "id": "CRAG Dataset", "label": "CRAG Dataset", "shape": "dot", "title": "Node: CRAG Dataset\nPaper ID: N/A\nCommunity:88"}, {"color": "#fd00f1", "id": "Shizueyy", "label": "Shizueyy", "shape": "dot", "title": "Node: Shizueyy\nPaper ID: N/A\nCommunity:88"}, {"color": "#00ffeb", "id": "Samhaa R. El-Beltagy", "label": "Samhaa R. El-Beltagy", "shape": "dot", "title": "Node: Samhaa R. El-Beltagy\nPaper ID: N/A\nCommunity:51"}, {"color": "#00ffeb", "id": "Mohamed A. Abdallah", "label": "Mohamed A. Abdallah", "shape": "dot", "title": "Node: Mohamed A. Abdallah\nPaper ID: N/A\nCommunity:51"}, {"color": "#0602ff", "id": "Arabic", "label": "Arabic", "shape": "dot", "title": "Node: Arabic\nPaper ID: N/A\nCommunity:70"}, {"color": "#0602ff", "id": "Semantic embedding models", "label": "Semantic embedding models", "shape": "dot", "title": "Node: Semantic embedding models\nPaper ID: N/A\nCommunity:70"}, {"color": "#0602ff", "id": "LLMs (Large Language Models)", "label": "LLMs (Large Language Models)", "shape": "dot", "title": "Node: LLMs (Large Language Models)\nPaper ID: N/A\nCommunity:70"}, {"color": "#a400ff", "id": "RAGChecker", "label": "RAGChecker", "shape": "dot", "title": "Node: RAGChecker\nPaper ID: N/A\nCommunity:81"}, {"color": "#a400ff", "id": "Dongyu Ru", "label": "Dongyu Ru", "shape": "dot", "title": "Node: Dongyu Ru\nPaper ID: N/A\nCommunity:81"}, {"color": "#a400ff", "id": "Amazon Science", "label": "Amazon Science", "shape": "dot", "title": "Node: Amazon Science\nPaper ID: N/A\nCommunity:81"}, {"color": "#0062ff", "id": "Graph Retrieval-Augmented Generation", "label": "Graph Retrieval-Augmented Generation", "shape": "dot", "title": "Node: Graph Retrieval-Augmented Generation\nPaper ID: N/A\nCommunity:63"}, {"color": "#ff006f", "id": "GraphRAG", "label": "GraphRAG", "shape": "dot", "title": "Node: GraphRAG\nPaper ID: N/A\nCommunity:97"}, {"color": "#ff006f", "id": "Boci Peng", "label": "Boci Peng", "shape": "dot", "title": "Node: Boci Peng\nPaper ID: N/A\nCommunity:97"}, {"color": "#ff00e4", "id": "RAG Noise", "label": "RAG Noise", "shape": "dot", "title": "Node: RAG Noise\nPaper ID: N/A\nCommunity:89"}, {"color": "#00fffa", "id": "Jinyang Wu", "label": "Jinyang Wu", "shape": "dot", "title": "Node: Jinyang Wu\nPaper ID: N/A\nCommunity:52"}, {"color": "#00fffa", "id": "Pandora\u0027s Box", "label": "Pandora\u0027s Box", "shape": "dot", "title": "Node: Pandora\u0027s Box\nPaper ID: N/A\nCommunity:52"}, {"color": "#00fffa", "id": "Aladdin\u0027s Lamp", "label": "Aladdin\u0027s Lamp", "shape": "dot", "title": "Node: Aladdin\u0027s Lamp\nPaper ID: N/A\nCommunity:52"}, {"color": "#ff00e4", "id": "Noise RAG Benchmark (NoiserBench)", "label": "Noise RAG Benchmark (NoiserBench)", "shape": "dot", "title": "Node: Noise RAG Benchmark (NoiserBench)\nPaper ID: N/A\nCommunity:89"}, {"color": "#ff0026", "id": "OP-RAG", "label": "OP-RAG", "shape": "dot", "title": "Node: OP-RAG\nPaper ID: N/A\nCommunity:102"}, {"color": "#00f5ff", "id": "Tan Yu", "label": "Tan Yu", "shape": "dot", "title": "Node: Tan Yu\nPaper ID: N/A\nCommunity:53"}, {"color": "#00f5ff", "id": "Anbang Xu", "label": "Anbang Xu", "shape": "dot", "title": "Node: Anbang Xu\nPaper ID: N/A\nCommunity:53"}, {"color": "#00f5ff", "id": "Rama Akkiraju", "label": "Rama Akkiraju", "shape": "dot", "title": "Node: Rama Akkiraju\nPaper ID: N/A\nCommunity:53"}, {"color": "#ed00ff", "id": "MARAGS", "label": "MARAGS", "shape": "dot", "title": "Node: MARAGS\nPaper ID: N/A\nCommunity:86"}, {"color": "#ed00ff", "id": "Meta\u0027s Comprehensive RAG (CRAG)", "label": "Meta\u0027s Comprehensive RAG (CRAG)", "shape": "dot", "title": "Node: Meta\u0027s Comprehensive RAG (CRAG)\nPaper ID: N/A\nCommunity:86"}, {"color": "#ed00ff", "id": "KDD CUP 2024", "label": "KDD CUP 2024", "shape": "dot", "title": "Node: KDD CUP 2024\nPaper ID: N/A\nCommunity:86"}, {"color": "#ed00ff", "id": "API endpoints", "label": "API endpoints", "shape": "dot", "title": "Node: API endpoints\nPaper ID: N/A\nCommunity:86"}, {"color": "##28282B", "id": "OneGen", "label": "OneGen", "shape": "dot", "title": "Node: OneGen\nPaper ID: N/A\nCommunity:109"}, {"color": "##28282B", "id": "Entity Linking", "label": "Entity Linking", "shape": "dot", "title": "Node: Entity Linking\nPaper ID: N/A\nCommunity:109"}, {"color": "#010cff", "id": "MemoRAG", "label": "MemoRAG", "shape": "dot", "title": "Node: MemoRAG\nPaper ID: N/A\nCommunity:69"}, {"color": "#010cff", "id": "Long-term memory", "label": "Long-term memory", "shape": "dot", "title": "Node: Long-term memory\nPaper ID: N/A\nCommunity:69"}, {"color": "#010cff", "id": "Hongjin Qian", "label": "Hongjin Qian", "shape": "dot", "title": "Node: Hongjin Qian\nPaper ID: N/A\nCommunity:69"}, {"color": "#010cff", "id": "Peitian Zhang", "label": "Peitian Zhang", "shape": "dot", "title": "Node: Peitian Zhang\nPaper ID: N/A\nCommunity:69"}, {"color": "#010cff", "id": "Zheng Liu", "label": "Zheng Liu", "shape": "dot", "title": "Node: Zheng Liu\nPaper ID: N/A\nCommunity:69"}, {"color": "#010cff", "id": "Kelong Mao", "label": "Kelong Mao", "shape": "dot", "title": "Node: Kelong Mao\nPaper ID: N/A\nCommunity:69"}, {"color": "#4c00ff", "id": "SFR-RAG", "label": "SFR-RAG", "shape": "dot", "title": "Node: SFR-RAG\nPaper ID: N/A\nCommunity:75"}, {"color": "#4c00ff", "id": "HotpotQA", "label": "HotpotQA", "shape": "dot", "title": "Node: HotpotQA\nPaper ID: N/A\nCommunity:75"}, {"color": "#4c00ff", "id": "TriviaQA", "label": "TriviaQA", "shape": "dot", "title": "Node: TriviaQA\nPaper ID: N/A\nCommunity:75"}, {"color": "#4c00ff", "id": "ContextualBench", "label": "ContextualBench", "shape": "dot", "title": "Node: ContextualBench\nPaper ID: N/A\nCommunity:75"}, {"color": "#00e6ff", "id": "SFR-RAG-9B", "label": "SFR-RAG-9B", "shape": "dot", "title": "Node: SFR-RAG-9B\nPaper ID: N/A\nCommunity:54"}, {"color": "#00e6ff", "id": "Command-R+ (104B)", "label": "Command-R+ (104B)", "shape": "dot", "title": "Node: Command-R+ (104B)\nPaper ID: N/A\nCommunity:54"}, {"color": "#00e6ff", "id": "GPT-4o", "label": "GPT-4o", "shape": "dot", "title": "Node: GPT-4o\nPaper ID: N/A\nCommunity:54"}, {"color": "##28282B", "id": "P-RAG", "label": "P-RAG", "shape": "dot", "title": "Node: P-RAG\nPaper ID: N/A\nCommunity:112"}, {"color": "##28282B", "id": "Embodied Everyday Task", "label": "Embodied Everyday Task", "shape": "dot", "title": "Node: Embodied Everyday Task\nPaper ID: N/A\nCommunity:112"}, {"color": "#00d7ff", "id": "Sourav Verma", "label": "Sourav Verma", "shape": "dot", "title": "Node: Sourav Verma\nPaper ID: N/A\nCommunity:55"}, {"color": "#00d7ff", "id": "Contextual Compression", "label": "Contextual Compression", "shape": "dot", "title": "Node: Contextual Compression\nPaper ID: N/A\nCommunity:55"}, {"color": "#7800ff", "id": "Shuo Yu", "label": "Shuo Yu", "shape": "dot", "title": "Node: Shuo Yu\nPaper ID: N/A\nCommunity:78"}, {"color": "#5b00ff", "id": "Mingyue Cheng", "label": "Mingyue Cheng", "shape": "dot", "title": "Node: Mingyue Cheng\nPaper ID: N/A\nCommunity:76"}, {"color": "#5b00ff", "id": "Jiqian Yang", "label": "Jiqian Yang", "shape": "dot", "title": "Node: Jiqian Yang\nPaper ID: N/A\nCommunity:76"}, {"color": "#b300ff", "id": "Jie Ouyang", "label": "Jie Ouyang", "shape": "dot", "title": "Node: Jie Ouyang\nPaper ID: N/A\nCommunity:82"}, {"color": "#7800ff", "id": "Anhui Province Key Laboratory of Big Data Analysis and Application", "label": "Anhui Province Key Laboratory of Big Data Analysis and Application", "shape": "dot", "title": "Node: Anhui Province Key Laboratory of Big Data Analysis and Application\nPaper ID: N/A\nCommunity:78"}, {"color": "#7800ff", "id": "University of Science and Technology of China", "label": "University of Science and Technology of China", "shape": "dot", "title": "Node: University of Science and Technology of China\nPaper ID: N/A\nCommunity:78"}, {"color": "#7800ff", "id": "State Key Laboratory of Cognitive Intelligence", "label": "State Key Laboratory of Cognitive Intelligence", "shape": "dot", "title": "Node: State Key Laboratory of Cognitive Intelligence\nPaper ID: N/A\nCommunity:78"}, {"color": "#b300ff", "id": "APEX", "label": "APEX", "shape": "dot", "title": "Node: APEX\nPaper ID: N/A\nCommunity:82"}, {"color": "#b300ff", "id": "Meta KDD Cup 2024", "label": "Meta KDD Cup 2024", "shape": "dot", "title": "Node: Meta KDD Cup 2024\nPaper ID: N/A\nCommunity:82"}, {"color": "#b300ff", "id": "CRAG", "label": "CRAG", "shape": "dot", "title": "Node: CRAG\nPaper ID: N/A\nCommunity:82"}, {"color": "#0036ff", "id": "GEM-RAG", "label": "GEM-RAG", "shape": "dot", "title": "Node: GEM-RAG\nPaper ID: N/A\nCommunity:66"}, {"color": "#0036ff", "id": "UnifiedQA", "label": "UnifiedQA", "shape": "dot", "title": "Node: UnifiedQA\nPaper ID: N/A\nCommunity:66"}, {"color": "#0036ff", "id": "GPT-3.5 Turbo", "label": "GPT-3.5 Turbo", "shape": "dot", "title": "Node: GPT-3.5 Turbo\nPaper ID: N/A\nCommunity:66"}, {"color": "#0036ff", "id": "SBERT", "label": "SBERT", "shape": "dot", "title": "Node: SBERT\nPaper ID: N/A\nCommunity:66"}, {"color": "#ff009b", "id": "FlexRAG (Flexible Context Adaptation for RAG)", "label": "FlexRAG (Flexible Context Adaptation for RAG)", "shape": "dot", "title": "Node: FlexRAG (Flexible Context Adaptation for RAG)\nPaper ID: N/A\nCommunity:94"}, {"color": "#00c9ff", "id": "RAFT", "label": "RAFT", "shape": "dot", "title": "Node: RAFT\nPaper ID: N/A\nCommunity:56"}, {"color": "#00c9ff", "id": "PEFT", "label": "PEFT", "shape": "dot", "title": "Node: PEFT\nPaper ID: N/A\nCommunity:56"}, {"color": "#00c9ff", "id": "LoRA", "label": "LoRA", "shape": "dot", "title": "Node: LoRA\nPaper ID: N/A\nCommunity:56"}, {"color": "#00baff", "id": "CRAFT", "label": "CRAFT", "shape": "dot", "title": "Node: CRAFT\nPaper ID: N/A\nCommunity:57"}, {"color": "#00baff", "id": "Question Answering", "label": "Question Answering", "shape": "dot", "title": "Node: Question Answering\nPaper ID: N/A\nCommunity:57"}, {"color": "#1200ff", "id": "BSharedRAG", "label": "BSharedRAG", "shape": "dot", "title": "Node: BSharedRAG\nPaper ID: N/A\nCommunity:71"}, {"color": "#1200ff", "id": "e-commerce", "label": "e-commerce", "shape": "dot", "title": "Node: e-commerce\nPaper ID: N/A\nCommunity:71"}, {"color": "#1200ff", "id": "Low-Rank Adaptation (LoRA)", "label": "Low-Rank Adaptation (LoRA)", "shape": "dot", "title": "Node: Low-Rank Adaptation (LoRA)\nPaper ID: N/A\nCommunity:71"}, {"color": "#1200ff", "id": "Kaisi Guan", "label": "Kaisi Guan", "shape": "dot", "title": "Node: Kaisi Guan\nPaper ID: N/A\nCommunity:71"}, {"color": "#00abff", "id": "Retro-li", "label": "Retro-li", "shape": "dot", "title": "Node: Retro-li\nPaper ID: N/A\nCommunity:58"}, {"color": "#00abff", "id": "Retro", "label": "Retro", "shape": "dot", "title": "Node: Retro\nPaper ID: N/A\nCommunity:58"}, {"color": "#00abff", "id": "Semantic Similarity Search", "label": "Semantic Similarity Search", "shape": "dot", "title": "Node: Semantic Similarity Search\nPaper ID: N/A\nCommunity:58"}, {"color": "#00abff", "id": "Non-Parametric Memory", "label": "Non-Parametric Memory", "shape": "dot", "title": "Node: Non-Parametric Memory\nPaper ID: N/A\nCommunity:58"}, {"color": "#00abff", "id": "Analog In-Memory Computing Hardware", "label": "Analog In-Memory Computing Hardware", "shape": "dot", "title": "Node: Analog In-Memory Computing Hardware\nPaper ID: N/A\nCommunity:58"}, {"color": "#ff0026", "id": "documents", "label": "documents", "shape": "dot", "title": "Node: documents\nPaper ID: N/A\nCommunity:102"}, {"color": "#009dff", "id": "DPrompt tuning", "label": "DPrompt tuning", "shape": "dot", "title": "Node: DPrompt tuning\nPaper ID: N/A\nCommunity:59"}, {"color": "#009dff", "id": "preprocessing", "label": "preprocessing", "shape": "dot", "title": "Node: preprocessing\nPaper ID: N/A\nCommunity:59"}, {"color": "#c100ff", "id": "Long Context Question Answering", "label": "Long Context Question Answering", "shape": "dot", "title": "Node: Long Context Question Answering\nPaper ID: N/A\nCommunity:83"}, {"color": "#de00ff", "id": "RAIDD", "label": "RAIDD", "shape": "dot", "title": "Node: RAIDD\nPaper ID: N/A\nCommunity:85"}, {"color": "#ff00aa", "id": "StructRAG", "label": "StructRAG", "shape": "dot", "title": "Node: StructRAG\nPaper ID: N/A\nCommunity:93"}, {"color": "#ff00aa", "id": "Knowledge-intensive reasoning", "label": "Knowledge-intensive reasoning", "shape": "dot", "title": "Node: Knowledge-intensive reasoning\nPaper ID: N/A\nCommunity:93"}, {"color": "#008eff", "id": "Retrieval-Augmented Generation (RAG) agents", "label": "Retrieval-Augmented Generation (RAG) agents", "shape": "dot", "title": "Node: Retrieval-Augmented Generation (RAG) agents\nPaper ID: N/A\nCommunity:60"}, {"color": "#008eff", "id": "Backbone Large Language Model (LLM)", "label": "Backbone Large Language Model (LLM)", "shape": "dot", "title": "Node: Backbone Large Language Model (LLM)\nPaper ID: N/A\nCommunity:60"}, {"color": "#008eff", "id": "Knowledge-Intensive Language Tasks (KILT) benchmark", "label": "Knowledge-Intensive Language Tasks (KILT) benchmark", "shape": "dot", "title": "Node: Knowledge-Intensive Language Tasks (KILT) benchmark\nPaper ID: N/A\nCommunity:60"}, {"color": "#0080ff", "id": "FunnelRAG", "label": "FunnelRAG", "shape": "dot", "title": "Node: FunnelRAG\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Xinping Zhao", "label": "Xinping Zhao", "shape": "dot", "title": "Node: Xinping Zhao\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Yan Zhong", "label": "Yan Zhong", "shape": "dot", "title": "Node: Yan Zhong\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Zetian Sun", "label": "Zetian Sun", "shape": "dot", "title": "Node: Zetian Sun\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Xinshuo Hu", "label": "Xinshuo Hu", "shape": "dot", "title": "Node: Xinshuo Hu\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Zhenyu Liu", "label": "Zhenyu Liu", "shape": "dot", "title": "Node: Zhenyu Liu\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Dongfang Li", "label": "Dongfang Li", "shape": "dot", "title": "Node: Dongfang Li\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Baotian Hu", "label": "Baotian Hu", "shape": "dot", "title": "Node: Baotian Hu\nPaper ID: N/A\nCommunity:61"}, {"color": "#0080ff", "id": "Min Zhang", "label": "Min Zhang", "shape": "dot", "title": "Node: Min Zhang\nPaper ID: N/A\nCommunity:61"}, {"color": "#0071ff", "id": "Wenjia Zhai", "label": "Wenjia Zhai", "shape": "dot", "title": "Node: Wenjia Zhai\nPaper ID: N/A\nCommunity:62"}, {"color": "#0071ff", "id": "Self-adaptive Multimodal Retrieval-Augmented Generation", "label": "Self-adaptive Multimodal Retrieval-Augmented Generation", "shape": "dot", "title": "Node: Self-adaptive Multimodal Retrieval-Augmented Generation\nPaper ID: N/A\nCommunity:62"}, {"color": "#0071ff", "id": "Traditional Retrieval-Augmented Generation", "label": "Traditional Retrieval-Augmented Generation", "shape": "dot", "title": "Node: Traditional Retrieval-Augmented Generation\nPaper ID: N/A\nCommunity:62"}, {"color": "#ffbe00", "id": "SAM-RAG", "label": "SAM-RAG", "shape": "dot", "title": "Node: SAM-RAG\nPaper ID: N/A\nCommunity:13"}, {"color": "#ffbe00", "id": "Multimodal Retrieval-Augmented Generation", "label": "Multimodal Retrieval-Augmented Generation", "shape": "dot", "title": "Node: Multimodal Retrieval-Augmented Generation\nPaper ID: N/A\nCommunity:13"}, {"color": "#0062ff", "id": "CoFE-RAG", "label": "CoFE-RAG", "shape": "dot", "title": "Node: CoFE-RAG\nPaper ID: N/A\nCommunity:63"}, {"color": "#0062ff", "id": "Jintao Liu", "label": "Jintao Liu", "shape": "dot", "title": "Node: Jintao Liu\nPaper ID: N/A\nCommunity:63"}, {"color": "#ff0026", "id": "Knowledge-intensive tasks", "label": "Knowledge-intensive tasks", "shape": "dot", "title": "Node: Knowledge-intensive tasks\nPaper ID: N/A\nCommunity:102"}, {"color": "#ff0061", "id": "Knowledge Retrieval", "label": "Knowledge Retrieval", "shape": "dot", "title": "Node: Knowledge Retrieval\nPaper ID: N/A\nCommunity:98"}, {"color": "#ff0061", "id": "Knowledge Selection", "label": "Knowledge Selection", "shape": "dot", "title": "Node: Knowledge Selection\nPaper ID: N/A\nCommunity:98"}, {"color": "#ffa000", "id": "Probing-RAG", "label": "Probing-RAG", "shape": "dot", "title": "Node: Probing-RAG\nPaper ID: N/A\nCommunity:11"}, {"color": "#ffa000", "id": "Prober", "label": "Prober", "shape": "dot", "title": "Node: Prober\nPaper ID: N/A\nCommunity:11"}, {"color": "#ffa000", "id": "Open-domain QA Datasets", "label": "Open-domain QA Datasets", "shape": "dot", "title": "Node: Open-domain QA Datasets\nPaper ID: N/A\nCommunity:11"}, {"color": "#ff0035", "id": "AutoRAG", "label": "AutoRAG", "shape": "dot", "title": "Node: AutoRAG\nPaper ID: N/A\nCommunity:101"}, {"color": "#ff0035", "id": "Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich", "label": "Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich", "shape": "dot", "title": "Node: Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich\nPaper ID: N/A\nCommunity:101"}]);
                  edges = new vis.DataSet([{"from": "Fine-tune the Entire RAG Architecture", "title": "Relationship: Modification\nDescription: The fine-tuning technique is applied to the RAG architecture.\nPaper ID: 2106.11517", "to": "RAG Architecture"}, {"from": "RAG Architecture", "title": "Relationship: Component\nDescription: The DPR retriever is a component of the RAG architecture.\nPaper ID: 2106.11517", "to": "DPR Retriever"}, {"from": "RAG Architecture", "title": "Relationship: Development\nDescription: Shamane Siriwardhana was involved in the development of the RAG architecture.\nPaper ID: 2106.11517", "to": "Shamane Siriwardhana"}, {"from": "Large Language Models", "title": "Relationship: integrates\nDescription: Retrieval Augmented Generation integrates external knowledge into Large Language Models to enhance accuracy and relevancy in question answering tasks.\nPaper ID: 2409.17648", "to": "Retrieval Augmented Generation"}, {"from": "Large Language Models", "title": "Relationship: uses\nDescription: Large Language Models use Retrieval-Augmented Generation to improve the consistency and coherence of generated content.\nPaper ID: 2409.13385", "to": "Retrieval-Augmented Generation"}, {"from": "Large Language Models", "title": "Relationship: connection\nDescription: The paper examines the relationship between retrievers and Large Language Models in the context of Retrieval-augmented Generation.\nPaper ID: 2401.06954", "to": "Retrievers"}, {"from": "Large Language Models", "title": "Relationship: enhancement\nDescription: Retrieval-augmented Generation is an effective way to enhance the performance of Large Language Models.\nPaper ID: 2401.06954", "to": "Retrieval-augmented Generation"}, {"from": "Large Language Models", "title": "Relationship: Enhances\nDescription: CRUD-RAG enhances the capabilities of large language models by incorporating external knowledge sources.\nPaper ID: 2401.17043", "to": "CRUD-RAG"}, {"from": "Large Language Models", "title": "Relationship: Augments\nDescription: LLMs can be augmented by RA-LLMs to harness external and authoritative knowledge bases\nPaper ID: 2405.06211", "to": "Retrieval-Augmented Large Language Models"}, {"from": "Large Language Models", "title": "Relationship: enhances\nDescription: M-RAG enhances Large Language Models by retrieving relevant memories from an external database\nPaper ID: 2405.1642", "to": "M-RAG"}, {"from": "Large Language Models", "title": "Relationship: related_to\nDescription: Large Language Models are related to OpenAI, as OpenAI highlights the process of fine-tuning LLMs.\nPaper ID: 2406.11201", "to": "OpenAI"}, {"from": "Large Language Models", "title": "Relationship: Enhances\nDescription: Retrieval-Augmented Generation enhances Large Language Models\nPaper ID: 2407.01219", "to": "Retrieval-Augmented Generation (RAG)"}, {"from": "Large Language Models", "title": "Relationship: Improves\nDescription: FS-RAG aims to improve the factual accuracy of Large Language Models\nPaper ID: 2406.16167", "to": "FS-RAG"}, {"from": "Large Language Models", "title": "Relationship: Enhances\nDescription: Query-Dependent Retrievals enhance Large Language Models\nPaper ID: 2407.01219", "to": "Query-Dependent Retrievals"}, {"from": "Large Language Models", "title": "Relationship: refines\nDescription: Graph Retrieval-Augmented Generation refines Large Language Model outputs by referencing an external knowledge base\nPaper ID: 2408.08921", "to": "Graph Retrieval-Augmented Generation"}, {"from": "Large Language Models", "title": "Relationship: applies_to\nDescription: FunnelRAG is used in Large Language Models\nPaper ID: 2410.10293", "to": "FunnelRAG"}, {"from": "Large Language Models", "title": "Relationship: enhances\nDescription: CoFE-RAG enhances Large Language Models to generate more accurate and reliable answers\nPaper ID: 2410.12248", "to": "CoFE-RAG"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: applies_to\nDescription: Retrieval Augmented Generation is applied in the field of Medical Education\nPaper ID: 2308.00479", "to": "Medical Education"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: uses\nDescription: Retrieval Augmented Generation uses Financial Documents to source relevant text chunks for query-based responses.\nPaper ID: 2404.07221", "to": "Financial Documents"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: Extension\nDescription: FS-RAG is an extension to Retrieval Augmented Generation\nPaper ID: 2406.16167", "to": "FS-RAG"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: enhances\nDescription: Retrieval augmented generation enhances the accuracy and reliability of generative AI models for document-grounded question-answering tasks.\nPaper ID: 2407.15353", "to": "Document-Grounded Question-Answering"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: applied\nDescription: Retrieval augmented generation is applied to knowledge-intensive vertical domains, such as electronic design automation.\nPaper ID: 2407.15353", "to": "Electronic Design Automation"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: fine-tuned\nDescription: LLM is fine-tuned with high-quality domain corpus for retrieval augmented generation.\nPaper ID: 2407.15353", "to": "LLM"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: uses\nDescription: RAG is a tool used by LLMs to efficiently process overly lengthy contexts.\nPaper ID: 2407.16833", "to": "Large Language Models (LLMs)"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: routes_to\nDescription: Self-Route routes queries to RAG based on model self-reflection.\nPaper ID: 2407.16833", "to": "Self-Route"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: uses\nDescription: Retrieval Augmented Generation is used in Long Context Question Answering systems.\nPaper ID: 2410.03754", "to": "Long Context Question Answering"}, {"from": "Retrieval Augmented Generation", "title": "Relationship: extends\nDescription: RAIDD is an extension to Retrieval Augmented Generation systems.\nPaper ID: 2410.03754", "to": "RAIDD"}, {"from": "Cheonsu Jeong", "title": "Relationship: Uses\nDescription: The author uses Large Language Models (LLM) in their study on implementing generative AI services.\nPaper ID: 2309.01105", "to": "Large Language Models (LLM)"}, {"from": "Large Language Models (LLM)", "title": "Relationship: Is used by\nDescription: The Retrieval-Augmented Generation (RAG) model is designed to utilize the capabilities of Large Language Models (LLM) for improved content generation.\nPaper ID: 2309.01105", "to": "Retrieval-Augmented Generation (RAG) model"}, {"from": "Retrieval-Augmented Generation (RAG) model", "title": "Relationship: Enhances\nDescription: The Retrieval-Augmented Generation (RAG) model enhances the functionality of generative AI services by improving information storage and retrieval processes.\nPaper ID: 2309.01105", "to": "Generative AI services"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Evaluates\nDescription: Retrieval-Augmented Generation is evaluated on the Retrieval-Augmented Generation Benchmark\nPaper ID: 2309.01431", "to": "Retrieval-Augmented Generation Benchmark"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: incorporates\nDescription: Retrieval-Augmented Generation incorporates knowledge from external databases to enhance the accuracy and credibility of Large Language Models\u0027 generation.\nPaper ID: 2312.10997", "to": "External Databases"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: uses\nDescription: Retrieval-Augmented Generation uses Information Retrieval to retrieve relevant passages or documents from a large corpus of text.\nPaper ID: 2401.14887", "to": "Information Retrieval"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: includes\nDescription: Generative AI includes Retrieval-Augmented Generation as a method to extend beyond the pre-trained knowledge of Large Language Models.\nPaper ID: 2401.14887", "to": "Generative AI"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Improves\nDescription: Retrieval-Augmented Generation improves the quality of structured outputs\nPaper ID: 2404.08189", "to": "Structured Output"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Author\nDescription: Hao Yu is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\nPaper ID: 2405.07437", "to": "Hao Yu"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Author\nDescription: Aoran Gan is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\nPaper ID: 2405.07437", "to": "Aoran Gan"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Author\nDescription: Kai Zhang is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\nPaper ID: 2405.07437", "to": "Kai Zhang"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Author\nDescription: Shiwei Tong is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\nPaper ID: 2405.07437", "to": "Shiwei Tong"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Author\nDescription: Qi Liu is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\nPaper ID: 2405.07437", "to": "Qi Liu"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Author\nDescription: Zhaofeng Liu is an author of the paper \u0027Evaluation of Retrieval-Augmented Generation: A Survey\u0027\nPaper ID: 2405.07437", "to": "Zhaofeng Liu"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Evaluates\nDescription: A Unified Evaluation Process of RAG evaluates Retrieval-Augmented Generation systems\nPaper ID: 2405.07437", "to": "A Unified Evaluation Process of RAG"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: augments\nDescription: DuetRAG augments the input of Large Language Models with relevant retrieved passages\nPaper ID: 2405.13002", "to": "DuetRAG"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Used\nDescription: Virtual Tokens are used in Retrieval-Augmented Generation\nPaper ID: 2405.1967", "to": "Virtual Tokens"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: enhances\nDescription: BERGEN is a library that enhances Large Language Models with external knowledge using Retrieval-Augmented Generation\nPaper ID: 2407.01102", "to": "BERGEN"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: Benchmark\nDescription: RAGBench is a benchmark for Retrieval-Augmented Generation systems.\nPaper ID: 2407.11005", "to": "RAGBench"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: uses\nDescription: RAG systems use LLMs to encode retrieved contexts and generate responses.\nPaper ID: 2409.15699", "to": "Large Language Models (LLMs)"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: extends\nDescription: GraphRAG extends Retrieval-Augmented Generation by leveraging structural information across entities\nPaper ID: 2408.08921", "to": "GraphRAG"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: improves\nDescription: FlexRAG enhances the performance of RAG systems by compressing retrieved contexts and optimizing embeddings.\nPaper ID: 2409.15699", "to": "FlexRAG (Flexible Context Adaptation for RAG)"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: evaluates\nDescription: CoFE-RAG is a framework that evaluates Retrieval-Augmented Generation\nPaper ID: 2410.12248", "to": "CoFE-RAG"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: uses\nDescription: Retrieval-Augmented Generation uses Knowledge Retrieval to retrieve external knowledge.\nPaper ID: 2410.13258", "to": "Knowledge Retrieval"}, {"from": "Retrieval-Augmented Generation", "title": "Relationship: uses\nDescription: Retrieval-Augmented Generation uses Knowledge Selection to select relevant knowledge from the retrieved knowledge.\nPaper ID: 2410.13258", "to": "Knowledge Selection"}, {"from": "RAGAS", "title": "Relationship: evaluation\nDescription: RAGAS is a framework for evaluating Retrieval Augmented Generation (RAG) pipelines.\nPaper ID: 2309.15217", "to": "Retrieval Augmented Generation (RAG)"}, {"from": "RAGAS", "title": "Relationship: uses\nDescription: RAGAS uses LLMs to provide knowledge from a reference textual database.\nPaper ID: 2309.15217", "to": "LLMs"}, {"from": "RAGAS", "title": "Relationship: author\nDescription: Shahul Es is an author of the paper \u0027RAGAS: Automated Evaluation of Retrieval Augmented Generation\u0027.\nPaper ID: 2309.15217", "to": "Shahul Es"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Sudeshna Das is the author of the paper that proposes the Retrieval Augmented Generation (RAG) framework\nPaper ID: 2405.19519", "to": "Sudeshna Das"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: enhances\nDescription: Multi-Head RAG enhances the abilities of Retrieval Augmented Generation (RAG) by enabling the retrieval of documents into the LLM context to provide more accurate and relevant responses.\nPaper ID: 2406.05085", "to": "Multi-Head RAG"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: enhances\nDescription: R^2AG is an enhanced version of RAG that incorporates retrieval information\nPaper ID: 2406.13249", "to": "R^2AG"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Florin Cuconasu is the author of the paper discussing RAG systems\nPaper ID: 2406.14972", "to": "Florin Cuconasu"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Giovanni Trappolini is the author of the paper discussing RAG systems\nPaper ID: 2406.14972", "to": "Giovanni Trappolini"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Nicola Tonellotto is the author of the paper discussing RAG systems\nPaper ID: 2406.14972", "to": "Nicola Tonellotto"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Fabrizio Silvestri is the author of the paper discussing RAG systems\nPaper ID: 2406.14972", "to": "Fabrizio Silvestri"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: enhances\nDescription: Speculative RAG enhances the performance of RAG by leveraging a larger generalist LM to efficiently verify multiple RAG drafts.\nPaper ID: 2407.08223", "to": "Speculative RAG"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Application\nDescription: RAG is applied to Arabic language\nPaper ID: 2408.07425", "to": "Arabic"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Used in\nDescription: Semantic embedding models are used in the retrieval stage of RAG\nPaper ID: 2408.07425", "to": "Semantic embedding models"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Used in\nDescription: LLMs are used in the generation stage of RAG\nPaper ID: 2408.07425", "to": "LLMs (Large Language Models)"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: is\nDescription: SFR-RAG is a paradigm that integrates external contextual information with large language models (LLMs) to enhance factual accuracy and relevance\nPaper ID: 2409.09916", "to": "SFR-RAG"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: is_a\nDescription: GEM-RAG is a method for Retrieval Augmented Generation.\nPaper ID: 2409.15566", "to": "GEM-RAG"}, {"from": "Retrieval Augmented Generation (RAG)", "title": "Relationship: Incorporates\nDescription: BSharedRAG incorporates the Retrieval Augmented Generation (RAG) technique\nPaper ID: 2409.20075", "to": "BSharedRAG"}, {"from": "LLMs", "title": "Relationship: Improves\nDescription: RAG combines retrieval mechanisms with generative language models to enhance the accuracy of LLMs\nPaper ID: 2410.12837", "to": "RAG"}, {"from": "LLMs", "title": "Relationship: integrated\nDescription: RAU integrates information retrieved from external resources with LLMs for understanding tasks.\nPaper ID: 2404.19543", "to": "RAU"}, {"from": "LLMs", "title": "Relationship: employs\nDescription: RAGEval uses LLMs to generate high-quality documents, questions, answers, and references.\nPaper ID: 2408.01262", "to": "RAGEval"}, {"from": "LLMs", "title": "Relationship: uses\nDescription: AutoRAG uses LLMs in conjunction with external documents\nPaper ID: 2410.20878", "to": "AutoRAG"}, {"from": "Naive RAG", "title": "Relationship: evolves\nDescription: Naive RAG evolves into Advanced RAG, which is a more sophisticated technique for Retrieval-Augmented Generation.\nPaper ID: 2312.10997", "to": "Advanced RAG"}, {"from": "Retrievers", "title": "Relationship: uses\nDescription: Retrieval-Augmented Language Models use Retrievers to retrieve information from external resources.\nPaper ID: 2404.19543", "to": "Retrieval-Augmented Language Models"}, {"from": "Retrievers", "title": "Relationship: provides\nDescription: Retrievers provide external documents to R^2AG\nPaper ID: 2406.13249", "to": "R^2AG"}, {"from": "Retrieval-augmented Generation", "title": "Relationship: refines\nDescription: Meta-prompting Optimized Retrieval-augmented Generation refines the retrieved content before including it in the prompt.\nPaper ID: 2407.03955", "to": "Meta-prompting Optimized Retrieval-augmented Generation"}, {"from": "Paulo Finardi", "title": "Relationship: Author\nDescription: Paulo Finardi is the author of the paper\nPaper ID: 2401.07883", "to": "The Chronicles of RAG"}, {"from": "Paulo Finardi", "title": "Relationship: Developer\nDescription: Paulo Finardi is a developer of the RAG technique\nPaper ID: 2401.07883", "to": "RAG"}, {"from": "RAG", "title": "Relationship: Tested\nDescription: RAG was tested on the Harry Potter book\nPaper ID: 2401.07883", "to": "Harry Potter"}, {"from": "RAG", "title": "Relationship: uses\nDescription: HiQA uses RAG as a method for integrating external documents during the response generation phase\nPaper ID: 2402.01767", "to": "HiQA"}, {"from": "RAG", "title": "Relationship: Application\nDescription: RAG systems are designed to process technical documents\nPaper ID: 2404.00657", "to": "Technical Documents"}, {"from": "RAG", "title": "Relationship: related_to\nDescription: CLAPNQ is a benchmark dataset for the full RAG pipeline.\nPaper ID: 2404.02103", "to": "CLAPNQ"}, {"from": "RAG", "title": "Relationship: Framework\nDescription: uRAG is a framework that serves multiple RAG systems\nPaper ID: 2405.00175", "to": "uRAG"}, {"from": "RAG", "title": "Relationship: Improves\nDescription: Multi-Meta-RAG improves the traditional RAG method by using database filtering with LLM-extracted metadata to select relevant documents.\nPaper ID: 2406.13213", "to": "Multi-Meta-RAG"}, {"from": "RAG", "title": "Relationship: Alternative\nDescription: RICHES offers an alternative to conventional RAG systems\nPaper ID: 2407.00361", "to": "RICHES"}, {"from": "RAG", "title": "Relationship: Transformation\nDescription: Modular RAG transforms traditional RAG systems into reconfigurable frameworks\nPaper ID: 2407.21059", "to": "Modular RAG"}, {"from": "RAG", "title": "Relationship: uses\nDescription: RAGEval is a framework designed to assess RAG systems.\nPaper ID: 2408.01262", "to": "RAGEval"}, {"from": "RAG", "title": "Relationship: Improvement\nDescription: OP-RAG has improved the performance of RAG for long-context question-answer applications\nPaper ID: 2409.01666", "to": "OP-RAG"}, {"from": "RAG", "title": "Relationship: Handles\nDescription: OneGen enables LLMs to handle RAG tasks that require both generation and retrieval.\nPaper ID: 2409.05152", "to": "OneGen"}, {"from": "RAG", "title": "Relationship: assists\nDescription: RAG helps the reasoning process of LLM\nPaper ID: 2410.02338", "to": "LLM"}, {"from": "RAG", "title": "Relationship: requires preprocessing\nDescription: RAG requires preprocessing of information in documents to filter out noise\nPaper ID: 2410.02338", "to": "documents"}, {"from": "RAG", "title": "Relationship: Handles\nDescription: RAG is integrated to handle knowledge-intensive tasks\nPaper ID: 2410.12837", "to": "Knowledge-intensive tasks"}, {"from": "RAG", "title": "Relationship: enhances\nDescription: AutoRAG enhances the Retrieval-Augmented Generation technology\nPaper ID: 2410.20878", "to": "AutoRAG"}, {"from": "OpenAI", "title": "Relationship: Provider\nDescription: OpenAI provides the gpt-4 model\nPaper ID: 2401.07883", "to": "gpt-4"}, {"from": "OpenAI", "title": "Relationship: develops\nDescription: OpenAI develops and provides SBERT, a text encoder.\nPaper ID: 2409.15566", "to": "SBERT"}, {"from": "Google", "title": "Relationship: Provider\nDescription: Google provides the Gemini Pro model\nPaper ID: 2401.07883", "to": "Gemini Pro"}, {"from": "Generative AI", "title": "Relationship: Related to\nDescription: Generative AI is prone to hallucination\nPaper ID: 2404.08189", "to": "Hallucination"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Supplement\nDescription: Retrieval-Augmented Generation (RAG) supplements Large Language Models (LLMs)\nPaper ID: 2406.03963", "to": "Retrieval-Augmented Generation (RAG)"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: improves\nDescription: PipeRAG improves the generation quality of large language models.\nPaper ID: 2403.05676", "to": "PipeRAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: based_on\nDescription: DRAGIN is based on the real-time information needs of Large Language Models\nPaper ID: 2403.10081", "to": "DRAGIN"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: addresses\nDescription: RQ-RAG addresses the limitations of LLMs\nPaper ID: 2404.0061", "to": "RQ-RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Optimizes\nDescription: RAGCache optimizes the performance of Large Language Models by caching intermediate states\nPaper ID: 2404.12457", "to": "RAGCache"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Combines\nDescription: The RAG framework combines LLMs with internal documents\nPaper ID: 2405.12363", "to": "Enterprise retrieval augmented generation (RAG)"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: RelatedTo\nDescription: FlashRAG is related to Large Language Models (LLMs) as it is designed to work with them.\nPaper ID: 2405.13576", "to": "FlashRAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: works_with\nDescription: Multi-Head RAG works with Large Language Models (LLMs) to provide more accurate and relevant responses.\nPaper ID: 2406.05085", "to": "Multi-Head RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: uses\nDescription: DR-RAG uses Large Language Models (LLMs) to generate responses to questions.\nPaper ID: 2406.07348", "to": "DR-RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: augments\nDescription: R^2AG augments LLMs with external documents provided by retrievers\nPaper ID: 2406.13249", "to": "R^2AG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: uses\nDescription: Speculative RAG uses large language models to generate and verify RAG drafts.\nPaper ID: 2407.08223", "to": "Speculative RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: is\nDescription: Gemini-1.5 is a type of Large Language Model.\nPaper ID: 2407.16833", "to": "Gemini-1.5"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: compared_to\nDescription: Large Language Models (LLMs) are compared to GPT-4 in terms of performance in the medical domain\nPaper ID: 2407.21055", "to": "GPT-4"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: uses\nDescription: Self-Route uses LLMs to route queries to RAG or LC.\nPaper ID: 2407.16833", "to": "Self-Route"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: augments\nDescription: The Bailicai framework augments the performance of LLMs in medicine\nPaper ID: 2407.21055", "to": "Bailicai"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: compared_to\nDescription: Large Language Models (LLMs) are compared to GPT-3.5 in terms of performance in the medical domain\nPaper ID: 2407.21055", "to": "GPT-3.5"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Integration\nDescription: Modular RAG integrates advanced retrievers, LLMs, and other complementary technologies\nPaper ID: 2407.21059", "to": "Modular RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: enhances\nDescription: The Hybrid RAG System enhances the accuracy and reduces hallucinations of Large Language Models.\nPaper ID: 2408.05141", "to": "Hybrid RAG System"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: augments\nDescription: RAG noise can be used to augment the capabilities of large language models\nPaper ID: 2408.13533", "to": "RAG Noise"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Improves\nDescription: OneGen is designed to improve LLMs\u0027 performance on tasks that require both generation and retrieval.\nPaper ID: 2409.05152", "to": "OneGen"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: uses\nDescription: SFR-RAG uses large language models (LLMs) to enhance factual accuracy and relevance\nPaper ID: 2409.09916", "to": "SFR-RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: augments\nDescription: GEM-RAG augments Large Language Models with rich in-context examples and information.\nPaper ID: 2409.15566", "to": "GEM-RAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Enhances\nDescription: StructRAG is a framework that enhances LLMs in knowledge-intensive reasoning tasks\nPaper ID: 2410.08815", "to": "StructRAG"}, {"from": "Large Language Models (LLMs)", "title": "Relationship: Augments\nDescription: RAG is a method that augments LLMs in knowledge-based tasks\nPaper ID: 2410.08815", "to": "Retrieval-augmented generation (RAG)"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Improvement\nDescription: CRAG improves the robustness of RAG by incorporating a lightweight retrieval evaluator and a decompose-then-recompose algorithm.\nPaper ID: 2401.15884", "to": "Corrective Retrieval Augmented Generation (CRAG)"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Used in\nDescription: BERT is used as a language model in the RAG technique\nPaper ID: 2402.16874", "to": "BERT"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Used in\nDescription: Orca2 is used as a language model in the RAG technique\nPaper ID: 2402.16874", "to": "Orca2"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Penghao Zhao is the author of the paper on RAG\nPaper ID: 2402.19473", "to": "Penghao Zhao"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Solution\nDescription: RAG is a solution to address challenges in AIGC\nPaper ID: 2402.19473", "to": "Artificial Intelligence Generated Content (AIGC)"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: enhances\nDescription: PipeRAG enhances the generation quality of large language models by incorporating external token databases.\nPaper ID: 2403.05676", "to": "PipeRAG"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Framework_for\nDescription: RAGGED is a framework for analyzing RAG configurations\nPaper ID: 2403.0904", "to": "RAGGED"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Improves\nDescription: RAG can significantly improve the performance of language models\nPaper ID: 2403.0904", "to": "Language Models (LMs)"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Used in\nDescription: Retrieval-Augmented Generation (RAG) technology is used in Conversational Systems\nPaper ID: 2403.11413", "to": "Conversational Systems"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Applies to\nDescription: RAG is primarily focused on the text domain\nPaper ID: 2404.10981", "to": "Text Domain"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Designed for\nDescription: RAGCache is a novel caching system designed to optimize the performance of Retrieval-Augmented Generation\nPaper ID: 2404.12457", "to": "RAGCache"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: RelatedTo\nDescription: FlashRAG is related to Retrieval-Augmented Generation (RAG) as it is a toolkit for implementing RAG methods.\nPaper ID: 2405.13576", "to": "FlashRAG"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Wei Tang is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Wei Tang"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Yixin Cao is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Yixin Cao"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Jiahao Ying is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Jiahao Ying"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Bo Wang is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Bo Wang"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Yuyue Zhao is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Yuyue Zhao"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Yong Liao is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Yong Liao"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Pengyuan Zhou is the author of Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "Pengyuan Zhou"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Related\nDescription: A + B framework is related to Retrieval-Augmented Generation (RAG)\nPaper ID: 2406.03963", "to": "A + B framework"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: is_a\nDescription: DR-RAG is a variant of Retrieval-Augmented Generation (RAG) that improves document retrieval recall and the accuracy of answers.\nPaper ID: 2406.07348", "to": "DR-RAG"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: applies_to\nDescription: Retrieval-Augmented Generation (RAG) is applied to the task of Question-Answering (QA).\nPaper ID: 2406.07348", "to": "Question-Answering (QA)"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Technique used in\nDescription: Retrieval-Augmented Generation (RAG) is a technique used in Natural Language Processing\nPaper ID: 2406.11424", "to": "Natural Language Processing"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Xiaohua Wang is the author of the paper on Retrieval-Augmented Generation\nPaper ID: 2407.01219", "to": "Xiaohua Wang"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Uses\nDescription: RAG systems use Context Window Utilization as a hyper-parameter\nPaper ID: 2407.19794", "to": "Context Window Utilization"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: implements\nDescription: The Bailicai framework implements the Retrieval-Augmented Generation approach\nPaper ID: 2407.21055", "to": "Bailicai"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: evaluates\nDescription: RAGChecker evaluates the performance of RAG systems\nPaper ID: 2408.08067", "to": "RAGChecker"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: is_a\nDescription: MemoRAG is a type of Retrieval-Augmented Generation (RAG)\nPaper ID: 2409.05591", "to": "MemoRAG"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Shuo Yu is the author of the paper about RAG\nPaper ID: 2409.13694", "to": "Shuo Yu"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Mingyue Cheng is the author of the paper about RAG\nPaper ID: 2409.13694", "to": "Mingyue Cheng"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Jiqian Yang is the author of the paper about RAG\nPaper ID: 2409.13694", "to": "Jiqian Yang"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: Author\nDescription: Jie Ouyang is the author of the paper about RAG\nPaper ID: 2409.13694", "to": "Jie Ouyang"}, {"from": "Retrieval-Augmented Generation (RAG)", "title": "Relationship: is_a\nDescription: FunnelRAG is a type of Retrieval-Augmented Generation (RAG)\nPaper ID: 2410.10293", "to": "FunnelRAG"}, {"from": "CRUD-RAG", "title": "Relationship: Uses\nDescription: CRUD-RAG uses external knowledge sources to enhance the capabilities of large language models.\nPaper ID: 2401.17043", "to": "Knowledge Sources"}, {"from": "CRUD-RAG", "title": "Relationship: Applies\nDescription: CRUD-RAG applies to various CRUD applications, including Create, Read, Update, and Delete.\nPaper ID: 2401.17043", "to": "CRUD"}, {"from": "CRUD-RAG", "title": "Relationship: Requires\nDescription: CRUD-RAG requires the generation of original, varied content for Create applications.\nPaper ID: 2401.17043", "to": "Create"}, {"from": "CRUD-RAG", "title": "Relationship: Involves\nDescription: CRUD-RAG involves responding to intricate questions in knowledge-intensive situations for Read applications.\nPaper ID: 2401.17043", "to": "Read"}, {"from": "HiQA", "title": "Relationship: evaluated_by\nDescription: HiQA is evaluated by MasQA, a benchmark for evaluating and researching in multi-document question-answering (MDQA)\nPaper ID: 2402.01767", "to": "MasQA"}, {"from": "Julien Pierre Edmond Ghali", "title": "Relationship: Co-author\nDescription: Both authors contributed to the research paper\nPaper ID: 2402.16874", "to": "Kosuke Shima"}, {"from": "Julien Pierre Edmond Ghali", "title": "Relationship: Co-author\nDescription: Both authors contributed to the research paper\nPaper ID: 2402.16874", "to": "Koichi Moriyama"}, {"from": "Julien Pierre Edmond Ghali", "title": "Relationship: Co-author\nDescription: Both authors contributed to the research paper\nPaper ID: 2402.16874", "to": "Atsuko Mutoh"}, {"from": "Julien Pierre Edmond Ghali", "title": "Relationship: Co-author\nDescription: Both authors contributed to the research paper\nPaper ID: 2402.16874", "to": "Nobuhiro Inuzuka"}, {"from": "BERT", "title": "Relationship: Used with\nDescription: UMAP is used to simplify document retrieval with BERT\nPaper ID: 2402.16874", "to": "UMAP"}, {"from": "Penghao Zhao", "title": "Relationship: Researcher\nDescription: Penghao Zhao is researching AIGC\nPaper ID: 2402.19473", "to": "Artificial Intelligence Generated Content (AIGC)"}, {"from": "PKU-DAIR", "title": "Relationship: Maintainer\nDescription: PKU-DAIR is maintaining the RAG-Survey repository\nPaper ID: 2402.19473", "to": "RAG-Survey"}, {"from": "Retrieval Augmented Generation Systems", "title": "Relationship: augments\nDescription: Retrieval Augmented Generation Systems augment Large-Language Model (LLM) outputs with domain specific and time sensitive data.\nPaper ID: 2403.0082", "to": "Large-Language Model (LLM)"}, {"from": "Retrieval Augmented Generation Systems", "title": "Relationship: queries\nDescription: Retrieval Augmented Generation Systems query the Vector Database for additional information.\nPaper ID: 2403.0082", "to": "Vector Database"}, {"from": "Retrieval Augmented Generation Systems", "title": "Relationship: uses\nDescription: The Boolean Agent uses Retrieval Augmented Generation Systems to decide whether to query a vector database or not.\nPaper ID: 2403.0082", "to": "Boolean Agent"}, {"from": "PipeRAG", "title": "Relationship: uses\nDescription: PipeRAG uses algorithm-system co-design to reduce generation latency and enhance generation quality.\nPaper ID: 2403.05676", "to": "Algorithm-System Co-design"}, {"from": "RAGGED", "title": "Relationship: Analyzes\nDescription: RAGGED is used to analyze RAG configurations across various DBQA tasks\nPaper ID: 2403.0904", "to": "Document-Based Question Answering (DBQA)"}, {"from": "DRAGIN", "title": "Relationship: authors\nDescription: The authors of the paper developed the DRAGIN framework\nPaper ID: 2403.10081", "to": "Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, Yiqun Liu"}, {"from": "DRAGIN", "title": "Relationship: open-sourced\nDescription: The code, data, and models of DRAGIN are open-sourced on GitHub\nPaper ID: 2403.10081", "to": "GitHub"}, {"from": "GitHub", "title": "Relationship: HostedOn\nDescription: FlashRAG is hosted on GitHub, a web-based platform for version control and collaboration.\nPaper ID: 2405.13576", "to": "FlashRAG"}, {"from": "GitHub", "title": "Relationship: Hosts\nDescription: GitHub hosts the RAG Foundry framework as open-source.\nPaper ID: 2408.02545", "to": "RAG Foundry"}, {"from": "GitHub", "title": "Relationship: Repository\nDescription: SAM-RAG is available on GitHub\nPaper ID: 2410.11321", "to": "SAM-RAG"}, {"from": "GitHub", "title": "Relationship: hosts\nDescription: The results of optimizing a dataset using AutoRAG are publicly available on GitHub\nPaper ID: 2410.20878", "to": "AutoRAG"}, {"from": "Anuja Tayal", "title": "Relationship: Co-author\nDescription: Anuja Tayal and Aman Tyagi co-authored the paper \u0027Dynamic Contexts for Generating Suggestion Questions in RAG Based Conversational Systems\u0027\nPaper ID: 2403.11413", "to": "Aman Tyagi"}, {"from": "Dynamic Contexts", "title": "Relationship: Generates\nDescription: Dynamic Contexts approach generates Suggestion Questions\nPaper ID: 2403.11413", "to": "Suggestion Questions"}, {"from": "Loops On Retrieval Augmented Generation (LoRAG)", "title": "Relationship: Author\nDescription: Ayush Thakur is one of the authors of LoRAG\nPaper ID: 2403.1545", "to": "Ayush Thakur"}, {"from": "Loops On Retrieval Augmented Generation (LoRAG)", "title": "Relationship: Author\nDescription: Rashmi Vashisth is one of the authors of LoRAG\nPaper ID: 2403.1545", "to": "Rashmi Vashisth"}, {"from": "Loops On Retrieval Augmented Generation (LoRAG)", "title": "Relationship: Evaluates\nDescription: LoRAG is evaluated on benchmark datasets\nPaper ID: 2403.1545", "to": "Benchmark datasets"}, {"from": "Loops On Retrieval Augmented Generation (LoRAG)", "title": "Relationship: Compared to\nDescription: LoRAG is compared to state-of-the-art models\nPaper ID: 2403.1545", "to": "State-of-the-art models"}, {"from": "Karthik Suresh", "title": "Relationship: Author\nDescription: Karthik Suresh is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\nPaper ID: 2403.15729", "to": "RAGS4EIC"}, {"from": "RAGS4EIC", "title": "Relationship: Author\nDescription: Neeltje Kackar is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\nPaper ID: 2403.15729", "to": "Neeltje Kackar"}, {"from": "RAGS4EIC", "title": "Relationship: Author\nDescription: Luke Schleck is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\nPaper ID: 2403.15729", "to": "Luke Schleck"}, {"from": "RAGS4EIC", "title": "Relationship: Author\nDescription: Cristiano Fanelli is one of the authors of the paper \u0027Towards a RAG-based Summarization Agent for the Electron-Ion Collider\u0027, which describes the development of RAGS4EIC\nPaper ID: 2403.15729", "to": "Cristiano Fanelli"}, {"from": "RAGS4EIC", "title": "Relationship: Related_to\nDescription: RAGS4EIC is a system developed for the Electron-Ion Collider (EIC) community\nPaper ID: 2403.15729", "to": "Electron-Ion Collider (EIC)"}, {"from": "RAGS4EIC", "title": "Relationship: Used_by\nDescription: The Large Language Model (LLM) is used by RAGS4EIC to generate concise summaries\nPaper ID: 2403.15729", "to": "Large Language Model (LLM)"}, {"from": "RAGS4EIC", "title": "Relationship: Foundation\nDescription: LangChain is the foundation of the RAGS4EIC workflow\nPaper ID: 2403.15729", "to": "LangChain"}, {"from": "Large Language Model (LLM)", "title": "Relationship: Model\nDescription: LLM is used in ARAGOG\nPaper ID: 2404.01037", "to": "ARAGOG"}, {"from": "Large Language Model (LLM)", "title": "Relationship: uses\nDescription: P-RAG leverages the powerful language processing capabilities of LLMs to effectively process and generate human-like language.\nPaper ID: 2409.11279", "to": "P-RAG"}, {"from": "RQ-RAG", "title": "Relationship: uses\nDescription: RQ-RAG uses the Llama2 model\nPaper ID: 2404.0061", "to": "Llama2 model"}, {"from": "RQ-RAG", "title": "Relationship: evaluated on\nDescription: RQ-RAG was evaluated on single-hop QA datasets\nPaper ID: 2404.0061", "to": "Single-hop QA datasets"}, {"from": "RQ-RAG", "title": "Relationship: evaluated on\nDescription: RQ-RAG was evaluated on multi-hop QA datasets\nPaper ID: 2404.0061", "to": "Multi-hop QA datasets"}, {"from": "Sumit Soman", "title": "Relationship: Co-author\nDescription: Sumit Soman and Sujoy Roychowdhury are co-authors of the paper \u0027Observations on Building RAG Systems for Technical Documents\u0027\nPaper ID: 2404.00657", "to": "Sujoy Roychowdhury"}, {"from": "ARAGOG", "title": "Relationship: Author\nDescription: ARAGOG is authored by Matou\u0161 Eibich\nPaper ID: 2404.01037", "to": "Matou\u0161 Eibich"}, {"from": "ARAGOG", "title": "Relationship: Author\nDescription: ARAGOG is authored by Shivay Nagpal\nPaper ID: 2404.01037", "to": "Shivay Nagpal"}, {"from": "ARAGOG", "title": "Relationship: Author\nDescription: ARAGOG is authored by Alexander Fred-Ojala\nPaper ID: 2404.01037", "to": "Alexander Fred-Ojala"}, {"from": "ARAGOG", "title": "Relationship: Method\nDescription: HyDE is a method used in ARAGOG\nPaper ID: 2404.01037", "to": "Hypothetical Document Embedding (HyDE)"}, {"from": "CLAPNQ", "title": "Relationship: based_on\nDescription: CLAPNQ includes long answers with grounded gold passages from Natural Questions (NQ).\nPaper ID: 2404.02103", "to": "Natural Questions (NQ)"}, {"from": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation", "title": "Relationship: Author\nDescription: Maxime Bouthors is one of the authors of the paper\nPaper ID: 2404.02835", "to": "Maxime Bouthors"}, {"from": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation", "title": "Relationship: Author\nDescription: Josep Crego is one of the authors of the paper\nPaper ID: 2404.02835", "to": "Josep Crego"}, {"from": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation", "title": "Relationship: Author\nDescription: Francois Yvon is one of the authors of the paper\nPaper ID: 2404.02835", "to": "Francois Yvon"}, {"from": "Retrieval-Augmented Neural Machine Translation (RAMT)", "title": "Relationship: Uses\nDescription: RAMT uses an autoregressive model\nPaper ID: 2404.02835", "to": "Autoregressive model"}, {"from": "Retrieval-Augmented Neural Machine Translation (RAMT)", "title": "Relationship: Uses\nDescription: RAMT uses an edit-based model\nPaper ID: 2404.02835", "to": "Edit-based model"}, {"from": "Retrieval-Augmented Neural Machine Translation (RAMT)", "title": "Relationship: Uses\nDescription: RAMT uses a large language model with in-context learning\nPaper ID: 2404.02835", "to": "Large language model with in-context learning"}, {"from": "Spurthi Setty", "title": "Relationship: co-author\nDescription: Spurthi Setty and Harsh Thakkar are co-authors of the paper \u0027Improving Retrieval for RAG based Question Answering Models on Financial Documents\u0027.\nPaper ID: 2404.07221", "to": "Harsh Thakkar"}, {"from": "Patrice B\u00e8chard", "title": "Relationship: Co-author\nDescription: Patrice B\u00e8chard and Orlando Marquez Ayala are authors of the paper\nPaper ID: 2404.08189", "to": "Orlando Marquez Ayala"}, {"from": "Yizheng Huang", "title": "Relationship: Co-author\nDescription: They co-authored the paper\nPaper ID: 2404.10981", "to": "Jimmy Huang"}, {"from": "RAGCache", "title": "Relationship: Integrates\nDescription: RAGCache integrates the strengths of External Knowledge Databases with Large Language Models\nPaper ID: 2404.12457", "to": "External Knowledge Databases"}, {"from": "vLLM", "title": "Relationship: Integrated with\nDescription: vLLM is integrated with Faiss to evaluate the performance of RAGCache\nPaper ID: 2404.12457", "to": "Faiss"}, {"from": "Retrieval-Augmented Language Models", "title": "Relationship: combines\nDescription: Retrieval-Augmented Language Models combine the retrieved information with Language Models\u0027 output.\nPaper ID: 2404.19543", "to": "Language Models"}, {"from": "Retrieval-Augmented Language Models", "title": "Relationship: uses\nDescription: Retrieval-Augmented Language Models use Augmentations to combine the retrieved information with Language Models\u0027 output.\nPaper ID: 2404.19543", "to": "Augmentations"}, {"from": "Language Models", "title": "Relationship: Enhances\nDescription: Probing-RAG enhances language models by retrieving and incorporating relevant external knowledge.\nPaper ID: 2410.13339", "to": "Probing-RAG"}, {"from": "Alireza Salemi", "title": "Relationship: Co-author\nDescription: Alireza Salemi and Hamed Zamani are co-authors of the paper \u0027Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models\u0027\nPaper ID: 2405.00175", "to": "Hamed Zamani"}, {"from": "uRAG", "title": "Relationship: Unified Ranking\nDescription: uRAG provides a unified ranking system for multiple retrieval-augmented generation (RAG) systems\nPaper ID: 2405.00175", "to": "Search Engine"}, {"from": "GAIA", "title": "Relationship: Assists\nDescription: GAIA is a system that assists in the operation of particle accelerators\nPaper ID: 2405.01359", "to": "Particle Accelerators"}, {"from": "GAIA", "title": "Relationship: Author\nDescription: Frank Mayet is the author of the paper \u0027GAIA: A General AI Assistant for Intelligent Accelerator Operations\u0027\nPaper ID: 2405.01359", "to": "Frank Mayet"}, {"from": "Particle Accelerators", "title": "Relationship: Operates\nDescription: Operators are responsible for running particle accelerators\nPaper ID: 2405.01359", "to": "Operators"}, {"from": "Operators", "title": "Relationship: Assists\nDescription: RAG System assists operators in knowledge retrieval tasks and machine operation\nPaper ID: 2405.01359", "to": "RAG System"}, {"from": "ReAct", "title": "Relationship: Coupled\nDescription: ReAct is used to couple an open-weights large language model with a high-level machine control system framework\nPaper ID: 2405.01359", "to": "LLM"}, {"from": "LLM", "title": "Relationship: Works with\nDescription: RICHES can work with any Instruction-tuned model, without additional training\nPaper ID: 2407.00361", "to": "RICHES"}, {"from": "LLM", "title": "Relationship: uses\nDescription: MARAGS uses an LLM to produce generations.\nPaper ID: 2409.03171", "to": "MARAGS"}, {"from": "LLM", "title": "Relationship: used_by\nDescription: The LLM is used in the retrieval process of RAIDD.\nPaper ID: 2410.03754", "to": "RAIDD"}, {"from": "Retrieval-Augmented Large Language Models", "title": "Relationship: Author\nDescription: Yutao Zhu is the author of Retrieval-Augmented Large Language Models\nPaper ID: 2405.1967", "to": "Yutao Zhu"}, {"from": "Retrieval-Augmented Large Language Models", "title": "Relationship: Author\nDescription: Zhaoheng Huang is the author of Retrieval-Augmented Large Language Models\nPaper ID: 2405.1967", "to": "Zhaoheng Huang"}, {"from": "Retrieval-Augmented Large Language Models", "title": "Relationship: Author\nDescription: Zhicheng Dou is the author of Retrieval-Augmented Large Language Models\nPaper ID: 2405.1967", "to": "Zhicheng Dou"}, {"from": "Retrieval-Augmented Large Language Models", "title": "Relationship: Author\nDescription: Ji-Rong Wen is the author of Retrieval-Augmented Large Language Models\nPaper ID: 2405.1967", "to": "Ji-Rong Wen"}, {"from": "Vatsal Raina", "title": "Relationship: Co-author\nDescription: Both authors contributed to the paper \u0027Question-Based Retrieval using Atomic Units for Enterprise RAG\u0027\nPaper ID: 2405.12363", "to": "Mark Gales"}, {"from": "Documents", "title": "Relationship: Used by\nDescription: The synthesizer LLM uses documents as input\nPaper ID: 2405.12363", "to": "Synthesizer LLM"}, {"from": "Atomic statements", "title": "Relationship: Used in\nDescription: Dense retrieval is used to retrieve relevant atomic statements\nPaper ID: 2405.12363", "to": "Dense retrieval"}, {"from": "Dense retrieval", "title": "Relationship: Used with\nDescription: The user query is used with dense retrieval to retrieve relevant chunks\nPaper ID: 2405.12363", "to": "User query"}, {"from": "DuetRAG", "title": "Relationship: matches\nDescription: DuetRAG matches with expert human researchers on HotPot QA\nPaper ID: 2405.13002", "to": "HotPot QA"}, {"from": "FlashRAG", "title": "Relationship: Author\nDescription: Jiajie Jin is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\nPaper ID: 2405.13576", "to": "Jiajie Jin"}, {"from": "FlashRAG", "title": "Relationship: Author\nDescription: Yutao Zhu is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\nPaper ID: 2405.13576", "to": "Yutao Zhu"}, {"from": "FlashRAG", "title": "Relationship: Author\nDescription: Xinyu Yang is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\nPaper ID: 2405.13576", "to": "Xinyu Yang"}, {"from": "FlashRAG", "title": "Relationship: Author\nDescription: Chenghao Zhang is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\nPaper ID: 2405.13576", "to": "Chenghao Zhang"}, {"from": "FlashRAG", "title": "Relationship: Author\nDescription: Zhicheng Dou is one of the authors of the paper \u0027FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\u0027.\nPaper ID: 2405.13576", "to": "Zhicheng Dou"}, {"from": "Zhicheng Dou", "title": "Relationship: author\nDescription: Zhicheng Dou is one of the authors of MemoRAG\nPaper ID: 2409.05591", "to": "MemoRAG"}, {"from": "Sparse RAG", "title": "Relationship: augmented_with\nDescription: Sparse RAG combines LLMs with retrieval to exhibit robust performance and extensive versatility\nPaper ID: 2405.16178", "to": "Large language models (LLMs)"}, {"from": "Sparse RAG", "title": "Relationship: uses\nDescription: Sparse RAG encodes retrieved documents in parallel to eliminate latency\nPaper ID: 2405.16178", "to": "Retrieved documents"}, {"from": "Sparse RAG", "title": "Relationship: uses\nDescription: Sparse RAG uses control tokens to prompt LLMs for auto-regressive decoding\nPaper ID: 2405.16178", "to": "Control tokens"}, {"from": "Large language models (LLMs)", "title": "Relationship: related_to\nDescription: The paper discusses the limitations of LLMs and proposes RAG as a solution\nPaper ID: 2407.13193", "to": "Retrieval-Augmented Generation for Natural Language Processing: A Survey"}, {"from": "Large language models (LLMs)", "title": "Relationship: uses\nDescription: EfficientRAG uses large language models to generate new queries.\nPaper ID: 2408.04259", "to": "EfficientRAG"}, {"from": "M-RAG", "title": "Relationship: leverages\nDescription: M-RAG leverages Multi-Agent Reinforcement Learning to optimize different language generation tasks explicitly\nPaper ID: 2405.1642", "to": "Multi-Agent Reinforcement Learning"}, {"from": "M-RAG", "title": "Relationship: author\nDescription: Zheng Wang is an author of the paper introducing M-RAG\nPaper ID: 2405.1642", "to": "Zheng Wang"}, {"from": "M-RAG", "title": "Relationship: author\nDescription: Shu Xian Teo is an author of the paper introducing M-RAG\nPaper ID: 2405.1642", "to": "Shu Xian Teo"}, {"from": "M-RAG", "title": "Relationship: author\nDescription: Jieer Ouyang is an author of the paper introducing M-RAG\nPaper ID: 2405.1642", "to": "Jieer Ouyang"}, {"from": "M-RAG", "title": "Relationship: author\nDescription: Yongjun Xu is an author of the paper introducing M-RAG\nPaper ID: 2405.1642", "to": "Yongjun Xu"}, {"from": "M-RAG", "title": "Relationship: author\nDescription: Wei Shi is an author of the paper introducing M-RAG\nPaper ID: 2405.1642", "to": "Wei Shi"}, {"from": "Sudeshna Das", "title": "Relationship: Uses\nDescription: The paper uses a Generative Large Language Model (LLM) in the study\nPaper ID: 2405.19519", "to": "Generative Large Language Model (LLM)"}, {"from": "Reddit", "title": "Relationship: Platform\nDescription: Reddit is a social media platform used in the study\nPaper ID: 2405.19519", "to": "Social media forums"}, {"from": "Social media forums", "title": "Relationship: Source\nDescription: Emerging drug-related information is sourced from social media forums\nPaper ID: 2405.19519", "to": "Emerging drug-related information"}, {"from": "Multi-Head RAG", "title": "Relationship: uses\nDescription: Transformer is used in Multi-Head RAG to leverage activations of its multi-head attention layer as keys for fetching multi-aspect documents.\nPaper ID: 2406.05085", "to": "Transformer"}, {"from": "Zijian Hei", "title": "Relationship: coauthor\nDescription: Zijian Hei and Weiling Liu are co-authors of the paper.\nPaper ID: 2406.07348", "to": "Weiling Liu"}, {"from": "Scott Barnett", "title": "Relationship: co_author\nDescription: Scott Barnett and Zac Brannelly are co-authors of the study.\nPaper ID: 2406.11201", "to": "Zac Brannelly"}, {"from": "Stefanus Kurniawan", "title": "Relationship: co_author\nDescription: Stefanus Kurniawan and Sheng Wong are co-authors of the study.\nPaper ID: 2406.11201", "to": "Sheng Wong"}, {"from": "Gautam B", "title": "Relationship: Co-author\nDescription: Gautam B and Anupam Purwar are co-authors of the paper\nPaper ID: 2406.11424", "to": "Anupam Purwar"}, {"from": "Anupam Purwar", "title": "Relationship: Co-author\nDescription: Kush Juvekar and Anupam Purwar are authors of the paper\nPaper ID: 2407.19794", "to": "Kush Juvekar"}, {"from": "Open-Source LLMs", "title": "Relationship: Used in\nDescription: Open-Source LLMs are used in Enterprise-Specific RAG Systems\nPaper ID: 2406.11424", "to": "Enterprise-Specific RAG Systems"}, {"from": "Antonin Sulc", "title": "Relationship: Developed\nDescription: Antonin Sulc is one of the authors who developed the RAG model\nPaper ID: 2406.12881", "to": "Retrieval Augmented Generation (RAG) model"}, {"from": "DESY", "title": "Relationship: Associated with\nDescription: DESY is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "Logbooks"}, {"from": "Logbooks", "title": "Relationship: Associated with\nDescription: BESSY is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "BESSY"}, {"from": "Logbooks", "title": "Relationship: Associated with\nDescription: Fermilab is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "Fermilab"}, {"from": "Logbooks", "title": "Relationship: Associated with\nDescription: BNL is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "BNL"}, {"from": "Logbooks", "title": "Relationship: Associated with\nDescription: SLAC is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "SLAC"}, {"from": "Logbooks", "title": "Relationship: Associated with\nDescription: LBNL is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "LBNL"}, {"from": "Logbooks", "title": "Relationship: Associated with\nDescription: CERN is one of the particle accelerator facilities associated with logbooks\nPaper ID: 2406.12881", "to": "CERN"}, {"from": "Multi-Meta-RAG", "title": "Relationship: Performs well on\nDescription: Multi-Meta-RAG greatly improves the results on the MultiHop-RAG benchmark.\nPaper ID: 2406.13213", "to": "MultiHop-RAG"}, {"from": "Mykhailo Poliakov", "title": "Relationship: Co-author\nDescription: Mykhailo Poliakov and Nadiya Shvai are co-authors of the paper introducing the Multi-Meta-RAG method.\nPaper ID: 2406.13213", "to": "Nadiya Shvai"}, {"from": "Fromm", "title": "Relationship: Author\nDescription: Fromm is the author of the quote \u0027Seldom is a glance at the statistics enough to understand the meaning of the figures\u0027\nPaper ID: 2406.14972", "to": "Quote"}, {"from": "Base models", "title": "Relationship: Comparison\nDescription: Base models outperform instructed LLMs in RAG tasks by 20% on average\nPaper ID: 2406.14972", "to": "Instructed LLMs"}, {"from": "FS-RAG", "title": "Relationship: Author\nDescription: FS-RAG is a method developed by Harish Tayyar Madabushi\nPaper ID: 2406.16167", "to": "Harish Tayyar Madabushi"}, {"from": "FS-RAG", "title": "Relationship: Based On\nDescription: FS-RAG is based on the theory of Frame Semantics\nPaper ID: 2406.16167", "to": "Frame Semantics"}, {"from": "Ragnar ok", "title": "Relationship: Framework_for\nDescription: Ragnar\"ok is a reusable framework for the TREC 2024 RAG Track\nPaper ID: 2406.16828", "to": "TREC 2024 RAG Track"}, {"from": "Ragnar ok", "title": "Relationship: Uses\nDescription: Ragnar\"ok uses the MS MARCO V2.1 collection\nPaper ID: 2406.16828", "to": "MS MARCO V2.1"}, {"from": "Ragnar ok", "title": "Relationship: Compared_to\nDescription: Ragnar\"ok is compared to OpenAI\u0027s GPT-4o in the TREC 2024 RAG Track\nPaper ID: 2406.16828", "to": "OpenAI\u0027s GPT-4o"}, {"from": "Ragnar ok", "title": "Relationship: Compared_to\nDescription: Ragnar\"ok is compared to Cohere\u0027s Command R+ in the TREC 2024 RAG Track\nPaper ID: 2406.16828", "to": "Cohere\u0027s Command R+"}, {"from": "RICHES", "title": "Relationship: Applies to\nDescription: RICHES demonstrates strong performance across ODQA tasks\nPaper ID: 2407.00361", "to": "ODQA"}, {"from": "BERGEN", "title": "Relationship: author\nDescription: David Rau is one of the authors of the paper \u0027BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\u0027\nPaper ID: 2407.01102", "to": "David Rau"}, {"from": "Multimodal Retrieval Techniques", "title": "Relationship: Enhances\nDescription: Multimodal Retrieval Techniques enhance Question-Answering Capabilities\nPaper ID: 2407.01219", "to": "Question-Answering Capabilities"}, {"from": "Visual Inputs", "title": "Relationship: Input\nDescription: Visual Inputs are used as input to generate Multimodal Content\nPaper ID: 2407.01219", "to": "Multimodal Content"}, {"from": "Meta-prompting Optimized Retrieval-augmented Generation", "title": "Relationship: evaluated_on\nDescription: Meta-prompting Optimized Retrieval-augmented Generation was evaluated on the StrategyQA dataset.\nPaper ID: 2407.03955", "to": "StrategyQA dataset"}, {"from": "Speculative RAG", "title": "Relationship: evaluated_on\nDescription: Speculative RAG was evaluated on the TrivaQA benchmark.\nPaper ID: 2407.08223", "to": "TrivaQA"}, {"from": "RAGBench", "title": "Relationship: Uses\nDescription: RAGBench uses the TRACe framework for evaluation.\nPaper ID: 2407.11005", "to": "TRACe"}, {"from": "RAGBench", "title": "Relationship: Competes with\nDescription: RoBERTa model competes with LLM-based RAG evaluation methods on the RAG evaluation task.\nPaper ID: 2407.11005", "to": "RoBERTa"}, {"from": "NinjaLLM", "title": "Relationship: hosts\nDescription: NinjaLLM is hosted on AWS Trainium AI chips.\nPaper ID: 2407.12057", "to": "AWS Trainium"}, {"from": "NinjaLLM", "title": "Relationship: hosts\nDescription: NinjaLLM is hosted on Inferentia2 AI chips.\nPaper ID: 2407.12057", "to": "Inferentia2"}, {"from": "NinjaLLM", "title": "Relationship: fine-tuned\nDescription: NinjaLLM is fine-tuned using SageMaker.\nPaper ID: 2407.12057", "to": "SageMaker"}, {"from": "NinjaLLM", "title": "Relationship: developed\nDescription: Tengfei Xue contributed to the development of NinjaLLM.\nPaper ID: 2407.12057", "to": "Tengfei Xue"}, {"from": "NinjaLLM", "title": "Relationship: benchmarked\nDescription: NinjaLLM\u0027s performance was benchmarked on the Natural Questions dataset.\nPaper ID: 2407.12057", "to": "Natural Questions"}, {"from": "NinjaLLM", "title": "Relationship: benchmarked\nDescription: NinjaLLM\u0027s performance was benchmarked on the HotPotQA dataset.\nPaper ID: 2407.12057", "to": "HotPotQA"}, {"from": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "title": "Relationship: discusses\nDescription: The paper reviews the techniques of RAG and its applications\nPaper ID: 2407.13193", "to": "Retrieval-augmented generation (RAG)"}, {"from": "Retrieval-Augmented Generation for Natural Language Processing: A Survey", "title": "Relationship: authored\nDescription: The authors of the paper wrote the paper\nPaper ID: 2407.13193", "to": "Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue"}, {"from": "Retrieval-augmented generation (RAG)", "title": "Relationship: is_a\nDescription: EfficientRAG is a type of retrieval-augmented generation method.\nPaper ID: 2408.04259", "to": "EfficientRAG"}, {"from": "OpenROAD", "title": "Relationship: evaluated\nDescription: ORD-QA is an evaluation benchmark for OpenROAD.\nPaper ID: 2407.15353", "to": "ORD-QA"}, {"from": "RAG systems", "title": "Relationship: Retrieves information from\nDescription: RAG systems retrieve relevant information from external knowledge bases\nPaper ID: 2407.19794", "to": "External knowledge bases"}, {"from": "Modular RAG", "title": "Relationship: Authorship\nDescription: Yunfan Gao is an author of the paper introducing Modular RAG\nPaper ID: 2407.21059", "to": "Yunfan Gao"}, {"from": "RAGEval", "title": "Relationship: author\nDescription: Kunlun Zhu is one of the authors of the paper introducing RAGEval.\nPaper ID: 2408.01262", "to": "Kunlun Zhu"}, {"from": "RAG Foundry", "title": "Relationship: Author\nDescription: Daniel Fleischer is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\nPaper ID: 2408.02545", "to": "Daniel Fleischer"}, {"from": "RAG Foundry", "title": "Relationship: Author\nDescription: Moshe Berchansky is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\nPaper ID: 2408.02545", "to": "Moshe Berchansky"}, {"from": "RAG Foundry", "title": "Relationship: Author\nDescription: Moshe Wasserblat is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\nPaper ID: 2408.02545", "to": "Moshe Wasserblat"}, {"from": "RAG Foundry", "title": "Relationship: Author\nDescription: Peter Izsak is one of the authors of the paper \u0027RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\u0027.\nPaper ID: 2408.02545", "to": "Peter Izsak"}, {"from": "RAG Foundry", "title": "Relationship: Uses\nDescription: RAG Foundry uses Llama-3 as a large language model.\nPaper ID: 2408.02545", "to": "Llama-3"}, {"from": "RAG Foundry", "title": "Relationship: Uses\nDescription: RAG Foundry uses Phi-3 as a large language model.\nPaper ID: 2408.02545", "to": "Phi-3"}, {"from": "RAG Foundry", "title": "Relationship: Developed\nDescription: IntelLabs developed the RAG Foundry framework.\nPaper ID: 2408.02545", "to": "IntelLabs"}, {"from": "EfficientRAG", "title": "Relationship: evaluated_on\nDescription: EfficientRAG is evaluated on multi-hop question-answering datasets.\nPaper ID: 2408.04259", "to": "Multi-hop question-answering datasets"}, {"from": "Hybrid RAG System", "title": "Relationship: evaluated_on\nDescription: The Hybrid RAG System was evaluated on the CRAG Dataset.\nPaper ID: 2408.05141", "to": "CRAG Dataset"}, {"from": "Hybrid RAG System", "title": "Relationship: author_of\nDescription: Shizueyy is the author of the Hybrid RAG System.\nPaper ID: 2408.05141", "to": "Shizueyy"}, {"from": "Samhaa R. El-Beltagy", "title": "Relationship: Co-author\nDescription: They co-authored the paper\nPaper ID: 2408.07425", "to": "Mohamed A. Abdallah"}, {"from": "RAGChecker", "title": "Relationship: developed_by\nDescription: RAGChecker was developed by Dongyu Ru and other authors\nPaper ID: 2408.08067", "to": "Dongyu Ru"}, {"from": "RAGChecker", "title": "Relationship: open_sourced_by\nDescription: RAGChecker was open-sourced by Amazon Science\nPaper ID: 2408.08067", "to": "Amazon Science"}, {"from": "GraphRAG", "title": "Relationship: contributed_to\nDescription: Boci Peng contributed to the development of GraphRAG\nPaper ID: 2408.08921", "to": "Boci Peng"}, {"from": "RAG Noise", "title": "Relationship: evaluated_by\nDescription: RAG noise is evaluated using the Noise RAG Benchmark (NoiserBench)\nPaper ID: 2408.13533", "to": "Noise RAG Benchmark (NoiserBench)"}, {"from": "Jinyang Wu", "title": "Relationship: compares\nDescription: Jinyang Wu compares the concept of Pandora\u0027s Box to the concept of RAG noise\nPaper ID: 2408.13533", "to": "Pandora\u0027s Box"}, {"from": "Jinyang Wu", "title": "Relationship: compares\nDescription: Jinyang Wu compares the concept of Aladdin\u0027s Lamp to the concept of RAG noise\nPaper ID: 2408.13533", "to": "Aladdin\u0027s Lamp"}, {"from": "Tan Yu", "title": "Relationship: Co-authorship\nDescription: Tan Yu and Anbang Xu are co-authors of the paper \u0027In Defense of RAG in the Era of Long-Context Language Models\u0027\nPaper ID: 2409.01666", "to": "Anbang Xu"}, {"from": "Tan Yu", "title": "Relationship: Co-authorship\nDescription: Tan Yu and Rama Akkiraju are co-authors of the paper \u0027In Defense of RAG in the Era of Long-Context Language Models\u0027\nPaper ID: 2409.01666", "to": "Rama Akkiraju"}, {"from": "MARAGS", "title": "Relationship: uses\nDescription: MARAGS is a system designed for Meta\u0027s Comprehensive RAG (CRAG) competition.\nPaper ID: 2409.03171", "to": "Meta\u0027s Comprehensive RAG (CRAG)"}, {"from": "MARAGS", "title": "Relationship: participates_in\nDescription: MARAGS participated in the KDD CUP 2024 competition.\nPaper ID: 2409.03171", "to": "KDD CUP 2024"}, {"from": "MARAGS", "title": "Relationship: queries\nDescription: MARAGS queries API endpoints for additional information.\nPaper ID: 2409.03171", "to": "API endpoints"}, {"from": "OneGen", "title": "Relationship: Handles\nDescription: OneGen enables LLMs to handle Entity Linking tasks that require both generation and retrieval.\nPaper ID: 2409.05152", "to": "Entity Linking"}, {"from": "MemoRAG", "title": "Relationship: uses\nDescription: MemoRAG uses long-term memory to store information\nPaper ID: 2409.05591", "to": "Long-term memory"}, {"from": "MemoRAG", "title": "Relationship: author\nDescription: Hongjin Qian is one of the authors of MemoRAG\nPaper ID: 2409.05591", "to": "Hongjin Qian"}, {"from": "MemoRAG", "title": "Relationship: author\nDescription: Peitian Zhang is one of the authors of MemoRAG\nPaper ID: 2409.05591", "to": "Peitian Zhang"}, {"from": "MemoRAG", "title": "Relationship: author\nDescription: Zheng Liu is one of the authors of MemoRAG\nPaper ID: 2409.05591", "to": "Zheng Liu"}, {"from": "MemoRAG", "title": "Relationship: author\nDescription: Kelong Mao is one of the authors of MemoRAG\nPaper ID: 2409.05591", "to": "Kelong Mao"}, {"from": "SFR-RAG", "title": "Relationship: evaluated_on\nDescription: SFR-RAG is evaluated on the HotpotQA benchmark\nPaper ID: 2409.09916", "to": "HotpotQA"}, {"from": "SFR-RAG", "title": "Relationship: evaluated_on\nDescription: SFR-RAG is evaluated on the TriviaQA benchmark\nPaper ID: 2409.09916", "to": "TriviaQA"}, {"from": "SFR-RAG", "title": "Relationship: evaluated_on\nDescription: SFR-RAG is evaluated on the ContextualBench evaluation framework\nPaper ID: 2409.09916", "to": "ContextualBench"}, {"from": "SFR-RAG-9B", "title": "Relationship: compared_to\nDescription: SFR-RAG-9B is compared to the Command-R+ (104B) model\nPaper ID: 2409.09916", "to": "Command-R+ (104B)"}, {"from": "SFR-RAG-9B", "title": "Relationship: compared_to\nDescription: SFR-RAG-9B is compared to the GPT-4o model\nPaper ID: 2409.09916", "to": "GPT-4o"}, {"from": "P-RAG", "title": "Relationship: related_to\nDescription: P-RAG is designed to address the challenges of Embodied Everyday Task, such as lack of explicit task planning and extensive training required to equip models with knowledge of the task environment.\nPaper ID: 2409.11279", "to": "Embodied Everyday Task"}, {"from": "Sourav Verma", "title": "Relationship: author\nDescription: Sourav Verma is the author of a paper that explores the evolution of Contextual Compression paradigms.\nPaper ID: 2409.13385", "to": "Contextual Compression"}, {"from": "Shuo Yu", "title": "Relationship: Affiliation\nDescription: Shuo Yu is affiliated with Anhui Province Key Laboratory of Big Data Analysis and Application\nPaper ID: 2409.13694", "to": "Anhui Province Key Laboratory of Big Data Analysis and Application"}, {"from": "Shuo Yu", "title": "Relationship: Affiliation\nDescription: Shuo Yu is affiliated with University of Science and Technology of China\nPaper ID: 2409.13694", "to": "University of Science and Technology of China"}, {"from": "Shuo Yu", "title": "Relationship: Affiliation\nDescription: Shuo Yu is affiliated with State Key Laboratory of Cognitive Intelligence\nPaper ID: 2409.13694", "to": "State Key Laboratory of Cognitive Intelligence"}, {"from": "Jie Ouyang", "title": "Relationship: authored_paper\nDescription: Jie Ouyang authored a paper on the Meta KDD Cup 2024\nPaper ID: 2409.15337", "to": "Meta KDD Cup 2024"}, {"from": "APEX", "title": "Relationship: participated_in\nDescription: APEX team participated in the Meta KDD Cup 2024\nPaper ID: 2409.15337", "to": "Meta KDD Cup 2024"}, {"from": "APEX", "title": "Relationship: solved\nDescription: APEX team solved the CRAG benchmark challenge\nPaper ID: 2409.15337", "to": "CRAG"}, {"from": "GEM-RAG", "title": "Relationship: evaluates\nDescription: UnifiedQA is used to evaluate the performance of GEM-RAG.\nPaper ID: 2409.15566", "to": "UnifiedQA"}, {"from": "GEM-RAG", "title": "Relationship: evaluates\nDescription: GPT-3.5 Turbo is used to evaluate the performance of GEM-RAG.\nPaper ID: 2409.15566", "to": "GPT-3.5 Turbo"}, {"from": "GEM-RAG", "title": "Relationship: uses\nDescription: GEM-RAG uses SBERT as a text encoder.\nPaper ID: 2409.15566", "to": "SBERT"}, {"from": "RAFT", "title": "Relationship: combines\nDescription: RAFT combines with PEFT to reduce fine-tuning and storage requirements.\nPaper ID: 2409.17648", "to": "PEFT"}, {"from": "PEFT", "title": "Relationship: used in\nDescription: LoRA is used in PEFT as a parameter-efficient fine-tuning technique.\nPaper ID: 2409.17648", "to": "LoRA"}, {"from": "CRAFT", "title": "Relationship: applies to\nDescription: CRAFT is particularly useful for knowledge-intensive question answering tasks in resource-constrained environments.\nPaper ID: 2409.17648", "to": "Question Answering"}, {"from": "BSharedRAG", "title": "Relationship: Domain\nDescription: BSharedRAG is a system designed for the e-commerce domain\nPaper ID: 2409.20075", "to": "e-commerce"}, {"from": "BSharedRAG", "title": "Relationship: Uses\nDescription: BSharedRAG uses the Low-Rank Adaptation (LoRA) module\nPaper ID: 2409.20075", "to": "Low-Rank Adaptation (LoRA)"}, {"from": "BSharedRAG", "title": "Relationship: Author\nDescription: Kaisi Guan is an author of the paper proposing BSharedRAG\nPaper ID: 2409.20075", "to": "Kaisi Guan"}, {"from": "Retro-li", "title": "Relationship: Improved\nDescription: Retro-li is an improved version of Retro that uses a small-scale database and semantic similarity search to improve language modeling capabilities and reduce toxicity and hallucinations.\nPaper ID: 2410.00004", "to": "Retro"}, {"from": "Retro-li", "title": "Relationship: Uses\nDescription: Retro-li uses semantic similarity search to find accurate and better neighbors in a small-scale database.\nPaper ID: 2410.00004", "to": "Semantic Similarity Search"}, {"from": "Retro-li", "title": "Relationship: Contains\nDescription: Retro-li contains a non-parametric memory that is used to retrieve information and improve language modeling capabilities.\nPaper ID: 2410.00004", "to": "Non-Parametric Memory"}, {"from": "Retro-li", "title": "Relationship: Can be Implemented On\nDescription: Retro-li\u0027s non-parametric memory can be implemented on analog in-memory computing hardware, which can provide O(1) search time and minimal performance loss.\nPaper ID: 2410.00004", "to": "Analog In-Memory Computing Hardware"}, {"from": "DPrompt tuning", "title": "Relationship: resolves\nDescription: DPrompt tuning effectively resolves the issue of preprocessing information in documents\nPaper ID: 2410.02338", "to": "preprocessing"}, {"from": "StructRAG", "title": "Relationship: Requires\nDescription: StructRAG is designed to handle knowledge-intensive reasoning tasks\nPaper ID: 2410.08815", "to": "Knowledge-intensive reasoning"}, {"from": "Retrieval-Augmented Generation (RAG) agents", "title": "Relationship: Uses\nDescription: RAG agents use the LLM as a backbone\nPaper ID: 2410.09942", "to": "Backbone Large Language Model (LLM)"}, {"from": "Retrieval-Augmented Generation (RAG) agents", "title": "Relationship: Evaluates\nDescription: The approach is evaluated on the KILT benchmark\nPaper ID: 2410.09942", "to": "Knowledge-Intensive Language Tasks (KILT) benchmark"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Xinping Zhao is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Xinping Zhao"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Yan Zhong is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Yan Zhong"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Zetian Sun is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Zetian Sun"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Xinshuo Hu is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Xinshuo Hu"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Zhenyu Liu is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Zhenyu Liu"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Dongfang Li is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Dongfang Li"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Baotian Hu is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Baotian Hu"}, {"from": "FunnelRAG", "title": "Relationship: author_of\nDescription: Min Zhang is one of the authors of FunnelRAG\nPaper ID: 2410.10293", "to": "Min Zhang"}, {"from": "Wenjia Zhai", "title": "Relationship: Author\nDescription: Wenjia Zhai is the author of the paper \u0027Self-adaptive Multimodal Retrieval-Augmented Generation\u0027\nPaper ID: 2410.11321", "to": "Self-adaptive Multimodal Retrieval-Augmented Generation"}, {"from": "Self-adaptive Multimodal Retrieval-Augmented Generation", "title": "Relationship: Alternative\nDescription: Self-adaptive Multimodal Retrieval-Augmented Generation is an alternative to Traditional Retrieval-Augmented Generation\nPaper ID: 2410.11321", "to": "Traditional Retrieval-Augmented Generation"}, {"from": "SAM-RAG", "title": "Relationship: Application\nDescription: SAM-RAG is an application of Multimodal Retrieval-Augmented Generation\nPaper ID: 2410.11321", "to": "Multimodal Retrieval-Augmented Generation"}, {"from": "CoFE-RAG", "title": "Relationship: proposes\nDescription: Jintao Liu proposes the CoFE-RAG framework\nPaper ID: 2410.12248", "to": "Jintao Liu"}, {"from": "Knowledge Retrieval", "title": "Relationship: influences\nDescription: Knowledge Retrieval influences Knowledge Selection by providing the knowledge to be selected.\nPaper ID: 2410.13258", "to": "Knowledge Selection"}, {"from": "Probing-RAG", "title": "Relationship: Utilizes\nDescription: Probing-RAG utilizes a pre-trained prober to capture the internal cognition of language models.\nPaper ID: 2410.13339", "to": "Prober"}, {"from": "Probing-RAG", "title": "Relationship: Outperforms\nDescription: Probing-RAG outperforms previous methods in open-domain question answering tasks.\nPaper ID: 2410.13339", "to": "Open-domain QA Datasets"}, {"from": "AutoRAG", "title": "Relationship: authors\nDescription: The authors of the paper propose the AutoRAG framework\nPaper ID: 2410.20878", "to": "Dongkyu Kim, Byoungwook Kim, Donggeon Han and Matou\u0161 Eibich"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>
